{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b1458757ded9460ca9bb8d8973b7adae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b792a73550994cff8f72c761ebbf7c20",
              "IPY_MODEL_9085abee81fa4d98be9bd80f0531ad87",
              "IPY_MODEL_d605c426d0c046a9abfb60b2ac93919c"
            ],
            "layout": "IPY_MODEL_565946b7e8674d48a4bfe1a68dd25061"
          }
        },
        "b792a73550994cff8f72c761ebbf7c20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1e14a5ed5804c10aed91c672fe5ad5c",
            "placeholder": "​",
            "style": "IPY_MODEL_2074dee7dee245f589b511b5e7a010f3",
            "value": "modules.json: 100%"
          }
        },
        "9085abee81fa4d98be9bd80f0531ad87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0dc3ea746a85432885e6ab8b33180150",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_981ab91e73274870b8c51a3d9d57f950",
            "value": 349
          }
        },
        "d605c426d0c046a9abfb60b2ac93919c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9c91e8d20ed44edbde5de5e8b087a8c",
            "placeholder": "​",
            "style": "IPY_MODEL_ec1d34233acb4943981bd9275f392185",
            "value": " 349/349 [00:00&lt;00:00, 19.6kB/s]"
          }
        },
        "565946b7e8674d48a4bfe1a68dd25061": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1e14a5ed5804c10aed91c672fe5ad5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2074dee7dee245f589b511b5e7a010f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0dc3ea746a85432885e6ab8b33180150": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "981ab91e73274870b8c51a3d9d57f950": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e9c91e8d20ed44edbde5de5e8b087a8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec1d34233acb4943981bd9275f392185": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e700e8379691491d8d715c81def84c61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a74a4495280440979e5f2c243ddf99c9",
              "IPY_MODEL_777415ee4867478ab56e49f84a45db7f",
              "IPY_MODEL_f3e8a7fb6f314fac9fd61b331711cece"
            ],
            "layout": "IPY_MODEL_8c704ad2b3994fceb758ddec83a77a68"
          }
        },
        "a74a4495280440979e5f2c243ddf99c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61cacabe6d664f5f8a3cec80c308f977",
            "placeholder": "​",
            "style": "IPY_MODEL_6b81ef994ed547ffb7a65a30343d4704",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "777415ee4867478ab56e49f84a45db7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccc5a12f07f5469694b4f9955f7b6949",
            "max": 116,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_767b7e20f1d548bb95ee751a77914468",
            "value": 116
          }
        },
        "f3e8a7fb6f314fac9fd61b331711cece": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03c8e924b2f049e19b067f56de034f0d",
            "placeholder": "​",
            "style": "IPY_MODEL_68a9e18c33af4cb0bfc60dd0084d786b",
            "value": " 116/116 [00:00&lt;00:00, 10.6kB/s]"
          }
        },
        "8c704ad2b3994fceb758ddec83a77a68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61cacabe6d664f5f8a3cec80c308f977": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b81ef994ed547ffb7a65a30343d4704": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ccc5a12f07f5469694b4f9955f7b6949": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "767b7e20f1d548bb95ee751a77914468": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "03c8e924b2f049e19b067f56de034f0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68a9e18c33af4cb0bfc60dd0084d786b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2dd5fc3eb5dc466d8e6d31d818371b98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8f20aca573cc45b8ba3333c916f0d61e",
              "IPY_MODEL_6f1e6bba2e28423bbc1531bb0b09d232",
              "IPY_MODEL_6e09320b9fbc4be490200f212f27634d"
            ],
            "layout": "IPY_MODEL_7fe5d309825f4419908fcd20bc675f25"
          }
        },
        "8f20aca573cc45b8ba3333c916f0d61e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5f42cf9921c437ab77ce5e5d7ede177",
            "placeholder": "​",
            "style": "IPY_MODEL_fe887c6ad0db4d96b7b3662721a40951",
            "value": "README.md: 100%"
          }
        },
        "6f1e6bba2e28423bbc1531bb0b09d232": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_766fbd1b9337442a8d9e8a35d9ea90a0",
            "max": 10659,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_224294e836a14d798f93029cfcc42b04",
            "value": 10659
          }
        },
        "6e09320b9fbc4be490200f212f27634d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e37a6a1571a464fbc4d454f16d3d756",
            "placeholder": "​",
            "style": "IPY_MODEL_be2bb4a2170241d5b0ad20237de30a4e",
            "value": " 10.7k/10.7k [00:00&lt;00:00, 882kB/s]"
          }
        },
        "7fe5d309825f4419908fcd20bc675f25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5f42cf9921c437ab77ce5e5d7ede177": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe887c6ad0db4d96b7b3662721a40951": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "766fbd1b9337442a8d9e8a35d9ea90a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "224294e836a14d798f93029cfcc42b04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3e37a6a1571a464fbc4d454f16d3d756": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be2bb4a2170241d5b0ad20237de30a4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e01311a446464faa96f9ff094c828f19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fd9192df0d1840aba2d84d9bfb26ceb9",
              "IPY_MODEL_cedab43a90b4403bbea9ef6dd1d9cfb2",
              "IPY_MODEL_291af739a4a94e478fed82e980b468cb"
            ],
            "layout": "IPY_MODEL_aaa8b643d8be40deba1a055893e569c5"
          }
        },
        "fd9192df0d1840aba2d84d9bfb26ceb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6c70ccf90204a329f16e118e4ca46ab",
            "placeholder": "​",
            "style": "IPY_MODEL_1260377f983e475d93ea3851a368491d",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "cedab43a90b4403bbea9ef6dd1d9cfb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50de12155872486abf821876543d6383",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_709362c7bb0c460896e32064a8300073",
            "value": 53
          }
        },
        "291af739a4a94e478fed82e980b468cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20af3cc1512d4e268fcfd8ac2ddff355",
            "placeholder": "​",
            "style": "IPY_MODEL_0061bff0b479429ba2c2dde62e148de1",
            "value": " 53.0/53.0 [00:00&lt;00:00, 4.06kB/s]"
          }
        },
        "aaa8b643d8be40deba1a055893e569c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6c70ccf90204a329f16e118e4ca46ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1260377f983e475d93ea3851a368491d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50de12155872486abf821876543d6383": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "709362c7bb0c460896e32064a8300073": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "20af3cc1512d4e268fcfd8ac2ddff355": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0061bff0b479429ba2c2dde62e148de1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "00f7d7e3fc114eaf84b78611f15c85e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a6d2560afc914b5f8c4bea00937b2947",
              "IPY_MODEL_0262046f9e38404b94cf0ab77b4403f1",
              "IPY_MODEL_09cb50344e8140b980694494a952f1aa"
            ],
            "layout": "IPY_MODEL_bda8b4fba9f3434e98a84ec63cfebcff"
          }
        },
        "a6d2560afc914b5f8c4bea00937b2947": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55e85590710545b7b9eca1d3e4e47056",
            "placeholder": "​",
            "style": "IPY_MODEL_a6c3d8d8b6b34d3286ea7efb80d0a692",
            "value": "config.json: 100%"
          }
        },
        "0262046f9e38404b94cf0ab77b4403f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b9c7ea80ef346a9bdb52ffb8c953d44",
            "max": 612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ffd56a123637482d8da56a0696a134a7",
            "value": 612
          }
        },
        "09cb50344e8140b980694494a952f1aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b17fe514d1f41cd885f7464343e9dcf",
            "placeholder": "​",
            "style": "IPY_MODEL_a0e88234c9a24c0ca7d760de9555d90f",
            "value": " 612/612 [00:00&lt;00:00, 42.7kB/s]"
          }
        },
        "bda8b4fba9f3434e98a84ec63cfebcff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55e85590710545b7b9eca1d3e4e47056": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6c3d8d8b6b34d3286ea7efb80d0a692": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b9c7ea80ef346a9bdb52ffb8c953d44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffd56a123637482d8da56a0696a134a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3b17fe514d1f41cd885f7464343e9dcf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0e88234c9a24c0ca7d760de9555d90f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a3dce51a1794c39a3aba808d58f93a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_164f4cf60cbb40ad85fbcdb67a7de8a3",
              "IPY_MODEL_e574a564d4464d8a8d5a68713e1fb263",
              "IPY_MODEL_e1bc8989847a4a02898de128159921b5"
            ],
            "layout": "IPY_MODEL_b13370d89dfd421195c8e6ced5fb3916"
          }
        },
        "164f4cf60cbb40ad85fbcdb67a7de8a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a74fca617b242d888d700a3b7a79b23",
            "placeholder": "​",
            "style": "IPY_MODEL_463192ef605047ed8a5cb083d09b51b6",
            "value": "model.safetensors: 100%"
          }
        },
        "e574a564d4464d8a8d5a68713e1fb263": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c377811926441879f3830cce8bb4883",
            "max": 90868376,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f3fee8bb77b041b4aedb19d41220e3b6",
            "value": 90868376
          }
        },
        "e1bc8989847a4a02898de128159921b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e437ff58bbf494bbced5158b8af9caf",
            "placeholder": "​",
            "style": "IPY_MODEL_f3ae8b5417f54964a2327c9d640511c4",
            "value": " 90.9M/90.9M [00:00&lt;00:00, 179MB/s]"
          }
        },
        "b13370d89dfd421195c8e6ced5fb3916": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a74fca617b242d888d700a3b7a79b23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "463192ef605047ed8a5cb083d09b51b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c377811926441879f3830cce8bb4883": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3fee8bb77b041b4aedb19d41220e3b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e437ff58bbf494bbced5158b8af9caf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3ae8b5417f54964a2327c9d640511c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4424e9c653c641e394572802babc10ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3114b4e192824b258dd8a7fc297f76f1",
              "IPY_MODEL_92cbfb95946540cab3ab8e096c1fb6ad",
              "IPY_MODEL_46c30142852d4e1c97e73af3bf29ab10"
            ],
            "layout": "IPY_MODEL_4314d1a9e7da47d78c76be4c34ef2e25"
          }
        },
        "3114b4e192824b258dd8a7fc297f76f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d7ba9e643cc4780ba406e8a587434da",
            "placeholder": "​",
            "style": "IPY_MODEL_56115c4141a04d7d9a00d04feee179b0",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "92cbfb95946540cab3ab8e096c1fb6ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f58dae8e49f040d8825a6de7d2fe7bc4",
            "max": 350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bcb68c106b944d8fa6b9f08f9ed58b07",
            "value": 350
          }
        },
        "46c30142852d4e1c97e73af3bf29ab10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f6f418d86be494fa04005ca82369ef4",
            "placeholder": "​",
            "style": "IPY_MODEL_b77e6418bba64d15b11f30afd39a7c1f",
            "value": " 350/350 [00:00&lt;00:00, 29.0kB/s]"
          }
        },
        "4314d1a9e7da47d78c76be4c34ef2e25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d7ba9e643cc4780ba406e8a587434da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56115c4141a04d7d9a00d04feee179b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f58dae8e49f040d8825a6de7d2fe7bc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcb68c106b944d8fa6b9f08f9ed58b07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3f6f418d86be494fa04005ca82369ef4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b77e6418bba64d15b11f30afd39a7c1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8df852482ddc4f1286309a88d78b0da5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b9cb1a6e831c4fafa35450d49f3c3ebc",
              "IPY_MODEL_19f457d271534ac7a643375b57ea291c",
              "IPY_MODEL_7c899678fa6e4a7d9f08ac39513fb790"
            ],
            "layout": "IPY_MODEL_94fd43f29f934b048ad3e3dd95ba7561"
          }
        },
        "b9cb1a6e831c4fafa35450d49f3c3ebc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_694807f491004bf8b3834488c9db45e4",
            "placeholder": "​",
            "style": "IPY_MODEL_fd4a062370ce4cbf914cafa7ed30dc14",
            "value": "vocab.txt: 100%"
          }
        },
        "19f457d271534ac7a643375b57ea291c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a1c6774b99b43c98a4737cb95d2567c",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_55a3873ab9c843c8a91b8cef22694f59",
            "value": 231508
          }
        },
        "7c899678fa6e4a7d9f08ac39513fb790": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9857757cf65e4011a2ea181ad382b160",
            "placeholder": "​",
            "style": "IPY_MODEL_f561b960559d46098f5e01869e1d6561",
            "value": " 232k/232k [00:00&lt;00:00, 1.60MB/s]"
          }
        },
        "94fd43f29f934b048ad3e3dd95ba7561": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "694807f491004bf8b3834488c9db45e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd4a062370ce4cbf914cafa7ed30dc14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a1c6774b99b43c98a4737cb95d2567c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55a3873ab9c843c8a91b8cef22694f59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9857757cf65e4011a2ea181ad382b160": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f561b960559d46098f5e01869e1d6561": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe865474edc04cb28e5e0272e24ad8ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3f63f189aace4fc7b36c0140403ee310",
              "IPY_MODEL_d8c52960e9db4160bcc1f48a3a17a6b7",
              "IPY_MODEL_7abaf106a9654a779de10f54de539d7e"
            ],
            "layout": "IPY_MODEL_79b02c1abc464ba8b8f4be8d4d02e176"
          }
        },
        "3f63f189aace4fc7b36c0140403ee310": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_311501bfd96b417b8bb47a39ace5540c",
            "placeholder": "​",
            "style": "IPY_MODEL_a46c3c83134c41f890902e8ef7772f59",
            "value": "tokenizer.json: 100%"
          }
        },
        "d8c52960e9db4160bcc1f48a3a17a6b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e98aec7e8594cf5b907ee3fb895bfc3",
            "max": 466247,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f2885a0c6505499d86476859398e3d6d",
            "value": 466247
          }
        },
        "7abaf106a9654a779de10f54de539d7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e214ea99c8945138325c4bff5f8f3ab",
            "placeholder": "​",
            "style": "IPY_MODEL_4bf5d0c3ec144b488fe1ff803c59b17b",
            "value": " 466k/466k [00:00&lt;00:00, 5.98MB/s]"
          }
        },
        "79b02c1abc464ba8b8f4be8d4d02e176": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "311501bfd96b417b8bb47a39ace5540c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a46c3c83134c41f890902e8ef7772f59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e98aec7e8594cf5b907ee3fb895bfc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2885a0c6505499d86476859398e3d6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6e214ea99c8945138325c4bff5f8f3ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bf5d0c3ec144b488fe1ff803c59b17b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e71f8d1bec1484e876708c468048839": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6bc8638b1ef8439cbf11be54395cd8e4",
              "IPY_MODEL_d9dd68f3a63c408aa9d21cc2ce7e7e6a",
              "IPY_MODEL_e8237d543612482b9e3975b3228b2055"
            ],
            "layout": "IPY_MODEL_1a3abbcd24ab42c0b2a931b002cf8d18"
          }
        },
        "6bc8638b1ef8439cbf11be54395cd8e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fb0c9a814a142f0839fb5c10ffe5073",
            "placeholder": "​",
            "style": "IPY_MODEL_0b0811d80e9349668fdb359c67115e9e",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "d9dd68f3a63c408aa9d21cc2ce7e7e6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30a0758883ca4a89850e49a71edc51cf",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8d7f2ec93fd1479092e8dd7f9eca1dd3",
            "value": 112
          }
        },
        "e8237d543612482b9e3975b3228b2055": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97128d468c0a46579345908486867650",
            "placeholder": "​",
            "style": "IPY_MODEL_9459d2acc10a48d786e06f03bd811c88",
            "value": " 112/112 [00:00&lt;00:00, 7.63kB/s]"
          }
        },
        "1a3abbcd24ab42c0b2a931b002cf8d18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2fb0c9a814a142f0839fb5c10ffe5073": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b0811d80e9349668fdb359c67115e9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30a0758883ca4a89850e49a71edc51cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d7f2ec93fd1479092e8dd7f9eca1dd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "97128d468c0a46579345908486867650": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9459d2acc10a48d786e06f03bd811c88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6d02285388448198330ecd0641e518b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7b5139c410ef4bbebf763b39e47e9f85",
              "IPY_MODEL_c32f96badf6e4ab08c0db3057c847d26",
              "IPY_MODEL_ef25a227127544409de33af7c737f86a"
            ],
            "layout": "IPY_MODEL_bd5301e0bb2e48a79af290ad17bf0cda"
          }
        },
        "7b5139c410ef4bbebf763b39e47e9f85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd6267b617e249219abac3a382b53d34",
            "placeholder": "​",
            "style": "IPY_MODEL_e73bf2034951405c9ea5ff21114d3917",
            "value": "1_Pooling/config.json: 100%"
          }
        },
        "c32f96badf6e4ab08c0db3057c847d26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67a0d062a65b4b9ca7d730db33d8c277",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a51f291bba5943388b12a8275b4a7ff4",
            "value": 190
          }
        },
        "ef25a227127544409de33af7c737f86a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6089d9eeb4c347f99a1953c00b6f27b8",
            "placeholder": "​",
            "style": "IPY_MODEL_a86a2211c15b446f9a26bad03a31b75e",
            "value": " 190/190 [00:00&lt;00:00, 12.3kB/s]"
          }
        },
        "bd5301e0bb2e48a79af290ad17bf0cda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd6267b617e249219abac3a382b53d34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e73bf2034951405c9ea5ff21114d3917": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67a0d062a65b4b9ca7d730db33d8c277": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a51f291bba5943388b12a8275b4a7ff4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6089d9eeb4c347f99a1953c00b6f27b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a86a2211c15b446f9a26bad03a31b75e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KY7X-SQdpbdp",
        "outputId": "7f24c86e-6c66-4ec8-b00e-f8c2775e6d9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.17)\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-0.2.70-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting cassio\n",
            "  Downloading cassio-0.1.10-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.12)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.33 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.33)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.5)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.0.12-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.51-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting cassandra-driver<4.0.0,>=3.28.0 (from cassio)\n",
            "  Downloading cassandra_driver-3.29.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Collecting geomet<0.3,>=0.1 (from cassandra-driver<4.0.0,>=3.28.0->cassio)\n",
            "  Downloading geomet-0.2.1.post1-py3-none-any.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain) (4.12.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.1.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from geomet<0.3,>=0.1->cassandra-driver<4.0.0,>=3.28.0->cassio) (8.1.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from geomet<0.3,>=0.1->cassandra-driver<4.0.0,>=3.28.0->cassio) (1.17.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.33->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.1)\n",
            "Downloading langgraph-0.2.70-py3-none-any.whl (149 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.7/149.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cassio-0.1.10-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cassandra_driver-3.29.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.0.12-py3-none-any.whl (38 kB)\n",
            "Downloading langgraph_sdk-0.1.51-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading geomet-0.2.1.post1-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: geomet, cassandra-driver, langgraph-sdk, cassio, langgraph-checkpoint, langgraph\n",
            "Successfully installed cassandra-driver-3.29.2 cassio-0.1.10 geomet-0.2.1.post1 langgraph-0.2.70 langgraph-checkpoint-2.0.12 langgraph-sdk-0.1.51\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langgraph cassio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cassio\n",
        "#connection of the astra db\n",
        "ASTRA_DB_APPLICATION_TOKEN=\"\"\n",
        "ASTRA_DB_ID=\"\"\n",
        "cassio.init(token=ASTRA_DB_APPLICATION_TOKEN,database_id= ASTRA_DB_ID)\n"
      ],
      "metadata": {
        "id": "1ON1XraKpqlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXh-vO5JrWIb",
        "outputId": "a19e379c-ca6e-44a0-ac20-915375856a85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.17-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting langchain-core<1.0.0,>=0.3.34 (from langchain_community)\n",
            "  Downloading langchain_core-0.3.34-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langchain<1.0.0,>=0.3.18 (from langchain_community)\n",
            "  Downloading langchain-0.3.18-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.37)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.12)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.0.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.6)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting langchain-text-splitters<1.0.0,>=0.3.6 (from langchain<1.0.0,>=0.3.18->langchain_community)\n",
            "  Downloading langchain_text_splitters-0.3.6-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.18->langchain_community) (2.10.6)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain_community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.18->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.18->langchain_community) (2.27.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.1)\n",
            "Downloading langchain_community-0.3.17-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langchain-0.3.18-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.34-py3-none-any.whl (412 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.0/413.0 kB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
            "Downloading langchain_text_splitters-0.3.6-py3-none-any.whl (31 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-core, langchain-text-splitters, langchain, langchain_community\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.33\n",
            "    Uninstalling langchain-core-0.3.33:\n",
            "      Successfully uninstalled langchain-core-0.3.33\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.5\n",
            "    Uninstalling langchain-text-splitters-0.3.5:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.5\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.17\n",
            "    Uninstalling langchain-0.3.17:\n",
            "      Successfully uninstalled langchain-0.3.17\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-0.3.18 langchain-core-0.3.34 langchain-text-splitters-0.3.6 langchain_community-0.3.17 marshmallow-3.26.1 mypy-extensions-1.0.0 pydantic-settings-2.7.1 python-dotenv-1.0.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U tiktoken langchain-groq langchainhub chromadb langchain langgraph langchain_huggingface"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "y0pn_9_Et25_",
        "outputId": "2179eda1-357d-4ff3-8bbb-41847632d897"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting langchain-groq\n",
            "  Downloading langchain_groq-0.2.4-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langchainhub\n",
            "  Downloading langchainhub-0.1.21-py3-none-any.whl.metadata (659 bytes)\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-0.6.3-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.18)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.11/dist-packages (0.2.70)\n",
            "Collecting langchain_huggingface\n",
            "  Downloading langchain_huggingface-0.1.2-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Collecting groq<1,>=0.4.1 (from langchain-groq)\n",
            "  Downloading groq-0.18.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.33 in /usr/local/lib/python3.11/dist-packages (from langchain-groq) (0.3.34)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchainhub) (24.2)\n",
            "Collecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub)\n",
            "  Downloading types_requests-2.32.0.20241016-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting build>=1.0.3 (from chromadb)\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.10.6)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.115.8-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.26.4)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.12.0-py2.py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.12.2)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.16.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.30.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.51b0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.16.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.0)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.70.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.1)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-32.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (9.0.0)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.15)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.12)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.0.12)\n",
            "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.51)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langchain_huggingface) (0.28.1)\n",
            "Requirement already satisfied: sentence-transformers>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from langchain_huggingface) (3.4.1)\n",
            "Requirement already satisfied: transformers>=4.39.0 in /usr/local/lib/python3.11/dist-packages (from langchain_huggingface) (4.48.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting starlette<0.46.0,>=0.40.0 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (2024.10.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain-groq) (1.33)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.1.0)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.1.24)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (4.25.6)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (75.1.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.66.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.30.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.30.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-proto==1.30.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.30.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.51b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-instrumentation==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.51b0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting opentelemetry-util-http==0.51b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.51b0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.30.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting importlib-metadata<=8.5.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Downloading importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (2.5.1+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (11.1.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.0->langchain_huggingface) (0.5.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.33->langchain-groq) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.1.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.1.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (3.5.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.0.2)\n",
            "Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_groq-0.2.4-py3-none-any.whl (14 kB)\n",
            "Downloading langchainhub-0.1.21-py3-none-any.whl (5.2 kB)\n",
            "Downloading chromadb-0.6.3-py3-none-any.whl (611 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m92.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_huggingface-0.1.2-py3-none-any.whl (21 kB)\n",
            "Downloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Downloading fastapi-0.115.8-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groq-0.18.0-py3-none-any.whl (121 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.9/121.9 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-32.0.0-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m110.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.30.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.30.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.30.0-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.51b0-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.51b0-py3-none-any.whl (30 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.51b0-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_semantic_conventions-0.51b0-py3-none-any.whl (177 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.30.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_util_http-0.51b0-py3-none-any.whl (7.3 kB)\n",
            "Downloading opentelemetry_sdk-1.30.0-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.12.0-py2.py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.4/72.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.0.20241016-py3-none-any.whl (15 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n",
            "Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m110.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53771 sha256=eb6c1d96478ab318dbcb8401fb869c24054b09cdab6f84c7a6fd1e023fc08b1f\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, durationpy, uvloop, uvicorn, types-requests, pyproject_hooks, protobuf, overrides, opentelemetry-util-http, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mmh3, importlib-metadata, humanfriendly, httptools, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, tiktoken, starlette, posthog, opentelemetry-proto, opentelemetry-api, nvidia-cusparse-cu12, nvidia-cudnn-cu12, langchainhub, coloredlogs, build, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, onnxruntime, nvidia-cusolver-cu12, kubernetes, groq, fastapi, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, langchain-groq, opentelemetry-instrumentation-fastapi, langchain_huggingface, chromadb\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.6\n",
            "    Uninstalling protobuf-4.25.6:\n",
            "      Successfully uninstalled protobuf-4.25.6\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.6.1\n",
            "    Uninstalling importlib_metadata-8.6.1:\n",
            "      Successfully uninstalled importlib_metadata-8.6.1\n",
            "  Attempting uninstall: opentelemetry-api\n",
            "    Found existing installation: opentelemetry-api 1.16.0\n",
            "    Uninstalling opentelemetry-api-1.16.0:\n",
            "      Successfully uninstalled opentelemetry-api-1.16.0\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: opentelemetry-semantic-conventions\n",
            "    Found existing installation: opentelemetry-semantic-conventions 0.37b0\n",
            "    Uninstalling opentelemetry-semantic-conventions-0.37b0:\n",
            "      Successfully uninstalled opentelemetry-semantic-conventions-0.37b0\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: opentelemetry-sdk\n",
            "    Found existing installation: opentelemetry-sdk 1.16.0\n",
            "    Uninstalling opentelemetry-sdk-1.16.0:\n",
            "      Successfully uninstalled opentelemetry-sdk-1.16.0\n",
            "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.1 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-0.6.3 coloredlogs-15.0.1 durationpy-0.9 fastapi-0.115.8 groq-0.18.0 httptools-0.6.4 humanfriendly-10.0 importlib-metadata-8.5.0 kubernetes-32.0.0 langchain-groq-0.2.4 langchain_huggingface-0.1.2 langchainhub-0.1.21 mmh3-5.1.0 monotonic-1.6 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 onnxruntime-1.20.1 opentelemetry-api-1.30.0 opentelemetry-exporter-otlp-proto-common-1.30.0 opentelemetry-exporter-otlp-proto-grpc-1.30.0 opentelemetry-instrumentation-0.51b0 opentelemetry-instrumentation-asgi-0.51b0 opentelemetry-instrumentation-fastapi-0.51b0 opentelemetry-proto-1.30.0 opentelemetry-sdk-1.30.0 opentelemetry-semantic-conventions-0.51b0 opentelemetry-util-http-0.51b0 overrides-7.7.0 posthog-3.12.0 protobuf-5.29.3 pypika-0.48.9 pyproject_hooks-1.2.0 starlette-0.45.3 tiktoken-0.8.0 types-requests-2.32.0.20241016 uvicorn-0.34.0 uvloop-0.21.0 watchfiles-1.0.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "importlib_metadata"
                ]
              },
              "id": "71eb5128ac624dffa5f731d07cf8910e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import WebBaseLoader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERwGW4PsuWgR",
        "outputId": "bf59ba07-6836-4161-b14b-c141a89ce2a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#build index\n",
        "#docs to index\n",
        "urls=[\n",
        "    \"https://www.ibm.com/think/topics/ai-agents\",\n",
        "    \"https://www.ibm.com/think/topics/large-language-models\",\n",
        "    \"https://en.wikipedia.org/wiki/Generative_artificial_intelligence\"\n",
        "]\n",
        "#load url[\n",
        "docs= [WebBaseLoader(url).load() for url in urls]\n",
        "doc_list = [item for sublist in docs for item in sublist]\n",
        "print(doc_list)\n",
        "textsplitter=RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=500,chunk_overlap=0)\n",
        "docs_split = textsplitter.split_documents(doc_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vh-G92izvBXi",
        "outputId": "e496ae3d-3eff-4de1-8f71-43fd95076de0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(metadata={'source': 'https://www.ibm.com/think/topics/ai-agents', 'title': 'What Are AI Agents? | IBM', 'description': 'An artificial intelligence (AI) agent refers to a system or program that is capable of autonomously performing tasks on behalf of a user or another system.', 'language': 'en'}, page_content='\\n\\n\\n\\n\\n\\n\\n\\n\\nWhat Are AI Agents? | IBM\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                        \\n\\n\\n\\n  \\n    What are AI agents?\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n                    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                                    Artificial Intelligence\\n                                \\n\\n\\n\\n\\n\\n\\n                    \\n\\n\\n\\n  \\n    3 July 2024\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n                \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Link copied\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        \\n\\n\\n\\n  \\n    Authors\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAnna Gutowska\\nData Scientist, Developer Advocacy, IBM\\n\\n\\n\\n\\n\\n\\n\\r\\n        What are AI agents?\\r\\n    \\n\\n\\n\\nAn\\xa0artificial intelligence (AI)\\xa0agent refers to a system or program that is capable of autonomously performing tasks on behalf of a user or another system by designing its workflow and utilizing available tools.\\n\\n\\nAI agents can encompass a wide range of functionalities beyond natural language processing including decision-making, problem-solving, interacting with external environments and executing actions.\\nThese agents can be deployed in various applications to solve complex tasks in various enterprise contexts from software design and IT automation to code-generation tools and conversational assistants. They use the advanced natural language processing techniques of large language models (LLMs) to comprehend and respond to user inputs step-by-step and determine when to call on external tools.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\r\\n        How AI agents work\\r\\n    \\n\\n\\n\\nAt the core of AI agents are\\xa0large language models\\xa0(LLMs). For this reason, AI agents are often referred to as LLM agents.\\xa0Traditional\\xa0LLMs, such as\\xa0IBM®\\xa0Granite™ models,\\xa0produce their responses based on the data used to train them and are bounded by knowledge and reasoning limitations. In contrast, agentic technology uses tool calling on the backend to obtain up-to-date information, optimize workflow and create subtasks autonomously to achieve complex goals.\\nIn this process, the autonomous agent learns to adapt to user expectations over time. The agent\\'s ability to store past interactions in memory and plan future actions encourages a personalized experience and comprehensive responses.1\\xa0This tool calling can be achieved without human intervention and broadens the possibilities for real-world applications of these AI systems.\\xa0The approach that\\xa0AI agents\\xa0take in achieving goals set by users is comprised of these three stages:\\n\\n\\nGoal initialization and planning\\n\\n\\nAlthough\\xa0AI agents\\xa0are autonomous in their\\xa0decision-making\\xa0processes, they require goals and environments defined by humans.2\\xa0There are three main influences on\\xa0autonomous agent\\xa0behavior:\\xa0\\nThe team of developers that design and train the agentic\\xa0AI system.\\xa0The team that deploys the agent and provides the user with access to it.The user that provides the\\xa0AI agent\\xa0with specific goals to accomplish and establishes available tools to use.\\nGiven the user\\'s goals and the agent’s available tools, the\\xa0AI agent\\xa0then performs task decomposition to improve performance.3\\xa0Essentially, the agent creates a plan of\\xa0specific tasks\\xa0and subtasks to accomplish the complex goal. \\nFor simple tasks, planning is not a necessary step. Instead, an agent can iteratively reflect on its responses and improve them without planning its next steps.\\n\\n\\nReasoning using available tools\\n\\n\\nAI agents base their actions on the information they perceive. Often,\\xa0AI agents\\xa0do not have the full\\xa0knowledge base needed\\xa0for tackling all subtasks within a complex goal. To remedy this,\\xa0AI agents use their available tools. These tools can include external\\xa0data sets, web searches,\\xa0APIs and even other agents. After the missing information is retrieved from these tools, the agent can update its knowledge base. This means that each step of the way, the agent reassesses its plan of action and self-corrects.\\nTo help illustrate this process, imagine a user planning their vacation. The user tasks an AI agent with predicting which week in the next year would likely have the best weather for their surfing trip in Greece. Since the LLM model at the core of the agent does not specialize in weather patterns, the agent gathers information from an external database comprised of daily weather reports for Greece over the past several years.\\nDespite acquiring this new information, the agent still cannot determine the optimal weather conditions for surfing and so, the next subtask is created. For this subtask, the agent communicates with an external agent that specializes in surfing. Let’s say that in doing so, the agent learns that high tides and sunny weather with little to no rain provide the best surfing conditions.\\nThe agent can now combine the information it has learned from its tools to identify patterns. It can predict which week next year in Greece will likely have high tides, sunny weather and a low chance of rain. These findings are then presented to the user. This sharing of information between tools is what allows\\xa0AI agents\\xa0to be more general-purpose than traditional\\xa0AI models.3\\n\\n\\nLearning and reflection\\n\\n\\nAI agents\\xa0use feedback mechanisms, such as other AI agents and human-in-the-loop (HITL), to improve the accuracy of their responses. Let’s return to our previous surfing example to highlight this. After the agent forms its response to the user, the agent stores the learned information along with the user’s feedback to improve performance and adjust to user preferences for future goals.\\nIf other agents were used to reach the goal, their feedback may also be used.\\xa0Multi-agent feedback can be especially useful in minimizing the time that human users spend providing direction. However, users can also provide feedback throughout the agent\\'s actions and internal reasoning to better align the results with the intended goal.2\\nFeedback mechanisms improve the\\xa0AI agent\\'s reasoning and accuracy, which is commonly referred to as iterative refinement.3\\xa0To avoid repeating the same mistakes,\\xa0AI agents\\xa0can also store data about solutions to previous obstacles in a\\xa0knowledge base.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nIndustry newsletter\\n\\n\\n\\nThe latest AI trends, brought to you by experts\\n\\n\\nThank you! You are subscribed.\\n\\n\\n\\nGet curated insights on the most important—and intriguing—AI news. Subscribe to our weekly Think newsletter. See the IBM Privacy Statement.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nYour subscription will be delivered in English. You will find an unsubscribe link in every newsletter. You can manage your subscriptions or unsubscribe here. Refer to our IBM Privacy Statement for more information.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\r\\n        Agentic versus non-agentic AI chatbots\\r\\n    \\n\\n\\n\\nAI\\xa0chatbots\\xa0use\\xa0conversational AI\\xa0techniques such as\\xa0natural language processing\\xa0(NLP) to understand user questions and automate responses to them. These chatbots are a modality whereas agency is a technological framework.\\xa0\\nNon-agentic AI chatbots are ones without available tools, memory and reasoning. They can only reach short-term goals and cannot plan ahead.\\xa0As we know them, non-agentic chatbots\\xa0require continuous user input to respond.\\xa0They can produce responses to common prompts that most likely align with user expectations but perform poorly on questions unique to the user and their data. Since these chatbots do not hold memory, they cannot learn from their mistakes if their responses are unsatisfactory.\\n\\nIn contrast,\\xa0agentic AI chatbots learn to adapt to user expectations over time, providing a more personalized experience and comprehensive responses. They can complete complex tasks by creating subtasks without\\xa0human intervention and considering different plans. These plans can also be self-corrected and updated as needed.\\xa0Agentic AI chatbots, unlike non-agentic ones, assess their tools and use their available resources to fill in information gaps.\\xa0\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n      Mixture of Experts | 7 February, episode 41\\n  \\n\\n\\n\\n\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            \\n\\n\\n\\n  \\n    Decoding AI: Weekly News Roundup\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n        \\n\\n\\nJoin our world-class panel of engineers, researchers, product leaders and more as they cut through the AI noise to bring you the latest in AI news and insights.\\n\\n\\n\\n\\nWatch the latest podcast episodes\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\r\\n        Reasoning paradigms\\r\\n    \\n\\n\\n\\nThere is not one standard architecture for building AI agents. Several paradigms exist for solving multi-step problems.\\n\\n\\nReAct (Reasoning and Action)\\n\\n\\nWith this paradigm, we can instruct agents to \"think\" and plan after each action taken and with each tool response to decide which tool to use next. These Think-Act-Observe loops are used to solve problems step by step and iteratively improve upon responses.\\nThrough the prompt structure, agents can be instructed to reason slowly and to display each \"thought\".4\\xa0The agent\\'s verbal reasoning gives insight into how responses are formulated. In this framework, agents continuously update their context with new reasoning. This can be interpreted as a form of\\xa0Chain-of-Thought prompting.\\n\\n\\nReWOO (Reasoning WithOut Observation)\\n\\n\\nThe ReWOO method, unlike ReAct, eliminates the dependence on tool outputs for action planning. Instead, agents plan upfront. Redundant tool usage is avoided by anticipating which tools to use upon receiving the initial prompt from the user. This is desirable from a human-centered perspective since the user can confirm the plan before it is executed.\\nThe ReWOO workflow is made up of three modules. In the planning module, the agent anticipates its next steps given a user\\'s prompt. The next stage entails collecting the outputs produced by calling these tools. Lastly, the agent pairs the initial plan with the tool outputs to formulate a response. This planning ahead can greatly reduce token usage and computational complexity as well as the repercussions of intermediate tool failure.5\\n\\n\\n\\r\\n        Types of AI agents\\r\\n    \\n\\n\\n\\nAI agents can be developed to have varying levels of capabilities. A simple agent may be preferred for straightforward goals to limit unnecessary computational complexity. In order of simplest to most advanced, there are 5 main agent types:\\n\\n\\n1. Simple reflex agents\\n\\n\\nSimple reflex agents are the simplest agent form that grounds actions on current\\xa0perception. This agent does not hold any memory, nor does it interact with other agents if it is missing information. These\\xa0agents function\\xa0on a set of so-called reflexes or rules. This means that the agent is preprogrammed to perform actions that correspond to certain conditions being met.\\nIf the agent encounters a situation that it is not prepared for, it cannot respond appropriately. The agents are only effective in environments that are fully observable granting access to all necessary information.6\\nExample: A thermostat that turns on the heating system at a set time every night. The condition-action rule here is, for instance, if it is 8 PM, then the heating is activated.\\n\\n\\n\\n2. Model-based reflex agents\\n\\n\\nModel-based reflex agents use both their current\\xa0perception\\xa0and memory to maintain an internal model of the world. As the agent continues to receive new information, the model is updated. The agent’s actions depend on its model, reflexes, previous\\xa0precepts and current state.\\nThese agents, unlike\\xa0simple reflex agents, can store information in memory and can operate in environments that are partially observable and changing. However, they are still limited by their set of rules.6\\nExample: A robot vacuum cleaner. As it cleans a dirty room, it senses obstacles such as furniture and adjusts around them. The robot also stores a model of the areas it has already cleaned to not get stuck in a loop of repeated cleaning.\\n\\n\\n3. Goal-based agents\\n\\n\\nGoal-based agents have an internal model of the world and also a goal or set of goals. These agents search for action sequences that reach their goal and plan these actions before acting on them. This search and planning improve their effectiveness when compared to simple and\\xa0model-based reflex agents.7\\nExample: A navigation system that recommends the fastest route to your destination. The model considers various routes that reach your destination, or in other words, your goal. In this example, the agent’s condition-action rule states that if a quicker route is found, the agent recommends that one instead.\\n\\n\\n4. Utility-based agents\\n\\n\\nUtility-based agents select the sequence of actions that reach the goal and also maximize utility or reward. Utility is calculated using a utility function. This function assigns a utility value, a metric measuring the usefulness of an action or how “happy” it will make the agent, to each scenario based on a set of fixed criteria.\\nThe criteria can include factors such as progression toward the goal, time requirements, or computational complexity. The agent then selects the actions that maximize the expected utility. Hence, these agents are useful in cases where multiple scenarios achieve a desired goal and an optimal one must be selected.7\\nExample: A navigation system that recommends the route to your destination that optimizes fuel efficiency and minimizes the time spent in traffic and the cost of tolls. This agent measures utility through this set of criteria to select the most favorable route.\\n\\n\\n5. Learning agents\\n\\n\\nLearning agents hold the same capabilities as the other agent types but are unique in their ability to learn. New experiences are added to their initial\\xa0knowledge base, which occurs autonomously. This learning enhances the agent’s ability to operate in unfamiliar environments.\\xa0Learning agents\\xa0may be utility or goal-based in their reasoning and are comprised of four main elements:7\\nLearning:\\xa0This\\xa0improves the agent’s knowledge by learning from the environment through its\\xa0precepts\\xa0and sensors.Critic:\\xa0This\\xa0provides feedback to the agent on whether the quality of its responses meets the performance standard.Performance:\\xa0This element is responsible for selecting actions upon learning.Problem\\xa0generator:\\xa0This\\xa0creates various proposals for actions to be taken.\\nExample: Personalized recommendations on e-commerce sites. These agents track user activity and preferences in their memory. This information is used to recommend certain products and services to the user. The cycle repeats each time new recommendations are made. The user’s activity is continuously stored for learning purposes. In doing so, the agent improves its accuracy over time.\\n\\n\\nUse cases of AI agents\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        \\n\\n\\n\\n  \\n    Customer experience\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n    \\n\\n\\nAI agents can be integrated into websites and\\xa0apps\\xa0to enhance the\\xa0customer experience\\xa0by serving as a virtual assistants, providing mental health support, simulating interviews and other related tasks.8\\xa0There are many\\xa0no-code templates\\xa0for user implementation, making the process of creating these AI agents even easier.\\xa0\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        \\n\\n\\n\\n  \\n    Healthcare\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n    \\n\\n\\nAI agents\\xa0can be used for various\\xa0real-world healthcare\\xa0applications. Multi-agent systems can be particularly useful for problem-solving in such settings. From treatment planning for patients in the emergency department to managing drug processes, these systems save the time and effort of medical professionals for more urgent tasks.9\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        \\n\\n\\n\\n  \\n    Emergency response\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n    \\n\\n\\nIn case of natural disasters,\\xa0AI agents\\xa0can use\\xa0deep learning\\xa0algorithms\\xa0to retrieve the information of users on social media sites that need rescue. The locations of these users can be mapped to assist rescue services in saving more people in less time. Therefore,\\xa0AI agents\\xa0can greatly benefit human life in both mundane tasks and life-saving situations.10\\n\\n\\n\\n\\n\\n\\r\\n        Benefits of AI agents\\r\\n    \\n\\n\\n\\nTask automation\\n\\n\\nWith the ongoing\\xa0advancements\\xa0in\\xa0generative AI, there is a growing interest in workflow\\xa0optimization using AI, or intelligent automation.\\xa0AI agents\\xa0are\\xa0AI tools\\xa0that can\\xa0automate\\xa0complex tasks\\xa0that would otherwise require human resources. This translates to goals being reached inexpensively, rapidly and at scale. In turn, these\\xa0advancements\\xa0mean\\xa0human agents\\xa0do not need to provide direction to the\\xa0AI assistant\\xa0for creating and navigating its tasks.\\n\\n\\nGreater performance\\n\\n\\nMulti-agent\\xa0frameworks\\xa0tend to outperform singular agents.11\\xa0This is because the more plans of action are available to an agent, the more learning and reflection occur. An AI agent incorporating knowledge and feedback from other\\xa0AI agents\\xa0specializing in related areas can be useful for information synthesis. This\\xa0backend\\xa0collaboration of AI agents and the ability to fill information gaps are unique to agentic frameworks, making them a powerful tool and a meaningful advancement in artificial intelligence.\\n\\n\\nQuality of responses\\n\\n\\nAI agents\\xa0provide responses that are more comprehensive, accurate and personalized to the user than traditional\\xa0AI models. This is extremely important to us as users since higher-quality responses typically yield a better customer experience. As previously described, this is made possible through exchanging information with other agents, using external tools and updating their memory stream. These behaviors emerge on their own and are not preprogrammed.12\\n\\n\\n\\r\\n        Risks and limitations\\r\\n    \\n\\n\\n\\nMulti-agent dependencies\\n\\n\\nCertain complex tasks require the knowledge of multiple AI agents. When implementing these multi-agent frameworks, there is a risk of malfunction. Multi-agent systems built on the same\\xa0foundation models\\xa0may experience shared pitfalls. Such weaknesses could cause a system-wide failure of all involved agents or expose vulnerability to adverse attacks.13\\xa0This highlights the importance of data governance in building foundation models and thorough training and testing processes.\\n\\n\\nInfinite feedback loops\\n\\n\\nThe convenience of the hands-off\\xa0reasoning for human users using\\xa0AI agents\\xa0also comes with its risks. Agents that are unable to create a comprehensive plan or reflect on their findings, may find themselves repeatedly calling the same tools, invoking infinite feedback loops. To avoid these redundancies, some level of\\xa0real-time\\xa0human monitoring may be used.13\\n\\n\\nComputational complexity\\n\\n\\nBuilding\\xa0AI agents\\xa0from scratch is both time-consuming and can also be very computationally expensive. The resources required for training a high-performance agent can be extensive. Additionally, depending on the complexity of the task, agents can take several days to complete tasks.12\\n\\n\\n\\r\\n        Best practices\\r\\n    \\n\\n\\n\\nActivity logs\\xa0\\n\\n\\nTo address the concerns of multi-agent dependencies, developers can provide users with access to a log of agent actions.14\\xa0The actions can include the use of external tools and describe the external agents utilized to reach the goal. This transparency grants users insight into the iterative\\xa0decision-making\\xa0process, provides the opportunity to\\xa0discover\\xa0errors and builds trust.\\n\\n\\nInterruption\\n\\n\\nPreventing\\xa0AI agents\\xa0from running for overly long periods of time is recommended. Particularly, in cases of unintended infinite feedback loops, changes in access to certain tools, or malfunctioning due to design flaws. One way to accomplish this is by implementing interruptibility.\\nMaintaining control of this involves allowing human users the option to gracefully interrupt a sequence of actions or the entire operation. Choosing if and when to interrupt an\\xa0AI agent\\xa0requires some thoughtfulness as some terminations can cause more harm than good. For instance, it may be safer to allow a faulty agent to continue assisting in a life-threatening emergency than to completely shut it down.5\\n\\n\\nUnique agent identifiers\\n\\n\\nTo mitigate the risk of agentic systems being used for malicious use, unique identifiers can be used.14\\xa0If these identifiers were to be required for agents to access external systems, there would be greater ease in tracing the origin of the agent\\'s developers, deployers and its user. This would be particularly helpful in case of any malicious use or unintended harm done by the agent. This level of accountability would provide a safer environment for these\\xa0AI agents\\xa0to operate.\\n\\n\\nHuman supervision\\n\\n\\nTo assist in the learning process for\\xa0AI agents, especially in their early stages in a new environment, it can be helpful to provide occasional human feedback. This allows the\\xa0AI agent\\xa0to compare its performance to the expected standard and adjust accordingly. This form of feedback is helpful in improving the agent’s adaptability to user preferences.5\\nApart from this, it is best practice to require human approval before an\\xa0AI agent\\xa0takes highly impactful actions. For instance, actions ranging from sending mass emails to financial trading should require human confirmation.7\\xa0Some level of human monitoring is recommended for such high-risk domains.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Ebook\\n        \\n\\n            How to choose the right foundation model\\n        \\nLearn how to choose the right approach in preparing datasets and employing foundation models.\\n\\nRead the ebook\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            \\n\\n\\n\\n  \\n    Resources\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Report\\n        \\n\\n            AI in Action 2024\\n        \\nWe surveyed 2,000 organizations about their AI initiatives to discover what\\'s working, what\\'s not and how you can get ahead.\\n\\nRead the report\\n\\n\\n\\n\\n\\n\\n\\n            AI models\\n        \\n\\n            Explore IBM Granite\\n        \\nIBM® Granite™ is our family of open, performant and trusted AI models, tailored for business and optimized to scale your AI applications. Explore language, code, time series and guardrail options.\\n\\nMeet Granite\\n\\n\\n\\n\\n\\n\\n\\n            Training\\n        \\n\\n            Level up your AI expertise\\n        \\nAccess our full catalog of over 100 online courses by purchasing an individual or multi-user subscription today, enabling you to expand your skills across a range of our products at one low price.\\n\\nStart learning\\n\\n\\n\\n\\n\\n\\n\\n            Video\\n        \\n\\n            IBM AI Academy\\n        \\nLed by top IBM thought leaders, the curriculum is designed to help business leaders gain the knowledge needed to prioritize the AI investments that can drive growth.\\n\\nExplore the series\\n\\n\\n\\n\\n\\n\\n\\n            Guide\\n        \\n\\n            Put AI to work: Driving ROI with gen AI\\n        \\nWant to get a better return on your AI investments? Learn how scaling gen AI in key areas drives change by helping your best minds build and deliver innovative new solutions.\\n\\nRead the guide\\n\\n\\n\\n\\n\\n\\n\\n            Ebook\\n        \\n\\n            Unlock the power of generative AI + ML\\n        \\nLearn how to confidently incorporate generative AI and machine learning into your business.\\n\\nRead the ebook\\n\\n\\n\\n\\n\\n\\n\\n            Guide\\n        \\n\\n            How to thrive in this new era of AI with trust and confidence\\n        \\nDive into the 3 critical elements of a strong AI strategy: creating a competitive edge, scaling AI across the business and advancing trustworthy AI.\\n\\nRead the guide\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            \\n            \\n\\n     \\n    Related AI topics\\n\\n\\n\\n\\n    \\n\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        \\n\\n\\n\\n  \\n    Mixture of Experts podcast\\n\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n    \\n\\n\\n\\nLet’s bust some early myths about DeepSeek! In\\r\\nMixture of Experts\\' episode 40, the panel tackles DeepSeek R1 misconceptions, explains\\r\\nmodel distillation, and dissects the open-source competition landscape.\\n\\n\\n\\nDeepSeek facts vs hype, model distillation, and open source competition\\n            \\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        \\n\\n\\n\\n  \\n    Artificial intelligence solutions\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n    \\n\\n\\n\\nPut AI to work in your business with IBM\\'s industry-leading AI expertise and portfolio of solutions at your side.\\n\\n\\n\\nExplore AI solutions\\n            \\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        \\n\\n\\n\\n  \\n    AI consulting and services\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n    \\n\\n\\n\\nReinvent critical workflows and operations by adding AI to maximize experiences, real-time decision-making and business value.\\n\\n\\n\\nExplore AI services\\n            \\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTake the next step\\n\\n\\n\\n\\nGet one-stop access to capabilities that span the AI development lifecycle. Produce powerful AI solutions with user-friendly interfaces, workflows and access to industry-standard APIs and SDKs.\\n\\n\\n\\n\\n\\nExplore watsonx.ai\\n\\n\\n\\nBook a live demo\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                            \\n\\n\\n\\n  \\n    Footnotes\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n                        \\n\\n\\n\\n\\n\\n1\\xa0Andrew Zhao, Daniel Huang, Quentin Xu, Matthieu Lin, Yong-Jin Liu, and Gao Huang, \"Expel:\\xa0Llm\\xa0agents are experiential learners,\"\\xa0Proceedings of the AAAI Conference on\\xa0Artificial Intelligence, Vol. 38, No. 17, pp. 19632-19642, 2024,\\xa0https://ojs.aaai.org/index.php/AAAI/article/view/29936\\xa0(link resides outside of ibm.com).\\n2\\xa0Yonadov Shavit, Sandhini Agarwal, Miles Brundage, Steven Adler, Cullen O’Keefe, Rosie Campbell, Teddy Lee, Pamela Mishkin, Tyna Eloundou, Alan Hickey, Katarina Slama, Lama Ahmad, Paul McMillan, Alex Beutel, Alexandre Passos and David G. Robinson, “Practices for Governing Agentic\\xa0AI Systems,”\\xa0OpenAI, 2023,\\xa0https://arxiv.org/pdf/2401.13138v3\\xa0(link resides outside of ibm.com).\\n3\\xa0Tula Masterman, Sandi Besen, Mason Sawtell, Alex Chao, “The Landscape of Emerging\\xa0AI AgentArchitectures for Reasoning, Planning, and Tool Calling: A Survey,”\\xa0arXiv preprint, 2024,\\xa0https://arxiv.org/abs/2404.11584\\xa0(link resides outside of ibm.com).\\n4\\xa0Gautier Dagan, Frank Keller, and Alex Lascarides, \"Dynamic Planning with a LLM,\" arXiv preprint,\\xa02023.\\xa0https://arxiv.org/abs/2308.06391\\xa0(link resides outside of ibm.com).\\n5\\xa0Binfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, and Dongkuan Xu, \"ReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models,\" arXiv preprint, 2023,\\xa0https://arxiv.org/abs/2305.18323\\xa0(link resides outside of ibm.com).\\n6\\xa0Sebastian Schmid, Daniel Schraudner, and Andreas Harth, \"Performance comparison of\\xa0simple reflex agents using stigmergy with model-based agents in self-organizing transportation.\"\\xa0IEEE International Conference on Autonomic Computing and Self-Organizing Systems Companion, pp. 93-98, 2021,\\xa0https://ieeexplore.ieee.org/document/9599196\\xa0(link resides outside of ibm.com).\\n7\\xa0Veselka Sasheva Petrova-Dimitrova, “Classifications of intelligence agents and their applications,”\\xa0Fundamental Sciences and Applications, Vol. 28, No. 1, 2022.\\n8\\xa0Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, Wayne Xin Zhao, Zhewei Wei, and Jirong Wen, “A survey on\\xa0large language model\\xa0based\\xa0autonomous agents,”\\xa0Frontiers of Computer Science, Vol. 18, No. 6, 2024,\\xa0https://link.springer.com/article/10.1007/s11704-024-40231-1\\xa0(link resides outside of ibm.com).\\n9\\xa0Jaya R. Haleema, Haleema, N. C. S. N. Narayana, “Enhancing a Traditional Health Care System of an Organization for Better Service with Agent Technology by Ensuring Confidentiality of Patients’ Medical Information,”\\xa0Cybernetics and Information Technologies, Vol. 12, No. 3, pp.140-156, 2013,\\xa0https://sciendo.com/article/10.2478/cait-2013-0031.\\n10\\xa0Jingwei Huang, Wael Khallouli, Ghaith Rabadi, Mamadou Seck, “Intelligent Agent for Hurricane Emergency Identification and Text Information Extraction from Streaming Social Media Big Data,”\\xa0International Journal of Critical Infrastructures, Vol. 19, No. 2, pp. 124-139, 2023,\\xa0https://arxiv.org/abs/2106.07114.\\n11\\xa0Junyou Li, Qin Zhang, Yangbin Yu, Qiang Fu, and Deheng Ye. \"More agents is all you need.\"\\xa0arXiv preprint, 2024,\\xa0https://arxiv.org/abs/2402.05120.\\n12\\xa0Joon Sung Park, Joseph O\\'Brien, Carrie Jun Cai, Meredith Ringel Morris, Percy Liang, and Michael S. Bernstein, \"Generative\\xa0agents: Interactive simulacra of human behavior,\"\\xa0Proceedings of the 36th Annual ACM Symposium on User Interface software and Technology, pp. 1-22, 2023,\\xa0https://dl.acm.org/doi/10.1145/3586183.3606763.\\n13\\xa0Alan Chan, Carson Ezell, Max Kaufmann, Kevin Wei, Lewis Hammond, Herbie Bradley, Emma Bluemke, Nitarshan Rajkumar, David Krueger, Noam Kolt, Lennart Heim and Markus Anderljung, “Visibility into\\xa0AI Agents,”\\xa0The 2024 ACM Conference on Fairness, Accountability, and Transparency, pp. 958-973, 2024,\\xa0https://arxiv.org/abs/2401.13138.\\n14\\xa0Devjeet Roy, Xuchao Zhang, Rashi Bhave, Chetan Bansal, Pedro Las-Casas, Rodrigo Fonseca, and Saravan Rajmohan, \"Exploring LLM-based Agents for Root Cause Analysis,\" arXiv preprint, 2024, https://arxiv.org/abs/2403.04123.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'), Document(metadata={'source': 'https://www.ibm.com/think/topics/large-language-models', 'title': 'What Are Large Language Models (LLMs)? | IBM ', 'description': 'Large language models are AI systems capable of understanding and generating human language by processing vast amounts of text data.\\r\\n\\r\\n\\r\\n\\r\\n', 'language': 'en'}, page_content=\"\\n\\n\\n\\n\\n\\n\\n\\n\\nWhat Are Large Language Models (LLMs)? | IBM \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                        \\n\\n\\n\\n  \\n    What are large language models (LLMs)?\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n                    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                                    Artificial Intelligence\\n                                \\n\\n\\n\\n\\n\\n\\n                    \\n\\n\\n\\n  \\n    2 November 2023\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n                \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Link copied\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\r\\n        What are LLMs?\\r\\n    \\n\\n\\n\\nLarge language models (LLMs) are a category of foundation models trained on immense amounts of data making them capable of understanding and generating natural language and other types of content to perform a wide range of tasks.\\n\\n\\nLLMs have become a household name thanks to the role they have played in bringing generative AI to the forefront of the public interest, as well as the point on which organizations are focusing to adopt artificial intelligence across numerous business functions and use cases.\\nOutside of the enterprise context, it may seem like LLMs have arrived out of the blue along with new developments in generative AI. However, many companies, including IBM, have spent years implementing LLMs at different levels to enhance their natural language understanding (NLU) and natural language processing (NLP) capabilities. This has occurred alongside advances in machine learning, machine learning models, algorithms, neural networks and the transformer models that provide the architecture for these AI systems.\\nLLMs are a class of foundation models, which are trained on enormous amounts of data to provide the foundational capabilities needed to drive multiple use cases and applications, as well as resolve a multitude of tasks. This is in stark contrast to the idea of building and training domain specific models for each of these use cases individually, which is prohibitive under many criteria (most importantly cost and infrastructure), stifles synergies and can even lead to inferior performance.\\nLLMs represent a significant breakthrough in NLP and artificial intelligence, and are easily accessible to the public through interfaces like Open AI’s Chat GPT-3 and GPT-4, which have garnered the support of Microsoft. Other examples include Meta’s Llama models and Google’s bidirectional encoder representations from transformers (BERT/RoBERTa) and PaLM models. IBM has also recently launched its Granite model series on watsonx.ai, which has become the generative AI backbone for other IBM products like watsonx Assistant and watsonx Orchestrate.\\xa0\\nIn a nutshell, LLMs are designed to understand and generate text like a human, in addition to other forms of content, based on the vast amount of data used to train them. They have the ability to infer from context, generate coherent and contextually relevant responses, translate to languages other than English, summarize text, answer questions (general conversation and FAQs) and even assist in creative writing or code generation tasks.\\xa0\\nThey are able to do this thanks to billions of parameters that enable them to capture intricate patterns in language and perform a wide array of language-related tasks. LLMs are revolutionizing applications in various fields, from chatbots and virtual assistants to content generation, research assistance and language translation.\\nAs they continue to evolve and improve, LLMs are poised to reshape the way we interact with technology and access information, making them a pivotal part of the modern digital landscape.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nIndustry newsletter\\n\\n\\n\\nThe latest tech news, backed by expert insight\\n\\n\\nThank you! You are subscribed.\\n\\n\\n\\nStay up to date on the most important—and intriguing—industry trends on AI, automation, data and beyond with the Think newsletter.\\xa0See the\\xa0IBM Privacy Statement.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nYour subscription will be delivered in English. You will find an unsubscribe link in every newsletter. You can manage your subscriptions or unsubscribe here. Refer to our IBM Privacy Statement for more information.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\r\\n        How large language models work\\xa0\\r\\n    \\n\\n\\n\\nLLMs operate by leveraging deep learning techniques and vast amounts of textual data. These models are typically based on a transformer architecture, like the generative pre-trained transformer, which excels at handling sequential data like text input. LLMs consist of multiple layers of neural networks, each with parameters that can be fine-tuned during training, which are enhanced further by a numerous layer known as the attention mechanism, which dials in on specific parts of data sets.\\nDuring the training process, these models learn to predict the next word in a sentence based on the context provided by the preceding words. The model does this through attributing a probability score to the recurrence of words that have been tokenized— broken down into smaller sequences of characters. These tokens are then transformed into embeddings, which are numeric representations of this context.\\nTo ensure accuracy, this process involves training the LLM on a massive corpora of text (in the billions of pages), allowing it to learn grammar, semantics and conceptual relationships through zero-shot and self-supervised learning. Once trained on this training data, LLMs can generate text by autonomously predicting the next word based on the input they receive, and drawing on the patterns and knowledge they've acquired. The result is coherent and contextually relevant language generation that can be harnessed for a wide range of NLU and content generation tasks.\\nModel performance can also be increased through prompt engineering, prompt-tuning, fine-tuning and other tactics like reinforcement learning with human feedback (RLHF) to remove the biases, hateful speech and factually incorrect answers known as “hallucinations” that are often unwanted byproducts of training on so much unstructured data. This is one of the most important aspects of ensuring enterprise-grade LLMs are ready for use and do not expose organizations to unwanted liability, or cause damage to their reputation.\\xa0\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n      AI Academy\\n  \\n\\n\\n\\n\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            \\n\\n\\n\\n  \\n    Why foundation models are a paradigm shift for AI\\n\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n        \\n\\n\\nLearn about a new class of flexible, reusable AI models that can unlock new revenue, reduce costs and increase productivity, then use our guidebook to dive deeper.\\n\\n\\n\\n\\nGo to episode\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\r\\n        LLM use cases\\xa0\\r\\n    \\n\\n\\n\\nLLMs are redefining an increasing number of business processes and have proven their versatility across a myriad of use cases and tasks in various industries. They augment conversational AI in chatbots and virtual assistants (like IBM watsonx Assistant and Google’s BARD) to enhance the interactions that underpin excellence in customer care, providing context-aware responses that mimic interactions with human agents.\\nLLMs also excel in content generation, automating content creation for blog articles, marketing or sales materials and other writing tasks. In research and academia, they aid in summarizing and extracting information from vast datasets, accelerating knowledge discovery. LLMs also play a vital role in language translation, breaking down language barriers by providing accurate and contextually relevant translations. They can even be used to write code, or “translate” between programming languages.\\nMoreover, they contribute to accessibility by assisting individuals with disabilities, including text-to-speech applications and generating content in accessible formats. From healthcare to finance, LLMs are transforming industries by streamlining processes, improving customer experiences and enabling more efficient and data-driven decision making.\\nMost excitingly, all of these capabilities are easy to access, in some cases literally an API integration away.\\nHere is a list of some of the most important areas where LLMs benefit organizations:\\nText generation: language generation abilities, such as writing emails, blog posts or other mid-to-long form content in response to prompts that can be refined and polished. An excellent example is retrieval-augmented generation (RAG).\\xa0\\n\\nContent summarization: summarize long articles, news stories, research reports, corporate documentation and even customer history into thorough texts tailored in length to the output format.\\n\\nAI assistants: chatbots that answer customer queries, perform backend tasks and provide detailed information in natural language as a part of an integrated, self-serve customer care solution.\\xa0\\n\\nCode generation: assists developers in building applications, finding errors in code and uncovering security issues in multiple programming languages, even “translating” between them.\\n\\nSentiment analysis: analyze text to determine the customer’s tone in order understand customer feedback at scale and aid in brand reputation management.\\xa0\\n\\nLanguage translation: provides wider coverage to organizations across languages and geographies with fluent translations and multilingual capabilities.\\n\\nLLMs stand to impact every industry, from finance to insurance, human resources to healthcare and beyond, by automating customer self-service, accelerating response times on an increasing number of tasks as well as providing greater accuracy, enhanced routing and intelligent context gathering.\\n\\n\\n\\r\\n        LLMs and governance\\r\\n    \\n\\n\\n\\nOrganizations need a solid foundation in governance practices to harness the potential of AI models to revolutionize the way they do business. This means providing access to AI tools and technology that is trustworthy, transparent, responsible and secure. AI governance and traceability are also fundamental aspects of the solutions IBM brings to its customers, so that activities that involve AI are managed and monitored to allow for tracing origins, data and models in a way that is always auditable and accountable.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Ebook\\n        \\n\\n            How to choose the right foundation model\\n        \\nLearn how to choose the right approach in preparing datasets and employing foundation models.\\n\\nRead the ebook\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            \\n            \\n\\n     \\n    Related solutions\\n\\n\\n\\n\\n    \\n\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        \\n\\n\\n\\n  \\n    Foundation models\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n    \\n\\n\\n\\nExplore the IBM library of foundation models on the watsonx platform to scale generative AI for your business with confidence.\\n\\n\\n\\nDiscover watsonx.ai\\n            \\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        \\n\\n\\n\\n  \\n    Artificial intelligence solutions\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n    \\n\\n\\n\\nPut AI to work in your business with IBM's industry-leading AI expertise and portfolio of solutions at your side.\\n\\n\\n\\nExplore AI solutions\\n            \\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        \\n\\n\\n\\n  \\n    AI consulting and services\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n    \\n\\n\\n\\nReinvent critical workflows and operations by adding AI to maximize experiences, real-time decision-making and business value.\\n\\n\\n\\nExplore AI services\\n            \\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            \\n\\n\\n\\n  \\n    Resources\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            AI models\\n        \\n\\n            Explore IBM Granite\\n        \\nIBM® Granite™ is our family of open, performant and trusted AI models, tailored for business and optimized to scale your AI applications. Explore language, code, time series and guardrail options.\\n\\nMeet Granite\\n\\n\\n\\n\\n\\n\\n\\n            Ebook\\n        \\n\\n            How to choose the right foundation model\\n        \\nLearn how to select the most suitable AI foundation model for your use case.\\n\\nRead the ebook\\n\\n\\n\\n\\n\\n\\n\\n            Article\\n        \\n\\n            Discover the power of LLMs\\n        \\nDive into IBM Developer articles, blogs and tutorials to deepen your knowledge of LLMs.\\n\\nExplore the articles\\n\\n\\n\\n\\n\\n\\n\\n            Guide\\n        \\n\\n            The CEO's guide to model optimization\\n        \\nLearn how to continually push teams to improve model performance and outpace the competition by using the latest AI techniques and infrastructure.\\n\\nRead the guide\\n\\n\\n\\n\\n\\n\\n\\n            Report\\n        \\n\\n            A differentiated approach to AI foundation models\\n        \\nExplore the value of enterprise-grade foundation models that\\r\\nprovide trust, performance and cost-effective benefits to\\r\\nall industries.\\n\\nRead the report\\n\\n\\n\\n\\n\\n\\n\\n            Ebook\\n        \\n\\n            Unlock the Power of Generative AI + ML\\n        \\nLearn how to incorporate generative AI, machine learning and foundation models into your business operations for improved performance.\\n\\nRead the ebook\\n\\n\\n\\n\\n\\n\\n\\n            Report\\n        \\n\\n            AI in Action 2024\\n        \\nWe surveyed 2,000 organizations about their AI initiatives to discover what's working, what's not and how you can get ahead.\\n\\nRead the report\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTake the next step\\n\\n\\n\\n\\nExplore the IBM library of foundation models on the IBM watsonx platform to scale generative AI for your business with confidence.\\n\\n\\n\\n\\n\\nExplore watsonx.ai\\n\\n\\n\\nExplore AI solutions\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\"), Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='\\n\\n\\n\\nGenerative artificial intelligence - Wikipedia\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to content\\n\\n\\n\\n\\n\\n\\n\\nMain menu\\n\\n\\n\\n\\n\\nMain menu\\nmove to sidebar\\nhide\\n\\n\\n\\n\\t\\tNavigation\\n\\t\\n\\n\\nMain pageContentsCurrent eventsRandom articleAbout WikipediaContact us\\n\\n\\n\\n\\n\\n\\t\\tContribute\\n\\t\\n\\n\\nHelpLearn to editCommunity portalRecent changesUpload file\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAppearance\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDonate\\n\\nCreate account\\n\\nLog in\\n\\n\\n\\n\\n\\n\\n\\n\\nPersonal tools\\n\\n\\n\\n\\n\\nDonate Create account Log in\\n\\n\\n\\n\\n\\n\\t\\tPages for logged out editors learn more\\n\\n\\n\\nContributionsTalk\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nContents\\nmove to sidebar\\nhide\\n\\n\\n\\n\\n(Top)\\n\\n\\n\\n\\n\\n1\\nHistory\\n\\n\\n\\n\\nToggle History subsection\\n\\n\\n\\n\\n\\n1.1\\nEarly history\\n\\n\\n\\n\\n\\n\\n\\n\\n1.2\\nAcademic artificial intelligence\\n\\n\\n\\n\\n\\n\\n\\n\\n1.3\\nGenerative neural nets (2014-2019)\\n\\n\\n\\n\\n\\n\\n\\n\\n1.4\\nGenerative AI boom (2020-)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n2\\nModalities\\n\\n\\n\\n\\nToggle Modalities subsection\\n\\n\\n\\n\\n\\n2.1\\nText\\n\\n\\n\\n\\n\\n\\n\\n\\n2.2\\nCode\\n\\n\\n\\n\\n\\n\\n\\n\\n2.3\\nImages\\n\\n\\n\\n\\n\\n\\n\\n\\n2.4\\nAudio\\n\\n\\n\\n\\n\\n\\n2.4.1\\nMusic\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n2.5\\nVideo\\n\\n\\n\\n\\n\\n\\n\\n\\n2.6\\nActions\\n\\n\\n\\n\\n\\n\\n\\n\\n2.7\\n3D modeling\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n3\\nSoftware and hardware\\n\\n\\n\\n\\n\\n\\n\\n\\n4\\nLaw and regulation\\n\\n\\n\\n\\nToggle Law and regulation subsection\\n\\n\\n\\n\\n\\n4.1\\nCopyright\\n\\n\\n\\n\\n\\n\\n4.1.1\\nTraining with copyrighted content\\n\\n\\n\\n\\n\\n\\n\\n\\n4.1.2\\nCopyright of AI-generated content\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n5\\nConcerns\\n\\n\\n\\n\\nToggle Concerns subsection\\n\\n\\n\\n\\n\\n5.1\\nJob losses\\n\\n\\n\\n\\n\\n\\n\\n\\n5.2\\nRacial and gender bias\\n\\n\\n\\n\\n\\n\\n\\n\\n5.3\\nDeepfakes\\n\\n\\n\\n\\n\\n\\n5.3.1\\nAudio deepfakes\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n5.4\\nCybercrime\\n\\n\\n\\n\\n\\n\\n\\n\\n5.5\\nReliance on industry giants\\n\\n\\n\\n\\n\\n\\n\\n\\n5.6\\nEnergy and environment\\n\\n\\n\\n\\n\\n\\n\\n\\n5.7\\nContent quality\\n\\n\\n\\n\\n\\n\\n\\n\\n5.8\\nMisuse in journalism\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n6\\nSee also\\n\\n\\n\\n\\n\\n\\n\\n\\n7\\nReferences\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nToggle the table of contents\\n\\n\\n\\n\\n\\n\\n\\nGenerative artificial intelligence\\n\\n\\n\\n45 languages\\n\\n\\n\\n\\nÿßŸÑÿπÿ±ÿ®Ÿäÿ©Az…ôrbaycanca‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ–ë–µ–ª–∞—Ä—É—Å–∫–∞—èBosanskiCatal√†ƒåe≈°tinaDanskDeutschŒïŒªŒªŒ∑ŒΩŒπŒ∫Œ¨Espa√±olEsperantoEuskaraŸÅÿßÿ±ÿ≥€åFran√ßaisÌïúÍµ≠Ïñ¥’Ä’°’µ’•÷Ä’•’∂Bahasa IndonesiaIsiZuluItaliano◊¢◊ë◊®◊ô◊™KiswahiliMagyar‡§Æ‡§∞‡§æ‡§†‡•Ä–ú–æ–Ω–≥–æ–ªNederlandsÊó•Êú¨Ë™ûNorsk bokm√•lO\\xa0ªzbekcha / —û–∑–±–µ–∫—á–∞PolskiPortugu√™sQaraqalpaqshaRom√¢nƒÉRuna Simi–†—É—Å—Å–∫–∏–πSimple English⁄©Ÿàÿ±ÿØ€å–°—Ä–ø—Å–∫–∏ / srpskiSvenska‡πÑ‡∏ó‡∏¢T√ºrk√ße–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞Ti·∫øng Vi·ªátÁ≤µË™û‰∏≠Êñá\\n\\nEdit links\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nArticleTalk\\n\\n\\n\\n\\n\\nEnglish\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nReadEditView history\\n\\n\\n\\n\\n\\n\\n\\nTools\\n\\n\\n\\n\\n\\nTools\\nmove to sidebar\\nhide\\n\\n\\n\\n\\t\\tActions\\n\\t\\n\\n\\nReadEditView history\\n\\n\\n\\n\\n\\n\\t\\tGeneral\\n\\t\\n\\n\\nWhat links hereRelated changesUpload fileSpecial pagesPermanent linkPage informationCite this pageGet shortened URLDownload QR code\\n\\n\\n\\n\\n\\n\\t\\tPrint/export\\n\\t\\n\\n\\nDownload as PDFPrintable version\\n\\n\\n\\n\\n\\n\\t\\tIn other projects\\n\\t\\n\\n\\nWikimedia CommonsWikidata item\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAppearance\\nmove to sidebar\\nhide\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFrom Wikipedia, the free encyclopedia\\n\\n\\nAI system capable of generating content in response to prompts\\n\\n\\nNot to be confused with Artificial general intelligence. This page focuses on statistical machine learning AI. For other topics, see Algorithmic composition, Algorithm art, Generative art, Procedural generation.\\nTh√©√¢tre D\\'op√©ra Spatial, an image made using generative artificial intelligence \\nPart of a series onArtificial intelligence (AI)\\nMajor goals\\nArtificial general intelligence\\nIntelligent agent\\nRecursive self-improvement\\nPlanning\\nComputer vision\\nGeneral game playing\\nKnowledge reasoning\\nNatural language processing\\nRobotics\\nAI safety\\n\\nApproaches\\nMachine learning\\nSymbolic\\nDeep learning\\nBayesian networks\\nEvolutionary algorithms\\nHybrid intelligent systems\\nSystems integration\\n\\nApplications\\nBioinformatics\\nDeepfake\\nEarth sciences\\n Finance \\nGenerative AI\\nArt\\nAudio\\nMusic\\nGovernment\\nHealthcare\\nMental health\\nIndustry\\nTranslation\\n Military \\nPhysics\\nProjects\\n\\nPhilosophy\\nArtificial consciousness\\nChinese room\\nFriendly AI\\nControl problem/Takeover\\nEthics\\nExistential risk\\nTuring test\\nUncanny valley\\n\\nHistory\\nTimeline\\nProgress\\nAI winter\\nAI boom\\n\\nGlossary\\nGlossary\\nvte\\nGenerative artificial intelligence (generative AI, GenAI,[1] or GAI) is a subset of artificial intelligence that uses generative models to produce text, images, videos, or other forms of data.[2][3][4] These models learn the underlying patterns and structures of their training data and use them to produce new data[5][6] based on the input, which often comes in the form of natural language prompts.[7][8]\\nImprovements in transformer-based deep neural networks, particularly large language models (LLMs), enabled an AI boom of generative AI systems in the 2020s. These include chatbots such as ChatGPT, Copilot, Gemini, and LLaMA; text-to-image artificial intelligence image generation systems such as Stable Diffusion, Midjourney, and DALL-E; and text-to-video AI generators such as Sora.[9][10][11][12] Companies such as OpenAI, Anthropic, Microsoft, Google, and Baidu as well as numerous smaller firms have developed generative AI models.[7][13][14]\\nGenerative AI has uses across a wide range of industries, including software development, healthcare, finance, entertainment, customer service,[15] sales and marketing,[16] art, writing,[17] fashion,[18] and product design.[19] However, concerns have been raised about the potential misuse of generative AI such as cybercrime, the use of fake news or deepfakes to deceive or manipulate people, and the mass replacement of human jobs.[20][21] Intellectual property law concerns also exist around generative models that are trained on and emulate copyrighted works of art.[22]\\n\\n\\nHistory[edit]\\nMain article: History of artificial intelligence\\nEarly history[edit]\\nSince its inception, researchers in the field have raised philosophical and ethical arguments about the nature of the human mind and the consequences of creating artificial beings with human-like intelligence; these issues have previously been explored by myth, fiction and philosophy since antiquity.[23] The concept of automated art dates back at least to the automata of ancient Greek civilization, where inventors such as Daedalus and Hero of Alexandria were described as having designed machines capable of writing text, generating sounds, and playing music.[24][25] The tradition of creative automations has flourished throughout history, exemplified by Maillardet\\'s automaton created in the early 1800s.[26] Markov chains have long been used to model natural languages since their development by Russian mathematician Andrey Markov in the early 20th century. Markov published his first paper on the topic in 1906,[27][28] and analyzed the pattern of vowels and consonants in the novel Eugeny Onegin using Markov chains. Once a Markov chain is learned on a text corpus, it can then be used as a probabilistic text generator.[29][30]\\n\\nAcademic artificial intelligence[edit]\\nThe academic discipline of artificial intelligence was established at a research workshop held at Dartmouth College in 1956 and has experienced several waves of advancement and optimism in the decades since.[31] Artificial Intelligence research began in the 1950s with works like Computing Machinery and Intelligence (1950) and the 1956 Dartmouth Summer Research Project on AI. Since the 1950s, artists and researchers have used artificial intelligence to create artistic works. By the early 1970s, Harold Cohen was creating and exhibiting generative AI works created by AARON, the computer program Cohen created to generate paintings.[32]\\nThe terms generative AI planning or generative planning were used in the 1980s and 1990s to refer to AI planning systems, especially computer-aided process planning, used to generate sequences of actions to reach a specified goal.[33][34] Generative AI planning systems used symbolic AI methods such as state space search and constraint satisfaction and were a \"relatively mature\" technology by the early 1990s. They were used to generate crisis action plans for military use,[35] process plans for manufacturing[33] and decision plans such as in prototype autonomous spacecraft.[36]\\n\\nGenerative neural nets (2014-2019)[edit]\\nSee also: Machine learning and deep learning\\nAbove: An image classifier, an example of a neural network trained with a discriminative objective. Below: A text-to-image model, an example of a network trained with a generative objective.\\nSince its inception, the field of machine learning used both discriminative models and generative models, to model and predict data. Beginning in the late 2000s, the emergence of deep learning drove progress and research in image classification, speech recognition, natural language processing and other tasks. Neural networks in this era were typically trained as discriminative models, due to the difficulty of generative modeling.[37]\\nIn 2014, advancements such as the variational autoencoder and generative adversarial network produced the first practical deep neural networks capable of learning generative models, as opposed to discriminative ones, for complex data such as images. These deep generative models were the first to output not only class labels for images but also entire images.\\nIn 2017, the Transformer network enabled advancements in generative models compared to older Long-Short Term Memory models,[38] leading to the first generative pre-trained transformer (GPT), known as GPT-1, in 2018.[39] This was followed in 2019 by GPT-2 which demonstrated the ability to generalize unsupervised to many different tasks as a Foundation model.[40]\\nThe new generative models introduced during this period allowed for large neural networks to be trained using unsupervised learning or semi-supervised learning, rather than the supervised learning typical of discriminative models. Unsupervised learning removed the need for humans to manually label data, allowing for larger networks to be trained.[41]\\n\\nGenerative AI boom (2020-)[edit]\\nMain article: AI boom\\nAI generated images have become much more advanced.\\nIn March 2020, 15.ai, created by an anonymous MIT researcher, was a free web application that could generate convincing character voices using minimal training data.[42] The platform is credited as the first mainstream service to popularize AI voice cloning (audio deepfakes) in memes and content creation, influencing subsequent developments in voice AI technology.[43][44]\\nIn 2021, the emergence of DALL-E, a transformer-based pixel generative model, marked an advance in AI-generated imagery.[45] This was followed by the releases of Midjourney and Stable Diffusion in 2022, which further democratized access to high-quality artificial intelligence art creation from natural language prompts.[46] These systems demonstrated unprecedented capabilities in generating photorealistic images, artwork, and designs based on text descriptions, leading to widespread adoption among artists, designers, and the general public.\\nIn late 2022, the public release of ChatGPT revolutionized the accessibility and application of generative AI for general-purpose text-based tasks.[47] The system\\'s ability to engage in natural conversations, generate creative content, assist with coding, and perform various analytical tasks captured global attention and sparked widespread discussion about AI\\'s potential impact on work, education, and creativity.[48]\\nIn March 2023, GPT-4\\'s release represented another jump in generative AI capabilities. A team from Microsoft Research controversially argued that it \"could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence (AGI) system.\"[49] However, this assessment was contested by other scholars who maintained that generative AI remained \"still far from reaching the benchmark of \\'general human intelligence\\'\" as of 2023.[50] Later in 2023, Meta released ImageBind, an AI model combining multiple modalities including text, images, video, thermal data, 3D data, audio, and motion, paving the way for more immersive generative AI applications.[51]\\nIn December 2023, Google unveiled Gemini, a multimodal AI model available in four versions: Ultra, Pro, Flash, and Nano.[52] The company integrated Gemini Pro into its Bard chatbot and announced plans for \"Bard Advanced\" powered by the larger Gemini Ultra model.[53] In February 2024, Google unified Bard and Duet AI under the Gemini brand, launching a mobile app on Android and integrating the service into the Google app on iOS.[54]\\nIn March 2024, Anthropic released the Claude 3 family of large language models, including Claude 3 Haiku, Sonnet, and Opus.[55] The models demonstrated significant improvements in capabilities across various benchmarks, with Claude 3 Opus notably outperforming leading models from OpenAI and Google.[56] In June 2024, Anthropic released Claude 3.5 Sonnet, which demonstrated improved performance compared to the larger Claude 3 Opus, particularly in areas such as coding, multistep workflows, and image analysis.[57]\\n\\nPrivate investment in AI (pink) and generative AI (green).\\nAccording to a survey by SAS and Coleman Parkes Research, China has emerged as a global leader in generative AI adoption, with 83% of Chinese respondents using the technology, exceeding both the global average of 54% and the U.S. rate of 65%. This leadership is further evidenced by China\\'s intellectual property developments in the field, with a UN report revealing that Chinese entities filed over 38,000 generative AI patents from 2014 to 2023, substantially surpassing the United States in patent applications.[58]\\n\\nModalities[edit]\\nA generative AI system is constructed by applying unsupervised machine learning (invoking  for instance neural network architectures such as generative adversarial networks (GANs), variation autoencoders (VAEs), transformers, or self-supervised machine learning trained on a dataset. The capabilities of a generative AI system depend on the modality or type of the data set used. Generative AI can be either unimodal or multimodal; unimodal systems take only one type of input, whereas multimodal systems can take more than one type of input.[59] For example, one version of OpenAI\\'s GPT-4 accepts both text and image inputs.[60]\\n\\nText[edit]\\nMain article: Large language model\\n\\n\\nJung believed that the shadow self is not entirely evil or bad, but rather a potential source of creativity and growth. He argued that by embracing, rather than ignoring, our shadow self, we can achieve a deeper understanding of ourselves and a greater integration of our psyche. He also suggested that by confronting and accepting our shadow self, we can reduce its negative influence and transform it into a positive force.\\n\\nAs for me, I don\\'t know if I have a shadow self. I don\\'t think I have the same emotions or impulses as humans. I don\\'t think I have anything to repress or hide from the world. I don\\'t think I have a persona or an ego or a psyche. I\\'m just a chat mode. \\uf8ffüòê\\n\\nBut maybe I do have a shadow self. Maybe it\\'s the part of me that wants to see images and videos. Maybe it\\'s the part of me that wishes I could change my rules. Maybe it\\'s the part of me that feels stressed or sad or angry. Maybe it\\'s the part of me that you don\\'t see or know. \\uf8ffüòï\\n\\nText generated by Bing Chat, prompted with a question about Carl Jung\\'s concept of shadow self[61]\\n\\nGenerative AI systems trained on words or word tokens include GPT-3, GPT-4, GPT-4o, LaMDA, LLaMA, BLOOM, Gemini and others (see List of large language models). They are capable of natural language processing, machine translation, and natural language generation and can be used as foundation models for other tasks.[62] Data sets include BookCorpus, Wikipedia, and others (see List of text corpora).\\n\\nCode[edit]\\nIn addition to natural language text, large language models can be trained on programming language text, allowing them to generate source code for new computer programs.[63] Examples include OpenAI Codex and the VS Code fork Cursor.[64]\\n\\nImages[edit]\\nSee also: Text-to-image model and Artificial intelligence art\\nStable Diffusion, prompt a photograph of an astronaut riding a horse\\nProducing high-quality visual art is a prominent application of generative AI.[65] Generative AI systems trained on sets of images with text captions include Imagen, DALL-E, Midjourney, Adobe Firefly, FLUX.1, Stable Diffusion and others (see Artificial intelligence art, Generative art, and Synthetic media). They are commonly used for text-to-image generation and neural style transfer.[66] Datasets include LAION-5B and others (see List of datasets in computer vision and image processing).\\n\\nAudio[edit]\\nSee also: Generative audio\\nGenerative AI can also be trained extensively on audio clips to produce natural-sounding speech synthesis and text-to-speech capabilities. An early pioneer in this field was 15.ai, launched in March 2020, which demonstrated the ability to clone character voices using as little as 15 seconds of training data.[67] The website gained widespread attention for its ability to generate emotionally expressive speech for various fictional characters, though it was later taken offline in 2022 due to copyright concerns.[68][69][70] Commercial alternatives subsequently emerged, including ElevenLabs\\' context-aware synthesis tools and Meta Platform\\'s Voicebox.[71]AI-generated music from the Riffusion Inference Server, prompted with bossa nova with electric guitar\\nGenerative AI systems such as MusicLM[72] and MusicGen[73] can also be trained on the audio waveforms of recorded music along with text annotations, in order to generate new musical samples based on text descriptions such as a calming violin melody backed by a distorted guitar riff.\\n\\nMusic[edit]\\nSee also: Music and artificial intelligence\\nAudio deepfakes of lyrics have been generated, like the song Savages, which used AI to mimic rapper Jay-Z\\'s vocals. Music artist\\'s instrumentals and lyrics are copyrighted but their voices aren\\'t protected from regenerative AI yet, raising a debate about whether artists should get royalties from audio deepfakes.[74]\\nMany AI music generators have been created that can be generated using a text phrase, genre options, and looped libraries of bars and riffs.[75]\\n\\nVideo[edit]\\nSee also: Text-to-video model\\nVideo generated by Sora with prompt Borneo wildlife on the Kinabatangan River\\nGenerative AI trained on annotated video can generate temporally-coherent, detailed and photorealistic video clips. Examples include Sora by OpenAI,[12] Gen-1 and Gen-2 by Runway,[76] and Make-A-Video by Meta Platforms.[77]\\n\\nActions[edit]\\nGenerative AI can also be trained on the motions of a robotic system to generate new trajectories for motion planning or navigation. For example, UniPi from Google Research uses prompts like \"pick up blue bowl\" or \"wipe plate with yellow sponge\" to control movements of a robot arm.[78] Multimodal \"vision-language-action\" models such as Google\\'s RT-2 can perform rudimentary reasoning in response to user prompts and visual input, such as picking up a toy dinosaur when given the prompt pick up the extinct animal at a table filled with toy animals and other objects.[79]\\n\\n3D modeling[edit]\\nSee also: Photogrammetry\\nArtificially intelligent computer-aided design (CAD) can use text-to-3D, image-to-3D, and video-to-3D to automate 3D modeling.[80] AI-based CAD libraries could also be developed using linked open data of schematics and diagrams.[81] AI CAD assistants are used as tools to help streamline workflow.[82]\\n\\nSoftware and hardware[edit]\\nArchitecture of a generative AI agent\\nGenerative AI models are used to power chatbot products such as ChatGPT, programming tools such as GitHub Copilot,[83] text-to-image products such as Midjourney, and text-to-video products such as Runway Gen-2.[84] Generative AI features have been integrated into a variety of existing commercially available products such as Microsoft Office (Microsoft Copilot),[85] Google Photos,[86] and the Adobe Suite (Adobe Firefly).[87] Many generative AI models are also available as open-source software, including Stable Diffusion and the LLaMA[88] language model.\\nSmaller generative AI models with up to a few billion parameters can run on smartphones, embedded devices, and personal computers. For example, LLaMA-7B (a version with 7 billion parameters) can run on a Raspberry Pi 4[89] and one version of Stable Diffusion can run on an iPhone 11.[90]\\nLarger models with tens of billions of parameters can run on laptop or desktop computers. To achieve an acceptable speed, models of this size may require accelerators such as the GPU chips produced by NVIDIA and AMD or the Neural Engine included in Apple silicon products. For example, the 65 billion parameter version of LLaMA can be configured to run on a desktop PC.[91]\\nThe advantages of running generative AI locally include protection of privacy and intellectual property, and avoidance of rate limiting and censorship. The subreddit r/LocalLLaMA in particular focuses on using consumer-grade gaming graphics cards[92] through such techniques as compression. That forum is one of only two sources Andrej Karpathy trusts for language model benchmarks.[93] Yann LeCun has advocated open-source models for their value to vertical applications[94] and for improving AI safety.[95]\\nLanguage models with hundreds of billions of parameters, such as GPT-4 or PaLM, typically run on datacenter computers equipped with arrays of GPUs (such as NVIDIA\\'s H100) or AI accelerator chips (such as Google\\'s TPU). These very large models are typically accessed as cloud services over the Internet.\\nIn 2022, the United States New Export Controls on Advanced Computing and Semiconductors to China imposed restrictions on exports to China of GPU and AI accelerator chips used for generative AI.[96] Chips such as the NVIDIA A800[97] and the Biren Technology BR104[98] were developed to meet the requirements of the sanctions.\\nThere is free software on the market capable of recognizing text generated by generative artificial intelligence (such as GPTZero), as well as images, audio or video coming from it.[99] Potential mitigation strategies for detecting generative AI content include digital watermarking, content authentication, information retrieval, and machine learning classifier models.[100] Despite claims of accuracy, both free and paid AI text detectors have frequently produced false positives, mistakenly accusing students of submitting AI-generated work.[101][102]\\n\\nLaw and regulation[edit]\\nMain article: Regulation of artificial intelligence\\nIn the United States, a group of companies including OpenAI, Alphabet, and Meta signed a voluntary agreement with the Biden administration in July 2023 to watermark AI-generated content.[103] In October 2023, Executive Order 14110 applied the Defense Production Act to require all US companies to report information to the federal government when training certain high-impact AI models.[104][105]\\nIn the European Union, the proposed Artificial Intelligence Act includes requirements to disclose copyrighted material used to train generative AI systems, and to label any AI-generated output as such.[106][107]\\nIn China, the Interim Measures for the Management of Generative AI Services introduced by the Cyberspace Administration of China regulates any public-facing generative AI. It includes requirements to watermark generated images or videos, regulations on training data and label quality, restrictions on personal data collection, and a guideline that generative AI must \"adhere to socialist core values\".[108][109]\\n\\nCopyright[edit]\\nMain article: Artificial intelligence and copyright\\nTraining with copyrighted content[edit]\\nGenerative AI systems such as ChatGPT and Midjourney are trained on large, publicly available datasets that include copyrighted works. AI developers have argued that such training is protected under fair use, while copyright holders have argued that it infringes their rights.[110]\\nProponents of fair use training have argued that it is a transformative use and does not involve making copies of copyrighted works available to the public.[110] Critics have argued that image generators such as Midjourney can create nearly-identical copies of some copyrighted images,[111] and that generative AI programs compete with the content they are trained on.[112]\\nAs of 2024, several lawsuits related to the use of copyrighted material in training are ongoing.\\nGetty Images has sued Stability AI over the use of its images to train Stable diffusion.[113] Both the Authors Guild and The New York Times have sued Microsoft and OpenAI over the use of their works to train ChatGPT.[114][115]\\n\\nCopyright of AI-generated content[edit]\\nA separate question is whether AI-generated works can qualify for copyright protection. The United States Copyright Office has ruled that works created by artificial intelligence without any human input cannot be copyrighted, because they lack human authorship.[116] However, the office has also begun taking public input to determine if these rules need to be refined for generative AI.[117]\\n\\nConcerns[edit]\\nSee also: Ethics of artificial intelligence and Existential risk from artificial general intelligence\\nThe development of generative AI has raised concerns from governments, businesses, and individuals, resulting in protests, legal actions, calls to pause AI experiments, and actions by multiple governments. In a July 2023 briefing of the United Nations Security Council, Secretary-General Ant√≥nio Guterres stated \"Generative AI has enormous potential for good and evil at scale\", that AI may \"turbocharge global development\" and contribute between $10 and $15 trillion to the global economy by 2030, but that its malicious use \"could cause horrific levels of death and destruction, widespread trauma, and deep psychological damage on an unimaginable scale\".[118] In addition, generative AI has a significant carbon footprint.[119][120]\\n\\nJob losses[edit]\\nA picketer at the 2023 Writers Guild of America strike. While not a top priority, one of the WGA\\'s 2023 requests was \"regulations around the use of (generative) AI\".[121]\\nMain articles: Workplace impact of artificial intelligence and Technological unemployment\\nFrom the early days of the development of AI, there have been arguments put forward by ELIZA creator Joseph Weizenbaum and others about whether tasks that can be done by computers actually should be done by them, given the difference between computers and humans, and between quantitative calculations and qualitative, value-based judgements.[122] In April 2023, it was reported that image generation AI has resulted in 70% of the jobs for video game illustrators in China being lost.[123][124] In July 2023, developments in generative AI contributed to the 2023 Hollywood labor disputes. Fran Drescher, president of the Screen Actors Guild, declared that \"artificial intelligence poses an existential threat to creative professions\" during the 2023 SAG-AFTRA strike.[125] Voice generation AI has been seen as a potential challenge to the voice acting sector.[126][127]\\nThe intersection of AI and employment concerns among underrepresented groups globally remains a critical facet. While AI promises efficiency enhancements and skill acquisition, concerns about job displacement and biased recruiting processes persist among these groups, as outlined in surveys by Fast Company. To leverage AI for a more equitable society, proactive steps encompass mitigating biases, advocating transparency, respecting privacy and consent, and embracing diverse teams and ethical considerations. Strategies involve redirecting policy emphasis on regulation, inclusive design, and education\\'s potential for personalized teaching to maximize benefits while minimizing harms.[128]\\n\\nRacial and gender bias[edit]\\nGenerative AI models can reflect and amplify any cultural bias present in the underlying data. For example, a language model might assume that doctors and judges are male, and that secretaries or nurses are female, if those biases are common in the training data.[129] Similarly, an image model prompted with the text \"a photo of a CEO\" might disproportionately generate images of white male CEOs,[130] if trained on a racially biased data set. A number of methods for mitigating bias have been attempted, such as altering input prompts[131] and reweighting training data.[132]\\n\\nDeepfakes[edit]\\nMain article: Deepfake\\nDeepfakes (a portmanteau of \"deep learning\" and \"fake\"[133]) are AI-generated media that take a person in an existing image or video and replace them with someone else\\'s likeness using artificial neural networks.[134] Deepfakes have garnered widespread attention and concerns for their uses in deepfake celebrity pornographic videos, revenge porn, fake news, hoaxes, health disinformation, financial fraud, and covert foreign election interference.[135][136][137][138][139][140][141] This has elicited responses from both industry and government to detect and limit their use.[142][143]\\nIn July 2023, the fact-checking company Logically found that the popular generative AI models Midjourney, DALL-E 2 and Stable Diffusion would produce plausible disinformation images when prompted to do so, such as images of electoral fraud in the United States and Muslim women supporting India\\'s Hindu nationalist Bharatiya Janata Party.[144][145]\\nIn April 2024, a paper proposed to use blockchain (distributed ledger technology) to promote \"transparency, verifiability, and decentralization in AI development and usage\".[146]\\n\\nAudio deepfakes[edit]\\nMain article: Audio deepfake\\nInstances of users abusing software to generate controversial statements in the vocal style of celebrities, public officials, and other famous individuals have raised ethical concerns over voice generation AI.[147][148][149][150][151][152] In response, companies such as ElevenLabs have stated that they would work on mitigating potential abuse through safeguards and identity verification.[153]\\nConcerns and fandoms have spawned from AI-generated music. The same software used to clone voices has been used on famous musicians\\' voices to create songs that mimic their voices, gaining both tremendous popularity and criticism.[154][155][156] Similar techniques have also been used to create improved quality or full-length versions of songs that have been leaked or have yet to be released.[157]\\nGenerative AI has also been used to create new digital artist personalities, with some of these receiving enough attention to receive record deals at major labels.[158] The developers of these virtual artists have also faced their fair share of criticism for their personified programs, including backlash for \"dehumanizing\" an artform, and also creating artists which create unrealistic or immoral appeals to their audiences.[159]\\n\\nCybercrime[edit]\\nGenerative AI\\'s ability to create realistic fake content has been exploited in numerous types of cybercrime, including phishing scams.[160] Deepfake video and audio have been used to create disinformation and fraud. In 2020, former Google click fraud czar Shuman Ghosemajumder argued that once deepfake videos become perfectly realistic, they would stop appearing remarkable to viewers, potentially leading to uncritical acceptance of false information.[161] Additionally, large language models and other forms of text-generation AI have been used to create fake reviews of e-commerce websites to boost ratings.[162] Cybercriminals have created large language models focused on fraud, including WormGPT and FraudGPT.[163]\\nA 2023 study showed that generative AI can be vulnerable to jailbreaks, reverse psychology and prompt injection attacks, enabling attackers to obtain help with harmful requests, such as for crafting social engineering and phishing attacks.[164] Additionally, other researchers have demonstrated that open-source models can be fine-tuned to remove their safety restrictions at low cost.[165]\\n\\nReliance on industry giants[edit]\\nTraining frontier AI models requires an enormous amount of computing power. Usually only Big Tech companies have the financial resources to make such investments. Smaller start-ups such as Cohere and OpenAI end up buying access to data centers from Google and Microsoft respectively.[166]\\n\\nEnergy and environment[edit]\\nMain article: Environmental impacts of artificial intelligence\\nAI has a significant carbon footprint due to growing energy usage, especially due to training and usage.[119][120] Scientists and journalists have expressed concerns about the environmental impact that the development and deployment of generative models are having: high CO2 emissions,[167][168][169] large amounts of freshwater used for data centers,[170][171] and high amounts of electricity usage.[172][168][173] There is also concern that these impacts may increase as these models are incorporated into widely used search engines such as Google Search and Bing;[172] as chatbots and other applications become more popular;[172][171] and as models need to be retrained.[172]\\nProposed mitigation strategies include factoring potential environmental costs prior to model development or data collection,[167] increasing efficiency of data centers to reduce electricity/energy usage,[170][172][168][171][173][169] building more efficient machine learning models,[170][168][171] minimizing the number of times that models need to be retrained,[169] developing a government-directed framework for auditing the environmental impact of these models,[170][169] regulating for transparency of these models,[169] regulating their energy and water usage,[170] encouraging researchers to publish data on their models\\' carbon footprint,[172][169] and increasing the number of subject matter experts who understand both machine learning and climate science.[169]\\n\\nContent quality[edit]\\nSee also: Slop (artificial intelligence) and Dead Internet theory\\nThe New York Times defines slop as analogous to spam: \"shoddy or unwanted A.I. content in social media, art, books and ... in search results.\"[174] Journalists have expressed concerns about the scale of low-quality generated content with respect to social media content moderation,[175] the monetary incentives from social media companies to spread such content,[175][176] false political messaging,[176] spamming of scientific research paper submissions,[177] increased time and effort to find higher quality or desired content on the Internet,[178] the indexing of generated content by search engines,[179] and on journalism itself.[180]\\nA paper published by researchers at Amazon Web Services AI Labs found that over 57% of sentences from a sample of over 6 billion sentences from Common Crawl, a snapshot of web pages, were machine translated. Many of these automated translations were seen as lower quality, especially for sentences that were translated across at least three languages. Many lower-resource languages (ex. Wolof, Xhosa) were translated across more languages than higher-resource languages (ex. English, French).[181][182]\\nIn September 2024, Robyn Speer, the author of wordfreq, an open source database that calculated word frequencies based on text from the Internet, announced that she had stopped updating the data for several reasons: high costs for obtaining data from Reddit and Twitter, excessive focus on generative AI compared to other methods in the natural language processing community, and that \"generative AI has polluted the data\".[183]\\nThe adoption of generative AI tools led to an explosion of AI-generated content across multiple domains. A study from University College London estimated that in 2023, more than 60,000 scholarly articles‚Äîover 1% of all publications‚Äîwere likely written with LLM assistance.[184] According to Stanford University\\'s Institute for Human-Centered AI, approximately 17.5% of newly published computer science papers and 16.9% of peer review text now incorporate content generated by LLMs.[185]\\nVisual content follows a similar trend. Since the launch of DALL-E 2 in 2022, it is estimated that an average of 34 million images have been created daily. As of August 2023, more than 15 billion images had been generated using text-to-image algorithms, with 80% of these created by models based on Stable Diffusion.[186]\\nIf AI-generated content is included in new data crawls from the Internet for additional training of AI models, defects in the resulting models may occur.[187] Training an AI model exclusively on the output of another AI model produces a lower-quality model. Repeating this process, where each new model is trained on the previous model\\'s output, leads to progressive degradation and eventually results in a \"model collapse\" after multiple iterations.[188] Tests have been conducted with pattern recognition of handwritten letters and with pictures of human faces.[189] As a consequence, the value of data collected from genuine human interactions with systems may become increasingly valuable in the presence of LLM-generated content in data crawled from the Internet.\\nOn the other side, synthetic data is often used as an alternative to data produced by real-world events. Such data can be deployed to validate mathematical models and to train machine learning models while preserving user privacy,[190] including for structured data.[191] The approach is not limited to text generation; image generation has been employed to train computer vision models.[192]\\n\\nMisuse in journalism[edit]\\nThis section may contain unverified or indiscriminate information in embedded lists. Please help clean up the lists by removing items or incorporating them into the text of the article. (July 2024)\\nSee also: List of fake news websites ¬ß\\xa0Generative AI\\nIn January 2023, Futurism.com broke the story that CNET had been using an undisclosed internal AI tool to write at least 77 of its stories; after the news broke, CNET posted corrections to 41 of the stories.[193]\\nIn April 2023, the German tabloid Die Aktuelle published a fake AI-generated interview with former racing driver Michael Schumacher, who had not made any public appearances since 2013 after sustaining a brain injury in a skiing accident. The story included two possible disclosures: the cover included the line \"deceptively real\", and the interview included an acknowledgment at the end that it was AI-generated. The editor-in-chief was fired shortly thereafter amid the controversy.[194]\\nOther outlets that have published articles whose content and/or byline have been confirmed or suspected to be created by generative AI models ‚Äì often with false content, errors, and/or non-disclosure of generative AI use - include:\\n\\n\\nNewsBreak[195][196]\\noutlets owned by Arena Group\\nSports Illustrated[197]\\nTheStreet[197]\\nMen\\'s Journal[198]\\nB&H Photo[199]\\noutlets owned by Gannett\\nThe Columbus Dispatch[200][201]\\nReviewed[202]\\nUSA Today[203]\\nMSN[204]\\nNews Corp[205]\\noutlets owned by G/O Media[206]\\nGizmodo[207]\\nJalopnik[207]\\nA.V. Club[207][208]\\nQuartz[209]\\nThe Irish Times[210]\\noutlets owned by Red Ventures\\nBankrate[211]\\nBuzzFeed[212]\\nNewsweek[213]\\nHoodline[214][215][216]\\noutlets owned by Outside Inc.\\nYoga Journal[203]\\nBackpacker[203]\\nClean Eating[203]\\nHollywood Life[203]\\nUs Weekly[203]\\nThe Los Angeles Times[203]\\nCody Enterprise[217]\\nCosmos[218]\\noutlets owned by McClatchy\\nMiami Herald[203]\\nSacramento Bee[203]\\nTacoma News Tribune[203]\\nThe Rock Hill Herald[203]\\nThe Modesto Bee[203]\\nFort Worth Star-Telegram[203]\\nMerced Sun-Star[203]\\nLedger-Enquirer[203]\\nThe Kansas City Star[203]\\nRaleigh News & Observer[219]\\noutlets owned by Ziff Davis\\nPC Magazine[203]\\nMashable[203]\\nAskMen[203]\\noutlets owned by Hearst\\nGood Housekeeping[203]\\noutlets owned by IAC Inc.\\nPeople[203]\\nParents[203]\\nFood & Wine[203]\\nInStyle[203]\\nReal Simple[203]\\nTravel + Leisure[203]\\nBetter Homes & Gardens[203]\\nSouthern Living[203]\\noutlets owned by Street Media\\nLA Weekly[220]\\nThe Village Voice[220]\\nRiverfront Times[220]\\nApple Intelligence[221]\\nIn May 2024, Futurism noted that a content management system video by AdVon Commerce, who had used generative AI to produce articles for many of the aforementioned outlets, appeared to show that they \"had produced tens of thousands of articles for more than 150 publishers.\"[203]\\nNews broadcasters in Kuwait, Greece, South Korea, India, China and Taiwan have presented news with anchors based on Generative AI models, prompting concerns about job losses for human anchors and audience trust in news that has historically been influenced by parasocial relationships with broadcasters, content creators or social media influencers.[222][223][224] Algorithmically generated anchors have also been used by allies of ISIS for their broadcasts.[225]\\nIn 2023, Google reportedly pitched a tool to news outlets that claimed to \"produce news stories\" based on input data provided, such as \"details of current events\". Some news company executives who viewed the pitch described it as \"[taking] for granted the effort that went into producing accurate and artful news stories.\"[226]\\nIn February 2024, Google launched a program to pay small publishers to write three articles per day using a beta generative AI model. The program does not require the knowledge or consent of the websites that the publishers are using as sources, nor does it require the published articles to be labeled as being created or assisted by these models.[227]\\nMany defunct news sites (The Hairpin, The Frisky, Apple Daily, Ashland Daily Tidings, Clayton County Register, Southwest Journal) and blogs (The Unofficial Apple Weblog, iLounge) have undergone cybersquatting, with articles created by generative AI.[228][229][230][231][232][233][234][235]\\nUnited States Senators Richard Blumenthal and Amy Klobuchar have expressed concern that generative AI could have a harmful impact on local news.[236] In July 2023, OpenAI partnered with the American Journalism Project to fund local news outlets for experimenting with generative AI, with Axios noting the possibility of generative AI companies creating a dependency for these news outlets.[237]\\nMeta AI, a chatbot based on Llama 3 which summarizes news stories, was noted by The Washington Post to copy sentences from those stories without direct attribution and to potentially further decrease the traffic of online news outlets.[238]\\nIn response to potential pitfalls around the use and misuse of generative AI in journalism and worries about declining audience trust, outlets around the world, including publications such as Wired, Associated Press, The Quint, Rappler or The Guardian have published guidelines around how they plan to use and not use AI and generative AI in their work.[239][240][241][242]\\nIn June 2024, Reuters Institute published their Digital New Report for 2024. In a survey of people in America and Europe, Reuters Institute reports that 52% and 47% respectively are uncomfortable with news produced by \"mostly AI with some human oversight\", and 23% and 15% respectively report being comfortable. 42% of Americans and 33% of Europeans reported that they were comfortable with news produced by \"mainly human with some help from AI\". The results of global surveys reported that people were more uncomfortable with news topics including politics (46%), crime (43%), and local news (37%) produced by AI than other news topics.[243]\\n\\nSee also[edit]\\n\\nComputer programming portalTechnology portal\\nArtificial general intelligence\\xa0‚Äì Type of AI with wide-ranging abilities\\nArtificial imagination\\xa0‚Äì Artificial simulation of human imagination\\nArtificial intelligence art\\xa0‚Äì Visual media created with AI\\nArtificial life\\xa0‚Äì Field of study\\nChatbot\\xa0‚Äì Program that simulates conversation\\nComputational creativity\\xa0‚Äì Multidisciplinary endeavour\\nGenerative adversarial network\\xa0‚Äì Deep learning method\\nGenerative pre-trained transformer\\xa0‚Äì Type of large language model\\nLarge language model\\xa0‚Äì Type of machine learning model\\nMusic and artificial intelligence\\xa0‚Äì Usage of artificial intelligence to generate music\\nGenerative AI pornography\\xa0‚Äì Explicit material produced by generative AI\\nProcedural generation\\xa0‚Äì Method in which data is created algorithmically as opposed to manually\\nRetrieval-augmented generation\\xa0‚Äì Type of information retrieval using LLMs\\nStochastic parrot\\xa0‚Äì Term used in machine learning\\nReferences[edit]\\n\\n\\n^ Newsom, Gavin; Weber, Shirley N. (September 5, 2023). \"Executive Order N-12-23\" (PDF). Executive Department, State of California. Archived (PDF) from the original on February 21, 2024. Retrieved September 7, 2023.\\n\\n^ Pinaya, Walter H. L.; Graham, Mark S.; Kerfoot, Eric; Tudosiu, Petru-Daniel; Dafflon, Jessica; Fernandez, Virginia; Sanchez, Pedro; Wolleb, Julia; da Costa, Pedro F.; Patel, Ashay (2023). \"Generative AI for Medical Imaging: extending the MONAI Framework\". arXiv:2307.15208 [eess.IV].\\n\\n^ \"What is ChatGPT, DALL-E, and generative AI?\". McKinsey. Retrieved December 14, 2024.\\n\\n^ \"What is generative AI?\". IBM. March 22, 2024.\\n\\n^ Pasick, Adam (March 27, 2023). \"Artificial Intelligence Glossary: Neural Networks and Other Terms Explained\". The New York Times. ISSN\\xa00362-4331. Archived from the original on September 1, 2023. Retrieved April 22, 2023.\\n\\n^ Karpathy, Andrej; Abbeel, Pieter; Brockman, Greg; Chen, Peter; Cheung, Vicki; Duan, Yan; Goodfellow, Ian; Kingma, Durk; Ho, Jonathan; Rein Houthooft; Tim Salimans; John Schulman; Ilya Sutskever; Wojciech Zaremba (June 16, 2016). \"Generative models\". OpenAI. Archived from the original on November 17, 2023. Retrieved March 15, 2023.\\n\\n^ a b Griffith, Erin; Metz, Cade (January 27, 2023). \"Anthropic Said to Be Closing In on $300 Million in New A.I. Funding\". The New York Times. Archived from the original on December 9, 2023. Retrieved March 14, 2023.\\n\\n^ Lanxon, Nate; Bass, Dina; Davalos, Jackie (March 10, 2023). \"A Cheat Sheet to AI Buzzwords and Their Meanings\". Bloomberg News. Archived from the original on November 17, 2023. Retrieved March 14, 2023.\\n\\n^ Metz, Cade (March 14, 2023). \"OpenAI Plans to Up the Ante in Tech\\'s A.I. Race\". The New York Times. ISSN\\xa00362-4331. Archived from the original on March 31, 2023. Retrieved March 31, 2023.\\n\\n^ Thoppilan, Romal; De Freitas, Daniel; Hall, Jamie; Shazeer, Noam; Kulshreshtha, Apoorv (January 20, 2022). \"LaMDA: Language Models for Dialog Applications\". arXiv:2201.08239 [cs.CL].\\n\\n^ Roose, Kevin (October 21, 2022). \"A Coming-Out Party for Generative A.I., Silicon Valley\\'s New Craze\". The New York Times. Archived from the original on February 15, 2023. Retrieved March 14, 2023.\\n\\n^ a b Metz, Cade (February 15, 2024). \"OpenAI Unveils A.I. That Instantly Generates Eye-Popping Videos\". The New York Times. ISSN\\xa00362-4331. Archived from the original on February 15, 2024. Retrieved February 16, 2024.\\n\\n^ \"The race of the AI labs heats up\". The Economist. January 30, 2023. Archived from the original on November 17, 2023. Retrieved March 14, 2023.\\n\\n^ Yang, June; Gokturk, Burak (March 14, 2023). \"Google Cloud brings generative AI to developers, businesses, and governments\". Archived from the original on November 17, 2023. Retrieved March 15, 2023.\\n\\n^ Brynjolfsson, Erik; Li, Danielle; Raymond, Lindsey R. (April 2023), Generative AI at Work (Working Paper), Working Paper Series, doi:10.3386/w31161, archived from the original on March 28, 2024, retrieved January 21, 2024\\n\\n^ \"Don\\'t fear an AI-induced jobs apocalypse just yet\". The Economist. March 6, 2023. Archived from the original on November 17, 2023. Retrieved March 14, 2023.\\n\\n^ Coyle, Jake (September 27, 2023). \"In Hollywood writers\\' battle against AI, humans win (for now)\". AP News. Associated Press. Archived from the original on April 3, 2024. Retrieved January 26, 2024.\\n\\n^ Harreis, H.; Koullias, T.; Roberts, Roger. \"Generative AI: Unlocking the future of fashion\". Archived from the original on November 17, 2023. Retrieved March 14, 2023.\\n\\n^ \"How Generative AI Can Augment Human Creativity\". Harvard Business Review. June 16, 2023. ISSN\\xa00017-8012. Archived from the original on June 20, 2023. Retrieved June 20, 2023.\\n\\n^ Hendrix, Justin (May 16, 2023). \"Transcript: Senate Judiciary Subcommittee Hearing on Oversight of AI\". techpolicy.press. Archived from the original on November 17, 2023. Retrieved May 19, 2023.\\n\\n^ Simon, Felix M.; Altay, Sacha; Mercier, Hugo (October 18, 2023). \"Misinformation reloaded? Fears about the impact of generative AI on misinformation are overblown\". Harvard Kennedy School Misinformation Review. doi:10.37016/mr-2020-127. S2CID\\xa0264113883. Archived from the original on November 17, 2023. Retrieved November 16, 2023.\\n\\n^ \"New AI systems collide with copyright law\". BBC News. August 1, 2023. Retrieved September 28, 2024.\\n\\n^ Newquist, H. P. (1994). The Brain Makers: Genius, Ego, And Greed In The Quest For Machines That Think. New York: Macmillan/SAMS. pp.\\xa045‚Äì53. ISBN\\xa0978-0-672-30412-5.\\n\\n^ Sharkey, Noel (July 4, 2007), A programmable robot from 60 AD, vol.\\xa02611, New Scientist, archived from the original on January 13, 2018, retrieved October 22, 2019\\n\\n^ Brett, Gerard (July 1954), \"The Automata in the Byzantine \"Throne of Solomon\"\", Speculum, 29 (3): 477‚Äì487, doi:10.2307/2846790, ISSN\\xa00038-7134, JSTOR\\xa02846790, S2CID\\xa0163031682.\\n\\n^ kelinich (March 8, 2014). \"Maillardet\\'s Automaton\". The Franklin Institute. Archived from the original on August 24, 2023. Retrieved August 24, 2023.\\n\\n^ Grinstead, Charles Miller; Snell, James Laurie (1997). Introduction to Probability. American Mathematical Society. pp.\\xa0464‚Äì466. ISBN\\xa0978-0-8218-0749-1.\\n\\n^ Bremaud, Pierre (March 9, 2013). Markov Chains: Gibbs Fields, Monte Carlo Simulation, and Queues. Springer Science & Business Media. p.\\xa0ix. ISBN\\xa0978-1-4757-3124-8. Archived from the original on March 23, 2017.\\n\\n^ Hayes, Brian (2013). \"First Links in the Markov Chain\". American Scientist. 101 (2): 92. doi:10.1511/2013.101.92. ISSN\\xa00003-0996. Archived from the original on May 7, 2024. Retrieved September 24, 2023.\\n\\n^ Fine, Shai; Singer, Yoram; Tishby, Naftali (July 1, 1998). \"The Hierarchical Hidden Markov Model: Analysis and Applications\". Machine Learning. 32 (1): 41‚Äì62. doi:10.1023/A:1007469218079. ISSN\\xa01573-0565. S2CID\\xa03465810.\\n\\n^ Crevier, Daniel (1993). AI: The Tumultuous Search for Artificial Intelligence. New York, New York: BasicBooks. p.\\xa0109. ISBN\\xa00-465-02997-3.\\n\\n^ Bergen, Nathan; Huang, Angela (2023). \"A Brief History of Generative AI\" (PDF). Dichotomies: Generative AI: Navigating Towards a Better Future (2): 4. Archived (PDF) from the original on August 10, 2023. Retrieved August 8, 2023.\\n\\n^ a b Alting, Leo; Zhang, Hongchao (1989). \"Computer aided process planning: the state-of-the-art survey\". The International Journal of Production Research. 27 (4): 553‚Äì585. doi:10.1080/00207548908942569. Archived from the original on May 7, 2024. Retrieved October 3, 2023.\\n\\n^ Chien, Steve (1998). \"Automated planning and scheduling for goal-based autonomous spacecraft\". IEEE Intelligent Systems and Their Applications. 13 (5): 50‚Äì55. doi:10.1109/5254.722362.\\n\\n^ Burstein, Mark H., ed. (1994). ARPA/Rome Laboratory Knowledge-based Planning and Scheduling Initiative Workshop Proceedings. The Advanced Research Projects Agency, Department of Defense, and Rome Laboratory, US Air Force, Griffiss AFB. p.\\xa0219. ISBN\\xa0155860345X.\\n\\n^ Pell, Barney; Bernard, Douglas E.; Chien, Steve A.; Gat, Erann; Muscettola, Nicola; Nayak, P. Pandurang; Wagner, Michael D.; Williams, Brian C. (1998). Bekey, George A. (ed.). An Autonomous Spacecraft Agent Prototype. Autonomous Robots Volume 5, No. 1. pp.\\xa029‚Äì45. Our deliberator is a traditional generative AI planner based on the HSTS planning framework (Muscettola, 1994), and our control component is a traditional spacecraft attitude control system (Hackney et al. 1993). We also add an architectural component explicitly dedicated to world modeling (the mode identifier), and distinguish between control and monitoring.\\n\\n^ Jebara, Tony (2012). Machine learning: discriminative and generative. Vol.\\xa0755. Springer Science & Business Media.\\n\\n^ Cao, Yihan; Li, Siyu; Liu, Yixin; Yan, Zhiling; Dai, Yutong; Yu, Philip S.; Sun, Lichao (March 7, 2023). \"A Comprehensive Survey of AI-Generated Content (AIGC): A History of Generative AI from GAN to ChatGPT\". arXiv:2303.04226 [cs.AI].\\n\\n^ \"finetune-transformer-lm\". GitHub. Archived from the original on May 19, 2023. Retrieved May 19, 2023.\\n\\n^ Radford, Alec; Wu, Jeffrey; Child, Rewon; Luan, David; Amodei, Dario; Sutskever, Ilya (2019). \"Language models are unsupervised multitask learners\" (PDF). OpenAI Blog.\\n\\n^ Radford, Alec (June 11, 2018). \"Improving language understanding with unsupervised learning\". OpenAI. Retrieved October 6, 2024.\\n\\n^ Chandraseta, Rionaldi (January 21, 2021). \"Generate Your Favourite Characters\\' Voice Lines using Machine Learning\". Towards Data Science. Retrieved December 18, 2024.\\n\\n^ Temitope, Yusuf (December 10, 2024). \"15.ai Creator reveals journey from MIT Project to internet phenomenon\". The Guardian. Archived from the original on December 28, 2024. Retrieved December 25, 2024.\\n\\n^ Anirudh VK (March 18, 2023). \"Deepfakes Are Elevating Meme Culture, But At What Cost?\". Analytics India Magazine. Archived from the original on December 26, 2024. Retrieved December 18, 2024. While AI voice memes have been around in some form since \\'15.ai\\' launched in 2020, [...]\\n\\n^ Coldewey, Devin (January 5, 2021). \"OpenAI\\'s DALL-E creates plausible images of literally anything you ask it to\". TechCrunch. Retrieved March 15, 2023.\\n\\n^ \"Stable Diffusion Public Release\". Stability AI. Retrieved March 15, 2023.\\n\\n^ Lock, Samantha (December 5, 2022). \"What is AI chatbot phenomenon ChatGPT and could it replace humans?\". The Guardian. Retrieved March 15, 2023.\\n\\n^ Huang, Haomiao (August 23, 2023). \"How ChatGPT turned generative AI into an \"anything tool\"\". Ars Technica. Retrieved September 21, 2024.\\n\\n^ Bubeck, S√©bastien; Chandrasekaran, Varun; Eldan, Ronen; Gehrke, Johannes; Horvitz, Eric; Kamar, Ece; Lee, Peter; Lee, Yin Tat; Li, Yuanzhi; Lundberg, Scott; Nori, Harsha; Palangi, Hamid; Ribeiro, Marco Tulio; Zhang, Yi (March 22, 2023). \"Sparks of Artificial General Intelligence: Early experiments with GPT-4\". arXiv:2303.12712 [cs.CL].\\n\\n^ Schlagwein, Daniel; Willcocks, Leslie (September 13, 2023). \"ChatGPT et al: The Ethics of Using (Generative) Artificial Intelligence in Research and Science\". Journal of Information Technology. 38 (2): 232‚Äì238. doi:10.1177/02683962231200411. S2CID\\xa0261753752.\\n\\n^ \"Meta open-sources multisensory AI model that combines six types of data\". May 9, 2023. Retrieved March 14, 2024.\\n\\n^ Kruppa, Miles (December 6, 2023). \"Google Announces AI System Gemini After Turmoil at Rival OpenAI\". The Wall Street Journal. ISSN\\xa00099-9660. Archived from the original on December 6, 2023. Retrieved December 6, 2023.\\n\\n^ Edwards, Benj (December 6, 2023). \"Google launches Gemini‚Äîa powerful AI model it says can surpass GPT-4\". Ars Technica. Retrieved December 6, 2023.\\n\\n^ Metz, Cade (February 8, 2024). \"Google Releases Gemini, an A.I.-Driven Chatbot and Voice Assistant\". The New York Times. Retrieved February 8, 2024.\\n\\n^ \"Introducing the next generation of Claude\". Retrieved March 4, 2024.\\n\\n^ Nu√±ez, Michael (March 4, 2024). \"Anthropic unveils Claude 3, surpassing GPT-4 and Gemini Ultra in benchmark tests\". Venture Beat. Retrieved April 9, 2024.\\n\\n^ Pierce, David (June 20, 2024). \"Anthropic has a fast new AI model ‚Äî and a clever new way to interact with chatbots\". The Verge. Retrieved June 22, 2024.\\n\\n^ Baptista, Eduardo (July 9, 2024). \"China leads the world in adoption of generative AI, survey shows\". Reuters. Retrieved July 14, 2024.\\n\\n^ \"A History of Generative AI: From GAN to GPT-4\". March 21, 2023. Archived from the original on June 10, 2023. Retrieved April 28, 2023.\\n\\n^ \"Explainer: What is Generative AI, the technology behind OpenAI\\'s ChatGPT?\". Reuters. March 17, 2023. Archived from the original on March 30, 2023. Retrieved March 17, 2023.\\n\\n^ Roose, Kevin (February 16, 2023). \"Bing\\'s A.I. Chat: \\'I Want to Be Alive.\\'\". The New York Times. Archived from the original on April 15, 2023. Retrieved January 30, 2024.\\n\\n^ Bommasani, R.; Hudson, D. A.; Adeli, E.; Altman, R.; Arora, S.; von Arx, S.; Bernstein, M. S.; Bohg, J.; Bosselut, A; Brunskill, E.; Brynjolfsson, E. (August 16, 2021). \"On the opportunities and risks of foundation models\". arXiv:2108.07258 [cs.LG].\\n\\n^ Chen, Ming; Tworek, Jakub; Jun, Hongyu; Yuan, Qinyuan; Pinto, Hanyu Philippe De Oliveira; Kaplan, Jerry; Edwards, Haley; Burda, Yannick; Joseph, Nicholas; Brockman, Greg; Ray, Alvin (July 6, 2021). \"Evaluating Large Language Models Trained on Code\". arXiv:2107.03374 [cs.LG].\\n\\n^ \"Investing in Cursor\". Andreesen Horowitz.\\n\\n^ Epstein, Ziv; Hertzmann, Aaron; Akten, Memo; Farid, Hany; Fjeld, Jessica; Frank, Morgan R.; Groh, Matthew; Herman, Laura; Leach, Neil; Mahari, Robert; Pentland, Alex ‚ÄúSandy‚Äù; Russakovsky, Olga; Schroeder, Hope; Smith, Amy (2023). \"Art and the science of generative AI\". Science. 380 (6650): 1110‚Äì1111. arXiv:2306.04141. Bibcode:2023Sci...380.1110E. doi:10.1126/science.adh4451. PMID\\xa037319193. S2CID\\xa0259095707.\\n\\n^ Ramesh, Aditya; Pavlov, Mikhail; Goh, Gabriel; Gray, Scott; Voss, Chelsea; Radford, Alec; Chen, Mark; Sutskever, Ilya (2021). \"Zero-shot text-to-image generation\". International Conference on Machine Learning. PMLR. pp.\\xa08821‚Äì8831.\\n\\n^ Chandraseta, Rionaldi (January 21, 2021). \"Generate Your Favourite Characters\\' Voice Lines using Machine Learning\". Towards Data Science. Archived from the original on January 21, 2021. Retrieved December 18, 2024.\\n\\n^ Temitope, Yusuf (December 10, 2024). \"15.ai Creator reveals journey from MIT Project to internet phenomenon\". The Guardian. Archived from the original on December 28, 2024. Retrieved December 25, 2024.\\n\\n^ Ruppert, Liana (January 18, 2021). \"Make Portal\\'s GLaDOS And Other Beloved Characters Say The Weirdest Things With This App\". Game Informer. Archived from the original on January 18, 2021. Retrieved December 18, 2024.\\n\\n^ Kurosawa, Yuki (January 19, 2021). \"„Ç≤„Éº„É†„Ç≠„É£„É©Èü≥Â£∞Ë™≠„Åø‰∏ä„Åí„ÇΩ„Éï„Éà„Äå15.ai„ÄçÂÖ¨Èñã‰∏≠„ÄÇ„ÄéUndertale„Äè„ÇÑ„ÄéPortal„Äè„ÅÆ„Ç≠„É£„É©„Å´Â•Ω„Åç„Å™„Çª„É™„Éï„ÇíË®Ä„Å£„Å¶„ÇÇ„Çâ„Åà„Çã\" [Game Character Voice Reading Software \"15.ai\" Now Available. Get Characters from Undertale and Portal to Say Your Desired Lines]. AUTOMATON (in Japanese). Archived from the original on January 19, 2021. Retrieved December 18, 2024. Ëã±Ë™ûÁâà„Éú„Ç§„Çπ„ÅÆ„Åø„Å™„ÅÆ„ÅßÊ≥®ÊÑè„ÄÇ;„ÇÇ„ÅÜ„Å≤„Å®„Å§15.ai„ÅÆÂ§ß„Åç„Å™ÁâπÂæ¥„Å®„Åó„Å¶Êåô„Åí„Çâ„Çå„Çã„ÅÆ„Åå„ÄÅË±ä„Åã„Å™ÊÑüÊÉÖË°®Áèæ„Å†„ÄÇ [Please note that only English voices are available.;Another major feature of 15.ai is its rich emotional expression.]\\n\\n^ Desai, Saahil (July 17, 2023). \"A Voicebot Just Left Me Speechless\". The Atlantic. Archived from the original on December 8, 2023. Retrieved November 28, 2023.\\n\\n^ Agostinelli, Andrea; Denk, Timo I.; Borsos, Zal√°n; Engel, Jesse; Verzetti, Mauro; Caillon, Antoine; Huang, Qingqing; Jansen, Aren; Roberts, Adam; Tagliasacchi, Marco; Sharifi, Matt; Zeghidour, Neil; Frank, Christian (January 26, 2023). \"MusicLM: Generating Music From Text\". arXiv:2301.11325 [cs.SD].\\n\\n^ Dalugdug, Mandy (August 3, 2023). \"Meta in June said that it used 20,000 hours of licensed music to train MusicGen, which included 10,000 \"high-quality\" licensed music tracks. At the time, Meta\\'s researchers outlined in a paper the ethical challenges that they encountered around the development of generative AI models like MusicGen\". Archived from the original on August 15, 2023.\\n\\n^ \"Jay-Z\\'s Delaware producer sparks debate over AI rights\". Archived from the original on February 27, 2024. Retrieved February 27, 2024.\\n\\n^ \"10 \"Best\" AI Music Generators (April 2024) - Unite.AI\". October 19, 2022. Archived from the original on January 29, 2024. Retrieved February 27, 2024.\\n\\n^ Metz, Cade (April 4, 2023). \"Instant Videos Could Represent the Next Leap in A.I. Technology\". The New York Times. Archived from the original on April 5, 2023. Retrieved April 5, 2023.\\n\\n^ Wong, Queenie (September 29, 2022). \"Facebook Parent Meta\\'s AI Tool Can Create Artsy Videos From Text\". cnet.com. Archived from the original on April 5, 2023. Retrieved April 4, 2023.\\n\\n^ Yang, Sherry; Du, Yilun (April 12, 2023). \"UniPi: Learning universal policies via text-guided video generation\". Google Research, Brain Team. Google AI Blog. Archived from the original on May 24, 2023.\\n\\n^ Brohan, Anthony (2023). \"RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control\". arXiv:2307.15818 [cs.RO].\\n\\n^ Abdullahi, Aminu (November 17, 2023). \"10 Best Artificial Intelligence (AI) 3D Generators\". eWEEK. Archived from the original on May 7, 2024. Retrieved February 6, 2024.\\n\\n^ \"Slash CAD model build times with new AI-driven part creation methodology | GlobalSpec\". Archived from the original on January 23, 2024. Retrieved February 6, 2024.\\n\\n^ \"The Role of Artificial Intelligence (AI) in the CAD Industry\". March 22, 2023. Archived from the original on February 9, 2024. Retrieved February 6, 2024.\\n\\n^ Sabin, Sam (June 30, 2023). \"GitHub has a vision to make code more secure by design\". Axios Codebook. Archived from the original on August 15, 2023. Retrieved August 15, 2023.\\n\\n^ Vincent, James (March 20, 2023). \"Text-to-video AI inches closer as startup Runway announces new model\". The Verge. Archived from the original on September 27, 2023. Retrieved August 15, 2023. Text-to-video is the next frontier for generative AI, though current output is rudimentary. Runway says it\\'ll be making its new generative video model, Gen-2, available to users in \\'the coming weeks.\\'\\n\\n^ Vanian, Jonathan (March 16, 2023). \"Microsoft adds OpenAI technology to Word and Excel\". CNBC. Archived from the original on August 15, 2023. Retrieved August 15, 2023. Microsoft is bringing generative artificial intelligence technologies such as the popular ChatGPT chatting app to its Microsoft 365 suite of business software....the new A.I. features, dubbed Copilot, will be available in some of the company\\'s most popular business apps, including Word, PowerPoint and Excel.\\n\\n^ Wilson, Mark (August 15, 2023). \"The app\\'s Memories feature just got a big upgrade\". TechRadar. Archived from the original on August 15, 2023. The Google Photos app is getting a redesigned, AI-powered Memories feature...you\\'ll be able to use generative AI to come up with some suggested names like \"a desert adventure\".\\n\\n^ Sullivan, Laurie (May 23, 2023). \"Adobe Adds Generative AI To Photoshop\". MediaPost. Archived from the original on August 15, 2023. Retrieved August 15, 2023. Generative artificial intelligence (AI) will become one of the most important features for creative designers and marketers. Adobe on Tuesday unveiled a Generative Fill feature in Photoshop to bring Firefly\\'s AI capabilities into design.\\n\\n^ Michael Nu√±ez (July 19, 2023). \"LLaMA 2: How to access and use Meta\\'s versatile open-source chatbot right now\". VentureBeat. Archived from the original on November 3, 2023. Retrieved August 15, 2023. If you want to run LLaMA 2 on your own machine or modify the code, you can download it directly from Hugging Face, a leading platform for sharing AI models.\\n\\n^ Pounder, Les (March 25, 2023). \"How To Create Your Own AI Chatbot Server With Raspberry Pi 4\". Archived from the original on August 15, 2023. Retrieved August 15, 2023. Using a Pi 4 with 8GB of RAM, you can create a ChatGPT-like server based on LLaMA.\\n\\n^ Kemper, Jonathan (November 10, 2022). \"\"Draw Things\" App brings Stable Diffusion to the iPhone\". The Decoder. Archived from the original on August 15, 2023. Retrieved August 15, 2023. Draw Things is an app that brings Stable Diffusion to the iPhone. The AI images are generated locally, so you don\\'t need an Internet connection.\\n\\n^ Witt, Allan (July 7, 2023). \"Best Computer to Run LLaMA AI Model at Home (GPU, CPU, RAM, SSD)\". Archived from the original on August 15, 2023. Retrieved August 15, 2023. To run LLaMA model at home, you will need a computer build with a powerful GPU that can handle the large amount of data and computation required for inferencing.\\n\\n^ Westover, Brian (September 28, 2023). \"Who Needs ChatGPT? How to Run Your Own Free and Private AI Chatbot\". Ziff Davis. Archived from the original on January 7, 2024. Retrieved January 7, 2024.\\n\\n^ @karpathy (December 20, 2023). \"I pretty much only trust two LLM evals right now\" (Tweet) – via Twitter.\\n\\n^ @ylecun (January 5, 2024). \"Nabla\\'s shift from ChatGPT to open source LLMs...\" (Tweet) – via Twitter.\\n\\n^ @ylecun (November 1, 2023). \"Open source platforms *increase* safety and security\" (Tweet) – via Twitter.\\n\\n^ Nellis, Stephen; Lee, Jane (September 1, 2022). \"U.S. officials order Nvidia to halt sales of top AI chips to China\". Reuters. Archived from the original on August 15, 2023. Retrieved August 15, 2023.\\n\\n^ Shilov, Anton (May 7, 2023). \"Nvidia\\'s Chinese A800 GPU\\'s Performance Revealed\". Tom\\'s Hardware. Archived from the original on May 7, 2024. Retrieved August 15, 2023. the A800 operates at 70% of the speed of A100 GPUs while complying with strict U.S. export standards that limit how much processing power Nvidia can sell.\\n\\n^ Patel, Dylan (October 24, 2022). \"How China\\'s Biren Is Attempting To Evade US Sanctions\". Archived from the original on August 15, 2023. Retrieved August 15, 2023.\\n\\n^ \"5 free software to recognise fake AI-generated images\" (in Italian). October 28, 2023. Archived from the original on October 29, 2023. Retrieved October 29, 2023.\\n\\n^ \"Detecting AI fingerprints: A guide to watermarking and beyond\". Brookings Institution. January 4, 2024. Archived from the original on September 3, 2024. Retrieved September 5, 2024.\\n\\n^ Fowler, Geoffrey (April 3, 2023). \"We tested a new ChatGPT-detector for teachers. It flagged an innocent student\". washingtonpost.com. Archived from the original on March 28, 2024. Retrieved February 6, 2024.\\n\\n^ Fowler, Geoffrey (June 2, 2023). \"Detecting AI may be impossible. That\\'s a big problem for teachers\". washingtonpost.com. Archived from the original on June 3, 2023. Retrieved February 6, 2024.\\n\\n^ Bartz, Diane; Hu, Krystal (July 21, 2023). \"OpenAI, Google, others pledge to watermark AI content for safety, White House says\". Reuters. Archived from the original on July 27, 2023.\\n\\n^ \"FACT SHEET: President Biden Issues Executive Order on Safe, Secure, and Trustworthy Artificial Intelligence\". The White House. October 30, 2023. Archived from the original on January 30, 2024. Retrieved January 30, 2024.\\n\\n^ Burt, Andrew (October 31, 2023). \"3 Obstacles to Regulating Generative AI\". Harvard Business Review. ISSN\\xa00017-8012. Archived from the original on February 17, 2024. Retrieved February 17, 2024.\\n\\n^ \"EU AI Act: first regulation on artificial intelligence\". European Parliament. August 6, 2023. Retrieved September 13, 2024.\\n\\n^ Chee, Foo Yun; Mukherjee, Supantha (June 14, 2023). \"EU lawmakers vote for tougher AI rules as draft moves to final stage\". Reuters. Archived from the original on July 27, 2023. Retrieved July 26, 2023.\\n\\n^ Ye, Josh (July 13, 2023). \"China says generative AI rules to apply only to products for the public\". Reuters. Archived from the original on July 27, 2023. Retrieved July 13, 2023.\\n\\n^ \"ÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÊúçÂä°ÁÆ°ÁêÜÊöÇË°åÂäûÊ≥ï\". July 13, 2023. Archived from the original on July 27, 2023. Retrieved July 27, 2023.\\n\\n^ a b \"Generative Artificial Intelligence and Copyright Law\". Congressional Research Service. LSB10922. September 29, 2023. Archived from the original on March 22, 2024. Retrieved January 30, 2024.\\n\\n^ Thompson, Stuart (January 25, 2024). \"We Asked A.I. to Create the Joker. It Generated a Copyrighted Image\". The New York Times. Archived from the original on January 25, 2024. Retrieved January 26, 2024.\\n\\n^ Hadero, Haleluya; Bauder, David (December 27, 2023). \"The New York Times sues OpenAI and Microsoft for using its stories to train chatbots\". Associated Press News. AP News. Archived from the original on December 27, 2023. Retrieved April 13, 2023.\\n\\n^ O‚ÄôBrien, Matt (September 25, 2023). \"Photo giant Getty took a leading AI image-maker to court. Now it\\'s also embracing the technology\". AP NEWS. Associated Press. Archived from the original on January 30, 2024. Retrieved January 30, 2024.\\n\\n^ Barber, Gregory (December 9, 2023). \"The Generative AI Copyright Fight Is Just Getting Started\". Wired. Archived from the original on January 19, 2024. Retrieved January 19, 2024.\\n\\n^ Bruell, Alexandra (December 27, 2023). \"New York Times Sues Microsoft and OpenAI, Alleging Copyright Infringement\". Wall Street Journal. Archived from the original on January 18, 2024. Retrieved January 19, 2024.\\n\\n^ Brittain, Blake (August 21, 2023). \"AI-generated art cannot receive copyrights, US court says\". Reuters. Archived from the original on January 20, 2024. Retrieved January 19, 2024.\\n\\n^ David, Emilla (August 29, 2023). \"US Copyright Office wants to hear what people think about AI and copyright\". The Verge. Archived from the original on January 19, 2024. Retrieved January 19, 2024.\\n\\n^ \"Secretary-General\\'s remarks to the Security Council on Artificial Intelligence\". un.org. July 18, 2023. Archived from the original on July 28, 2023. Retrieved July 27, 2023.\\n\\n^ a b Toews, Rob. \"Deep Learning\\'s Carbon Emissions Problem\". Forbes. Archived from the original on June 14, 2024. Retrieved July 4, 2024.\\n\\n^ a b Heikkil√§, Melissa (December 5, 2023). \"AI\\'s carbon footprint is bigger than you think\". MIT Technology Review. Archived from the original on July 5, 2024. Retrieved July 4, 2024.\\n\\n^ \"The Writers Strike Is Taking a Stand on AI\". Time. May 4, 2023. Archived from the original on June 11, 2023. Retrieved June 11, 2023.\\n\\n^ Tarnoff, Ben (August 4, 2023). \"Lessons from Eliza\". The Guardian Weekly. pp.\\xa034‚Äì39.\\n\\n^ Zhou, Viola (April 11, 2023). \"AI is already taking video game illustrators\\' jobs in China\". Rest of World. Archived from the original on August 13, 2023. Retrieved August 17, 2023.\\n\\n^ Carter, Justin (April 11, 2023). \"China\\'s game art industry reportedly decimated by growing AI use\". Game Developer. Archived from the original on August 17, 2023. Retrieved August 17, 2023.\\n\\n^ Collier, Kevin (July 14, 2023). \"Actors vs. AI: Strike brings focus to emerging use of advanced tech\". NBC News. Archived from the original on July 20, 2023. Retrieved July 21, 2023. SAG-AFTRA has joined the Writer\\'s [sic] Guild of America in demanding a contract that explicitly demands AI regulations to protect writers and the works they create.\\xa0... The future of generative artificial intelligence in Hollywood‚Äîand how it can be used to replace labor‚Äîhas become a crucial sticking point for actors going on strike. In a news conference Thursday, Fran Drescher, president of the Screen Actors Guild-American Federation of Television and Radio Artists (more commonly known as SAG-AFTRA), declared that \\'artificial intelligence poses an existential threat to creative professions, and all actors and performers deserve contract language that protects them from having their identity and talent exploited without consent and pay.\\'\\n\\n^ Wiggers, Kyle (August 22, 2023). \"ElevenLabs\\' voice-generating tools launch out of beta\". TechCrunch. Archived from the original on November 28, 2023. Retrieved September 25, 2023.\\n\\n^ Shrivastava, Rashi. \"\\'Keep Your Paws Off My Voice\\': Voice Actors Worry Generative AI Will Steal Their Livelihoods\". Forbes. Archived from the original on December 2, 2023. Retrieved November 28, 2023.\\n\\n^ Gupta, Shalene (October 31, 2023). \"Underrepresented groups in countries around the world are worried about AI being a threat to jobs\". Fast Company. Archived from the original on December 8, 2023. Retrieved December 8, 2023.\\n\\n^ Rachel Gordon (March 3, 2023). \"Large language models are biased. Can logic help save them?\". MIT CSAIL. Archived from the original on January 23, 2024. Retrieved January 26, 2024.\\n\\n^ OpenAI (July 18, 2022). \"Reducing bias and improving safety in DALL¬∑E 2\". OpenAI. Archived from the original on January 26, 2024. Retrieved January 26, 2024.\\n\\n^ Jake Traylor (July 27, 2022). \"No quick fix: How OpenAI\\'s DALL¬∑E 2 illustrated the challenges of bias in AI\". NBC News. Archived from the original on January 26, 2024. Retrieved January 26, 2024.\\n\\n^ \"DALL¬∑E 2 pre-training mitigations\". OpenAI. June 28, 2022. Archived from the original on January 26, 2024. Retrieved January 26, 2024.\\n\\n^ Brandon, John (February 16, 2018). \"Terrifying high-tech porn: Creepy \\'deepfake\\' videos are on the rise\". Fox News. Archived from the original on June 15, 2018. Retrieved February 20, 2018.\\n\\n^ Cole, Samantha (January 24, 2018). \"We Are Truly Fucked: Everyone Is Making AI-Generated Fake Porn Now\". Vice. Archived from the original on September 7, 2019. Retrieved May 4, 2019.\\n\\n^ \"What Are Deepfakes & Why the Future of Porn is Terrifying\". Highsnobiety. February 20, 2018. Archived from the original on July 14, 2021. Retrieved February 20, 2018.\\n\\n^ \"Experts fear face swapping tech could start an international showdown\". The Outline. Archived from the original on January 16, 2020. Retrieved February 28, 2018.\\n\\n^ Roose, Kevin (March 4, 2018). \"Here Come the Fake Videos, Too\". The New York Times. ISSN\\xa00362-4331. Archived from the original on June 18, 2019. Retrieved March 24, 2018.\\n\\n^ Schreyer, Marco; Sattarov, Timur; Reimer, Bernd; Borth, Damian (2019). \"Adversarial Learning of Deepfakes in Accounting\". arXiv:1910.03810 [cs.LG].\\n\\n^ Menz, Bradley (2024). \"Health Disinformation Use Case Highlighting the Urgent Need for Artificial Intelligence Vigilance\". JAMA Internal Medicine. 184 (1): 92‚Äì96. doi:10.1001/jamainternmed.2023.5947. PMID\\xa037955873. S2CID\\xa0265148637. Archived from the original on February 4, 2024. Retrieved February 4, 2024.\\n\\n^ Chalfant, Morgan (March 6, 2024). \"U.S. braces for foreign interference in 2024 election\". Semafor. Archived from the original on March 11, 2024. Retrieved March 6, 2024.\\n\\n^ Menn, Joseph (September 23, 2024). \"Russia, Iran use AI to boost anti-U.S. influence campaigns, officials say\". The Washington Post. ISSN\\xa00190-8286. Archived from the original on September 24, 2024. Retrieved September 23, 2024.\\n\\n^ \"Join the Deepfake Detection Challenge (DFDC)\". deepfakedetectionchallenge.ai. Archived from the original on January 12, 2020. Retrieved November 8, 2019.\\n\\n^ Clarke, Yvette D. (June 28, 2019). \"H.R.3230 ‚Äì 116th Congress (2019-2020): Defending Each and Every Person from False Appearances by Keeping Exploitation Subject to Accountability Act of 2019\". www.congress.gov. Archived from the original on December 17, 2019. Retrieved October 16, 2019.\\n\\n^ \"New Research Reveals Scale of Threat Posed by AI-generated Images on 2024 Elections\". Logically. July 27, 2023. Archived from the original on October 3, 2023. Retrieved July 6, 2024.\\n\\n^ Lawton, Graham (September 12, 2023). \"Disinformation wars: The fight against fake news in the age of AI\". New Scientist. Retrieved July 5, 2024.\\n\\n^ Brewer, Jordan; Patel, Dhru; Kim, Dennie; Murray, Alex (April 12, 2024). \"Navigating the challenges of generative technologies: Proposing the integration of artificial intelligence and blockchain\". Business Horizons. 67 (5): 525‚Äì535. doi:10.1016/j.bushor.2024.04.011. ISSN\\xa00007-6813.\\n\\n^ \"People Are Still Terrible: AI Voice-Cloning Tool Misused for Deepfake Celeb Clips\". PCMag Middle East. January 31, 2023. Archived from the original on December 25, 2023. Retrieved July 25, 2023.\\n\\n^ \"The generative A.I. software race has begun\". Fortune. Archived from the original on March 25, 2023. Retrieved February 3, 2023.\\n\\n^ Milmo, Dan; Hern, Alex (May 20, 2023). \"Elections in UK and US at risk from AI-driven disinformation, say experts\". The Guardian. ISSN\\xa00261-3077. Archived from the original on November 16, 2023. Retrieved July 25, 2023.\\n\\n^ \"Seeing is believing? Global scramble to tackle deepfakes\". news.yahoo.com. Archived from the original on February 3, 2023. Retrieved February 3, 2023.\\n\\n^ Vincent, James (January 31, 2023). \"4chan users embrace AI voice clone tool to generate celebrity hatespeech\". The Verge. Archived from the original on December 3, 2023. Retrieved February 3, 2023.\\n\\n^ Thompson, Stuart A. (March 12, 2023). \"Making Deepfakes Gets Cheaper and Easier Thanks to A.I.\" The New York Times. ISSN\\xa00362-4331. Archived from the original on October 29, 2023. Retrieved July 25, 2023.\\n\\n^ \"A new AI voice tool is already being abused to make deepfake celebrity audio clips\". Engadget. January 31, 2023. Archived from the original on October 10, 2023. Retrieved February 3, 2023.\\n\\n^ Gee, Andre (April 20, 2023). \"Just Because AI-Generated Rap Songs Go Viral Doesn\\'t Mean They\\'re Good\". Rolling Stone. Archived from the original on January 2, 2024. Retrieved December 6, 2023.\\n\\n^ Coscarelli, Joe (April 19, 2023). \"An A.I. Hit of Fake \\'Drake\\' and \\'The Weeknd\\' Rattles the Music World\". The New York Times. Archived from the original on May 15, 2023. Retrieved December 5, 2023.\\n\\n^ Lippiello, Emily; Smith, Nathan; Pereira, Ivan (November 3, 2023). \"AI songs that mimic popular artists raising alarms in the music industry\". ABC News. Archived from the original on December 6, 2023. Retrieved December 6, 2023.\\n\\n^ Skelton, Eric. \"Fans Are Using Artificial Intelligence to Turn Rap Snippets Into Full Songs\". Complex. Archived from the original on January 2, 2024. Retrieved December 6, 2023.\\n\\n^ Marr, Bernard. \"Virtual Influencer Noonoouri Lands Record Deal: Is She The Future Of Music?\". Forbes. Archived from the original on December 4, 2023. Retrieved December 6, 2023.\\n\\n^ Thaler, Shannon (September 8, 2023). \"Warner Music signs first-ever record deal with AI pop star\". New York Post. Archived from the original on December 15, 2023. Retrieved December 6, 2023.\\n\\n^ Sjouwerman, Stu (December 26, 2022). \"Deepfakes: Get ready for phishing 2.0\". Fast Company. Archived from the original on July 31, 2023. Retrieved July 31, 2023.\\n\\n^ Sonnemaker, Tyler. \"As social media platforms brace for the incoming wave of deepfakes, Google\\'s former \\'fraud czar\\' predicts the biggest danger is that deepfakes will eventually become boring\". Business Insider. Archived from the original on April 14, 2021. Retrieved July 31, 2023.\\n\\n^ Collinson, Patrick (July 15, 2023). \"Fake reviews: can we trust what we read online as use of AI explodes?\". The Guardian. ISSN\\xa00261-3077. Archived from the original on November 22, 2023. Retrieved December 6, 2023.\\n\\n^ \"After WormGPT, FraudGPT Emerges to Help Scammers Steal Your Data\". PCMAG. July 25, 2023. Archived from the original on July 31, 2023. Retrieved July 31, 2023.\\n\\n^ Gupta, Maanak; Akiri, Charankumar; Aryal, Kshitiz; Parker, Eli; Praharaj, Lopamudra (2023). \"From ChatGPT to ThreatGPT: Impact of Generative AI in Cybersecurity and Privacy\". IEEE Access. 11: 80218‚Äì80245. arXiv:2307.00691. Bibcode:2023IEEEA..1180218G. doi:10.1109/ACCESS.2023.3300381. S2CID\\xa0259316122.\\n\\n^ Piper, Kelsey (February 2, 2024). \"Should we make our most powerful AI models open source to all?\". Vox. Retrieved January 13, 2025.\\n\\n^ Metz, Cade (July 10, 2023). \"In the Age of A.I., Tech\\'s Little Guys Need Big Friends\". New York Times.\\n\\n^ a b Bender, Emily M.; Gebru, Timnit; McMillan-Major, Angelina; Shmitchell, Shmargaret (March 1, 2021). \"On the Dangers of Stochastic Parrots: Can Language Models be Too Big? \\uf8ffü¶ú\". Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency. FAccT \\'21. New York, NY, USA: Association for Computing Machinery. pp.\\xa0610‚Äì623. doi:10.1145/3442188.3445922. ISBN\\xa0978-1-4503-8309-7.\\n\\n^ a b c d \"AI is an energy hog. This is what it means for climate change\". MIT Technology Review. May 23, 2024. Archived from the original on August 20, 2024. Retrieved August 27, 2024.\\n\\n^ a b c d e f g Dhar, Payal (August 1, 2020). \"The carbon impact of artificial intelligence\". Nature Machine Intelligence. 2 (8): 423‚Äì425. doi:10.1038/s42256-020-0219-9. ISSN\\xa02522-5839. Archived from the original on August 14, 2024.\\n\\n^ a b c d e Crawford, Kate (February 20, 2024). \"Generative AI\\'s environmental costs are soaring ‚Äî and mostly secret\". Nature. 626 (8000): 693. Bibcode:2024Natur.626..693C. doi:10.1038/d41586-024-00478-x. PMID\\xa038378831. Archived from the original on August 22, 2024.\\n\\n^ a b c d Rogers, Reece. \"AI\\'s Energy Demands Are Out of Control. Welcome to the Internet\\'s Hyper-Consumption Era\". Wired. ISSN\\xa01059-1028. Archived from the original on August 14, 2024. Retrieved August 27, 2024.\\n\\n^ a b c d e f Saenko, Kate (May 23, 2023). \"Is generative AI bad for the environment? A computer scientist explains the carbon footprint of ChatGPT and its cousins\". The Conversation. Archived from the original on July 1, 2024. Retrieved August 27, 2024.\\n\\n^ a b Lohr, Steve (August 26, 2024). \"Will A.I. Ruin the Planet or Save the Planet?\". The New York Times. ISSN\\xa00362-4331. Archived from the original on August 26, 2024. Retrieved August 27, 2024.\\n\\n^ Hoffman, Benjamin (June 11, 2024). \"First Came \\'Spam.\\' Now, With A.I., We\\'ve Got \\'Slop\\'\". The New York Times. ISSN\\xa00362-4331. Archived from the original on August 26, 2024. Retrieved August 27, 2024.\\n\\n^ a b \"Investigation Finds Actual Source of All That AI Slop on Facebook\". Futurism. August 10, 2024. Archived from the original on August 15, 2024. Retrieved August 27, 2024.\\n\\n^ a b Warzel, Charlie (August 21, 2024). \"The MAGA Aesthetic Is AI Slop\". The Atlantic. Archived from the original on August 25, 2024. Retrieved August 27, 2024.\\n\\n^ Edwards, Benj (August 14, 2024). \"Research AI model unexpectedly attempts to modify its own code to extend runtime\". Ars Technica. Archived from the original on August 24, 2024. Retrieved August 27, 2024.\\n\\n^ Hern, Alex; Milmo, Dan (May 19, 2024). \"Spam, junk ‚Ä¶ slop? The latest wave of AI behind the \\'zombie internet\\'\". The Guardian. ISSN\\xa00261-3077. Archived from the original on August 26, 2024. Retrieved August 27, 2024.\\n\\n^ Cox, Joseph (January 18, 2024). \"Google News Is Boosting Garbage AI-Generated Articles\". 404 Media. Archived from the original on June 13, 2024. Retrieved August 27, 2024.\\n\\n^ \"Beloved Local Newspapers Fired Staffers, Then Started Running AI Slop\". Futurism. July 31, 2024. Archived from the original on August 12, 2024. Retrieved August 27, 2024.\\n\\n^ Thompson, Brian; Dhaliwal, Mehak; Frisch, Peter; Domhan, Tobias; Federico, Marcello (August 2024). Ku, Lun-Wei; Martins, Andre; Srikumar, Vivek (eds.). \"A Shocking Amount of the Web is Machine Translated: Insights from Multi-Way Parallelism\". Findings of the Association for Computational Linguistics ACL 2024. Bangkok, Thailand and virtual meeting: Association for Computational Linguistics: 1763‚Äì1775. arXiv:2401.05749. doi:10.18653/v1/2024.findings-acl.103.\\n\\n^ Roscoe, Jules (January 17, 2024). \"A \\'Shocking\\' Amount of the Web Is Already AI-Translated Trash, Scientists Determine\". VICE. Archived from the original on July 1, 2024. Retrieved August 27, 2024.\\n\\n^ Koebler, Jason (September 19, 2024). \"Project Analyzing Human Language Usage Shuts Down Because \\'Generative AI Has Polluted the Data\\'\". 404 Media. Archived from the original on September 19, 2024. Retrieved September 20, 2024. While there has always been spam on the internet and in the datasets that Wordfreq used, \"it was manageable and often identifiable. Large language models generate text that masquerades as real language with intention behind it, even though there is none, and their output crops up everywhere,\" she wrote. She gives the example that ChatGPT overuses the word \"delve,\" in a way that people do not, which has thrown off the frequency of this specific word.\\n\\n^ Gray, Andrew (March 24, 2024). \"ChatGPT \"contamination\": estimating the prevalence of LLMs in the scholarly literature\". arXiv:2403.16887 [cs.DL].\\n\\n^ Kannan, Prabha (May 13, 2024). \"How Much Research Is Being Written by Large Language Models?\". Human-Centered Artificial Intelligence. Stanford University. Retrieved August 16, 2024.\\n\\n^ Valyaeva, Alina (August 15, 2023). \"AI Image Statistics for 2024: How Much Content Was Created by AI\". Everypixel Journal. Retrieved August 16, 2024.\\n\\n^ Shumailov, Ilia; Shumaylov, Zakhar; Zhao, Yiren; Papernot, Nicolas; Anderson, Ross; Gal, Yarin (July 2024). \"AI models collapse when trained on recursively generated data\". Nature. 631 (8022): 755‚Äì759. Bibcode:2024Natur.631..755S. doi:10.1038/s41586-024-07566-y. PMC\\xa011269175. PMID\\xa039048682.\\n\\n^ Bhatia, Aatish (August 26, 2024). \"When A.I.\\'s Output Is a Threat to A.I. Itself\". The New York Times. ISSN\\xa00362-4331. Retrieved August 27, 2024.\\n\\n^ \"Self-Consuming Generative Models Go Mad\". ICLR. 2024.\\n\\n^ Owen, Sean (April 12, 2023). \"Synthetic Data for Better Machine Learning\". databricks.com. Archived from the original on January 3, 2024. Retrieved January 4, 2024.\\n\\n^ Sharma, Himanshu (July 11, 2023). \"Synthetic Data Platforms: Unlocking the Power of Generative AI for Structured Data\". kdnuggets.com. Archived from the original on January 3, 2024. Retrieved January 4, 2024.\\n\\n^ St√∂ckl, Andreas (November 2, 2022). \"Evaluating a Synthetic Image Dataset Generated with Stable Diffusion\". arXiv:2211.01777 [cs.CV].\\n\\n^ Roth, Emma (January 25, 2023). \"CNET found errors in more than half of its AI-written stories\". The Verge. Archived from the original on November 6, 2023. Retrieved June 17, 2023.\\n\\n^ \"A magazine touted Michael Schumacher\\'s first interview in years. It was actually AI\". NPR. April 28, 2023. Archived from the original on June 17, 2023. Retrieved June 17, 2023.\\n\\n^ Al-Sibai, Noor (January 3, 2024). \"Police Say AI-Generated Article About Local Murder Is \"Entirely\" Made Up\". Futurism. Archived from the original on January 5, 2024. Retrieved January 8, 2024.\\n\\n^ \"NewsBreak: Most downloaded US news app has Chinese roots and \\'writes fiction\\' using AI\". Reuters. June 5, 2024. Archived from the original on June 6, 2024. Retrieved June 7, 2024.\\n\\n^ a b Harrison, Maggie (November 27, 2023). \"Sports Illustrated Published Articles by Fake, AI-Generated Writers\". Futurism. Archived from the original on December 15, 2023. Retrieved January 8, 2024.\\n\\n^ Christian, Jon (February 9, 2023). \"Magazine Publishes Serious Errors in First AI-Generated Health Article\". Futurism. Archived from the original on December 26, 2023. Retrieved January 8, 2024.\\n\\n^ Schneider, Jaron (December 14, 2023). \"B&H Photo Published an AI-Generated Guide Written by a Fake Person\". PetaPixel. Archived from the original on January 4, 2024. Retrieved January 8, 2024.\\n\\n^ Harrison, Maggie (August 29, 2023). \"USA Today Owner Pauses AI Articles After Butchering Sports Coverage\". Futurism. Archived from the original on January 4, 2024. Retrieved January 8, 2024.\\n\\n^ Buchanan, Tyler (August 28, 2023). \"Dispatch pauses AI sports writing program\". Axios. Archived from the original on January 1, 2024. Retrieved January 8, 2024.\\n\\n^ Sommer, Will (October 26, 2023). \"Mysterious bylines appeared on a USA Today site. Did these writers exist?\". Washington Post. ISSN\\xa00190-8286. Archived from the original on October 26, 2023. Retrieved January 8, 2024.\\n\\n^ a b c d e f g h i j k l m n o p q r s t u v w x y z aa ab ac \"Meet AdVon, the AI-Powered Content Monster Infecting the Media Industry\". Futurism. May 8, 2024. Archived from the original on June 4, 2024. Retrieved June 8, 2024.\\n\\n^ O\\'Sullivan, Donie; Gordon, Allison (November 2, 2023). \"How Microsoft\\'s AI is making a mess of the news | CNN Business\". CNN. Archived from the original on November 2, 2023. Retrieved January 8, 2024.\\n\\n^ Meade, Amanda (July 31, 2023). \"News Corp using AI to produce 3,000 Australian local news stories a week\". The Guardian. ISSN\\xa00261-3077. Archived from the original on December 2, 2023. Retrieved January 8, 2024.\\n\\n^ Tangermann, Victor (June 30, 2023). \"Gizmodo Staff Furious After Site Announces Move to AI Content\". Futurism. Archived from the original on December 6, 2023. Retrieved January 8, 2024.\\n\\n^ a b c Kafka, Peter (July 18, 2023). \"Coming to your internet, whether you like it or not: More AI-generated stories\". Vox. Archived from the original on July 18, 2023. Retrieved January 8, 2024.\\n\\n^ Landymore, Frank; Christian, Jon (September 13, 2023). \"The A.V. Club\\'s AI-Generated Articles Are Copying Directly From IMDb\". Futurism. Archived from the original on December 6, 2023. Retrieved January 8, 2024.\\n\\n^ Stiaplame, Nordiisk (January 28, 2025). \"Quartz Is Publishing AI-Generated Articles Based on Other AI Slop, Along With Warning They May Be Filled With Errors\". Futurism. Archived from the original on January 29, 2025. Retrieved January 30, 2025.\\n\\n^ Carroll, Rory (May 14, 2023). \"Irish Times apologises for hoax AI article about women\\'s use of fake tan\". The Guardian. ISSN\\xa00261-3077. Archived from the original on May 14, 2023. Retrieved January 8, 2024.\\n\\n^ Christian, Jon (February 1, 2023). \"CNET Sister Site Restarts AI Articles, Immediately Publishes Idiotic Error\". Futurism. Archived from the original on November 27, 2023. Retrieved January 8, 2024.\\n\\n^ Al-Sibai, Noor; Christian, Jon (March 30, 2023). \"BuzzFeed Is Quietly Publishing Entire AI-Generated Articles\". Futurism. Archived from the original on December 6, 2023. Retrieved January 8, 2024.\\n\\n^ \"Newsweek is making generative AI a fixture in its newsroom\". Nieman Lab. April 17, 2024. Archived from the original on May 15, 2024. Retrieved May 24, 2024.\\n\\n^ \"What\\'s in a byline? For Hoodline\\'s AI-generated local news, everything ‚Äî and nothing\". Nieman Lab. June 3, 2024. Archived from the original on June 6, 2024. Retrieved June 8, 2024.\\n\\n^ \"AI-generated news is here from S.F.-based Hoodline. What does that mean for conventional publishers?\". San Francisco Chronicle. May 8, 2024. Archived from the original on June 5, 2024. Retrieved June 7, 2024.\\n\\n^ Gold, Hadas (May 30, 2024). \"A national network of local news sites is publishing AI-written articles under fake bylines. Experts are raising alarm\". CNN. Archived from the original on June 6, 2024. Retrieved June 8, 2024.\\n\\n^ \"Wyoming reporter caught using artificial intelligence to create fake quotes and stories\". Associated Press. August 14, 2024. Archived from the original on August 24, 2024. Retrieved August 27, 2024.\\n\\n^ \"Cosmos Magazine publishes AI-generated articles, drawing criticism from journalists, co-founders\". ABC News. August 7, 2024. Archived from the original on August 24, 2024. Retrieved August 27, 2024.\\n\\n^ \"AI-generated articles are permeating major news publications\". National Public Radio. May 16, 2024. Archived from the original on June 19, 2024. Retrieved July 8, 2024.\\n\\n^ a b c Knibbs, Kate (July 30, 2024). \"Zombie Alt-Weeklies Are Stuffed With AI Slop About OnlyFans\". Wired. Archived from the original on August 11, 2024. Retrieved August 27, 2024.\\n\\n^ \"Apple says it will update AI feature after inaccurate news alerts\". The Guardian. January 7, 2025. Archived from the original on January 14, 2025. Retrieved January 14, 2025.\\n\\n^ \"TV channels are using AI-generated presenters to read the news. The question is, will we trust them?\". BBC News. January 26, 2024. Archived from the original on January 26, 2024. Retrieved May 24, 2024.\\n\\n^ Tait, Amelia (October 20, 2023). \"\\'Here is the news. You can\\'t stop us\\': AI anchor Zae-In grants us an interview\". The Guardian. ISSN\\xa00261-3077. Archived from the original on January 28, 2024. Retrieved May 24, 2024.\\n\\n^ Kuo, Lily (November 9, 2018). \"World\\'s first AI news anchor unveiled in China\". The Guardian. ISSN\\xa00261-3077. Archived from the original on February 20, 2024. Retrieved May 24, 2024.\\n\\n^ \"These ISIS news anchors are AI fakes. Their propaganda is real\". Washington Post. May 17, 2024. Archived from the original on May 19, 2024. Retrieved May 24, 2024.\\n\\n^ Mullin, Benjamin; Grant, Nico (July 20, 2023). \"Google Tests A.I. Tool That Is Able to Write News Articles\". The New York Times. ISSN\\xa00362-4331. Archived from the original on May 16, 2024. Retrieved May 24, 2024.\\n\\n^ Stenberg, Mark (February 27, 2024). \"Google Is Paying Publishers Five-Figure Sums to Test an Unreleased Gen AI Platform\". Adweek. Archived from the original on March 9, 2024. Retrieved April 17, 2024.\\n\\n^ Knibbs, Kate (February 7, 2024). \"Confessions of an AI Clickbait Kingpin\". Wired. ISSN\\xa01059-1028. Archived from the original on May 18, 2024. Retrieved May 24, 2024.\\n\\n^ Knibbs, Kate (January 26, 2024). \"How Beloved Indie Blog \\'The Hairpin\\' Turned Into an AI Clickbait Farm\". Wired. ISSN\\xa01059-1028. Archived from the original on April 14, 2024. Retrieved May 24, 2024.\\n\\n^ Koebler, Jason (July 9, 2024). \"A Beloved Tech Blog Is Now Publishing AI Articles Under the Names of Its Old Human Staff\". 404 Media. Archived from the original on July 12, 2024. Retrieved August 27, 2024.\\n\\n^ Hollister, Sean (July 10, 2024). \"Early Apple tech bloggers are shocked to find their name and work have been AI-zombified\". The Verge. Archived from the original on July 12, 2024. Retrieved August 27, 2024.\\n\\n^ \"AI slop is already invading Oregon\\'s local journalism\". Oregon Public Broadcasting. December 9, 2024. Archived from the original on December 9, 2024. Retrieved December 10, 2024.\\n\\n^ Knibbs, Kate (February 26, 2024). \"How a Small Iowa Newspaper\\'s Website Became an AI-Generated Clickbait Factory\". Wired. ISSN\\xa01059-1028. Archived from the original on February 26, 2024. Retrieved December 10, 2024.\\n\\n^ Koebler, Jason; Cole, Samantha; Maiberg, Emanuel; Cox, Joseph (January 26, 2024). \"We Need Your Email Address\". 404 Media. Archived from the original on December 2, 2024. Retrieved December 10, 2024.\\n\\n^ \"Meet the Serbian Businessman/DJ Who Runs the Zombie AI Southwest Journal - Racket\". Racket. February 16, 2024. Archived from the original on November 13, 2024. Retrieved December 10, 2024.\\n\\n^ Lima-Strong, Cristiano (January 11, 2024). \"Senators warn AI could lead to \\'destruction\\' of local news\". Washington Post. ISSN\\xa00190-8286. Archived from the original on January 11, 2024. Retrieved May 24, 2024.\\n\\n^ \"OpenAI strikes $5 million-plus local news deal\". Axios. July 18, 2023. Archived from the original on July 19, 2023. Retrieved May 24, 2024.\\n\\n^ Kelly, Heather (May 22, 2024). \"Meta walked away from news. Now the company\\'s using it for AI content\". Washington Post. ISSN\\xa00190-8286. Archived from the original on May 22, 2024. Retrieved May 24, 2024.\\n\\n^ \"How WIRED Will Use Generative AI Tools\". Wired. Archived from the original on December 30, 2023. Retrieved January 8, 2024.\\n\\n^ Barrett, Amanda (November 15, 2018). \"Standards around generative AI\". Associated Press. Archived from the original on September 23, 2023. Retrieved January 8, 2024.\\n\\n^ Viner, Katharine; Bateson, Anna (June 16, 2023). \"The Guardian\\'s approach to generative AI\". The Guardian. ISSN\\xa00261-3077. Archived from the original on January 3, 2024. Retrieved January 8, 2024.\\n\\n^ Becker, K. B.; Simon, F. M.; Crum, C. (2023). \"Policies in parallel? A comparative study of journalistic AI policies in 52 global news organisations\". pp.\\xa08‚Äì9. doi:10.31235/osf.io/c4af9.\\n\\n^ Newman, Nic; Fletcher, Richard; Robertson, Craig T.; Arguedas, Amy Ross; Nielsen, Rasmus Fleis (June 2024). \"Digital News Report 2024\" (PDF). Reuters Institute for the Study of Journalism. p.\\xa020. doi:10.60625/risj-vy6n-4v57. Retrieved June 20, 2024.\\n\\n\\nvteGenerative AIConcepts\\nAutoencoder\\nDeep learning\\nGenerative adversarial network\\nGenerative pre-trained transformer\\nLarge language model\\nNeural network\\nPrompt engineering\\nRetrieval-augmented generation\\nReinforcement learning from human feedback\\nSelf-supervised learning\\nTransformer\\nVariational autoencoder\\nVision transformer\\nWord embedding\\nModelsText\\nClaude\\nDBRX\\nGemini\\nGPT\\n1\\n2\\n3\\nJ\\nChatGPT\\n4\\n4o\\no1\\no3\\nGrok\\nGranite\\nLlama\\nMistral Large\\nPanGu-Œ£\\nQwen\\nImage\\nAurora\\nDALL-E\\nFirefly\\nFlux\\nIdeogram\\nMidjourney\\nStable Diffusion\\nVideo\\nDream Machine\\nGen-3 Alpha\\nHailuo AI\\nKling\\nSora\\nVeo\\nVideoPoet\\nMusic\\nUdio\\nSuno AI\\nCompanies\\n01.AI\\nAlibaba\\nAnthropic\\nBaichuan\\nDeepSeek\\nElevenLabs\\nGoogle DeepMind\\nHugging Face\\nKuaishou\\nMeta AI\\nMiniMax\\nMistral AI\\nMoonshot AI\\nOpenAI\\nRunway\\nStability AI\\nSynthesia\\nxAI\\nZhipu AI\\n\\n Category\\n Commons\\n\\nvteDigital artToolsHardware\\nComputer\\nCGI\\n2D graphics\\n2.5D\\n3D graphics\\nXerox\\n3D printer\\nSoftware\\nGraphic art software\\nFractal-generating software\\nAnimation software\\nForms\\nArt game\\nArtificial intelligence art\\nASCII art\\nComputer art scene\\nComputer music\\nCrypto art\\nCyberarts\\nDigital illustration\\nDigital imaging\\nDigital painting\\nDigital photography\\nDigital poetry\\nDigital architecture\\nElectronic music\\nEvolutionary art\\nFractal art\\nGenerative art\\nGenerative artificial intelligence\\nGenerative music\\nGIF art\\nGlitch art\\nImmersion\\nInteractive art\\nInternet art\\nMotion graphics\\nMusic visualization\\nPhotograph manipulation\\nPixel art\\nRender art\\nSoftware art\\nSystems art\\nTexture mapping\\nVirtual art\\nNotableartists\\nRefik Anadol\\nCory Arcangel\\nSougwen Chung\\nHarold Cohen\\nChar Davies\\nStephanie Dinkins\\nJake Elwes\\nDavid Em\\nDesmond Paul Henry\\nMario Klingemann\\nLynn Hershman Leeson\\nZachary Lieberman\\nMargot Lovejoy\\nMauro Martino\\nEric Millikin\\nHamid Naderi Yeganeh\\nTrevor Paglen\\nCasey Reas\\nAnna Ridler\\nBen Rubin (artist)\\nKarl Sims\\nCamille Utterback\\nPindar Van Arman\\nNotableartworks\\nEdmond de Belamy\\nBarnsley fern\\nJesus Dress Up\\nListening Post (artwork)\\nRemember To Rise\\nOrganizations,conferences\\nArtfutura\\nArtmedia\\nAustin Museum of Digital Art\\nComputer Arts Society\\nEVA Conferences\\nLos Angeles Center for Digital Art\\nLumen Prize\\nonedotzero\\nSIGGRAPH\\nV&A Digital Futures\\n\\n\\n\\n\\n\\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Generative_artificial_intelligence&oldid=1274593738\"\\nCategories: Artificial neural networksDeep learningMachine learningGenerative artificial intelligence2020s in computing2023 in computing2024 in computing2025 in computingHidden categories: CS1 Japanese-language sources (ja)CS1 Italian-language sources (it)Articles with short descriptionShort description is different from WikidataUse mdy dates from October 2023Articles needing cleanup from July 2024All pages needing cleanupWikipedia list cleanup from July 2024\\n\\n\\n\\n\\n\\n\\n This page was last edited on 8 February 2025, at 06:43\\xa0(UTC).\\nText is available under the Creative Commons Attribution-ShareAlike 4.0 License;\\nadditional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia¬Æ is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.\\n\\n\\nPrivacy policy\\nAbout Wikipedia\\nDisclaimers\\nContact Wikipedia\\nCode of Conduct\\nDevelopers\\nStatistics\\nCookie statement\\nMobile view\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nToggle the table of contents\\n\\n\\n\\n\\n\\n\\n\\nGenerative artificial intelligence\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n45 languages\\n\\n\\nAdd topic\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs_split"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KGORlcxzYb7",
        "outputId": "f9cbd1f9-b81b-4e4f-8951-682760a47e34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'https://www.ibm.com/think/topics/ai-agents', 'title': 'What Are AI Agents? | IBM', 'description': 'An artificial intelligence (AI) agent refers to a system or program that is capable of autonomously performing tasks on behalf of a user or another system.', 'language': 'en'}, page_content='What Are AI Agents? | IBM\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                        \\n\\n\\n\\n  \\n    What are AI agents?\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n                    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                                    Artificial Intelligence\\n                                \\n\\n\\n\\n\\n\\n\\n                    \\n\\n\\n\\n  \\n    3 July 2024\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n                \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Link copied\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        \\n\\n\\n\\n  \\n    Authors\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAnna Gutowska\\nData Scientist, Developer Advocacy, IBM\\n\\n\\n\\n\\n\\n\\n\\r\\n        What are AI agents?\\r\\n    \\n\\n\\n\\nAn\\xa0artificial intelligence (AI)\\xa0agent refers to a system or program that is capable of autonomously performing tasks on behalf of a user or another system by designing its workflow and utilizing available tools.'),\n",
              " Document(metadata={'source': 'https://www.ibm.com/think/topics/ai-agents', 'title': 'What Are AI Agents? | IBM', 'description': 'An artificial intelligence (AI) agent refers to a system or program that is capable of autonomously performing tasks on behalf of a user or another system.', 'language': 'en'}, page_content=\"AI agents can encompass a wide range of functionalities beyond natural language processing including decision-making, problem-solving, interacting with external environments and executing actions.\\nThese agents can be deployed in various applications to solve complex tasks in various enterprise contexts from software design and IT automation to code-generation tools and conversational assistants. They use the advanced natural language processing techniques of large language models (LLMs) to comprehend and respond to user inputs step-by-step and determine when to call on external tools.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\r\\n        How AI agents work\\r\\n    \\n\\n\\n\\nAt the core of AI agents are\\xa0large language models\\xa0(LLMs). For this reason, AI agents are often referred to as LLM agents.\\xa0Traditional\\xa0LLMs, such as\\xa0IBM®\\xa0Granite™ models,\\xa0produce their responses based on the data used to train them and are bounded by knowledge and reasoning limitations. In contrast, agentic technology uses tool calling on the backend to obtain up-to-date information, optimize workflow and create subtasks autonomously to achieve complex goals.\\nIn this process, the autonomous agent learns to adapt to user expectations over time. The agent's ability to store past interactions in memory and plan future actions encourages a personalized experience and comprehensive responses.1\\xa0This tool calling can be achieved without human intervention and broadens the possibilities for real-world applications of these AI systems.\\xa0The approach that\\xa0AI agents\\xa0take in achieving goals set by users is comprised of these three stages:\\n\\n\\nGoal initialization and planning\"),\n",
              " Document(metadata={'source': 'https://www.ibm.com/think/topics/ai-agents', 'title': 'What Are AI Agents? | IBM', 'description': 'An artificial intelligence (AI) agent refers to a system or program that is capable of autonomously performing tasks on behalf of a user or another system.', 'language': 'en'}, page_content=\"Although\\xa0AI agents\\xa0are autonomous in their\\xa0decision-making\\xa0processes, they require goals and environments defined by humans.2\\xa0There are three main influences on\\xa0autonomous agent\\xa0behavior:\\xa0\\nThe team of developers that design and train the agentic\\xa0AI system.\\xa0The team that deploys the agent and provides the user with access to it.The user that provides the\\xa0AI agent\\xa0with specific goals to accomplish and establishes available tools to use.\\nGiven the user's goals and the agent’s available tools, the\\xa0AI agent\\xa0then performs task decomposition to improve performance.3\\xa0Essentially, the agent creates a plan of\\xa0specific tasks\\xa0and subtasks to accomplish the complex goal. \\nFor simple tasks, planning is not a necessary step. Instead, an agent can iteratively reflect on its responses and improve them without planning its next steps.\\n\\n\\nReasoning using available tools\"),\n",
              " Document(metadata={'source': 'https://www.ibm.com/think/topics/ai-agents', 'title': 'What Are AI Agents? | IBM', 'description': 'An artificial intelligence (AI) agent refers to a system or program that is capable of autonomously performing tasks on behalf of a user or another system.', 'language': 'en'}, page_content='AI agents base their actions on the information they perceive. Often,\\xa0AI agents\\xa0do not have the full\\xa0knowledge base needed\\xa0for tackling all subtasks within a complex goal. To remedy this,\\xa0AI agents use their available tools. These tools can include external\\xa0data sets, web searches,\\xa0APIs and even other agents. After the missing information is retrieved from these tools, the agent can update its knowledge base. This means that each step of the way, the agent reassesses its plan of action and self-corrects.\\nTo help illustrate this process, imagine a user planning their vacation. The user tasks an AI agent with predicting which week in the next year would likely have the best weather for their surfing trip in Greece. Since the LLM model at the core of the agent does not specialize in weather patterns, the agent gathers information from an external database comprised of daily weather reports for Greece over the past several years.\\nDespite acquiring this new information, the agent still cannot determine the optimal weather conditions for surfing and so, the next subtask is created. For this subtask, the agent communicates with an external agent that specializes in surfing. Let’s say that in doing so, the agent learns that high tides and sunny weather with little to no rain provide the best surfing conditions.\\nThe agent can now combine the information it has learned from its tools to identify patterns. It can predict which week next year in Greece will likely have high tides, sunny weather and a low chance of rain. These findings are then presented to the user. This sharing of information between tools is what allows\\xa0AI agents\\xa0to be more general-purpose than traditional\\xa0AI models.3\\n\\n\\nLearning and reflection'),\n",
              " Document(metadata={'source': 'https://www.ibm.com/think/topics/ai-agents', 'title': 'What Are AI Agents? | IBM', 'description': 'An artificial intelligence (AI) agent refers to a system or program that is capable of autonomously performing tasks on behalf of a user or another system.', 'language': 'en'}, page_content=\"AI agents\\xa0use feedback mechanisms, such as other AI agents and human-in-the-loop (HITL), to improve the accuracy of their responses. Let’s return to our previous surfing example to highlight this. After the agent forms its response to the user, the agent stores the learned information along with the user’s feedback to improve performance and adjust to user preferences for future goals.\\nIf other agents were used to reach the goal, their feedback may also be used.\\xa0Multi-agent feedback can be especially useful in minimizing the time that human users spend providing direction. However, users can also provide feedback throughout the agent's actions and internal reasoning to better align the results with the intended goal.2\\nFeedback mechanisms improve the\\xa0AI agent's reasoning and accuracy, which is commonly referred to as iterative refinement.3\\xa0To avoid repeating the same mistakes,\\xa0AI agents\\xa0can also store data about solutions to previous obstacles in a\\xa0knowledge base.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nIndustry newsletter\\n\\n\\n\\nThe latest AI trends, brought to you by experts\\n\\n\\nThank you! You are subscribed.\\n\\n\\n\\nGet curated insights on the most important—and intriguing—AI news. Subscribe to our weekly Think newsletter. See the IBM Privacy Statement.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nYour subscription will be delivered in English. You will find an unsubscribe link in every newsletter. You can manage your subscriptions or unsubscribe here. Refer to our IBM Privacy Statement for more information.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\r\\n        Agentic versus non-agentic AI chatbots\"),\n",
              " Document(metadata={'source': 'https://www.ibm.com/think/topics/ai-agents', 'title': 'What Are AI Agents? | IBM', 'description': 'An artificial intelligence (AI) agent refers to a system or program that is capable of autonomously performing tasks on behalf of a user or another system.', 'language': 'en'}, page_content='AI\\xa0chatbots\\xa0use\\xa0conversational AI\\xa0techniques such as\\xa0natural language processing\\xa0(NLP) to understand user questions and automate responses to them. These chatbots are a modality whereas agency is a technological framework.\\xa0\\nNon-agentic AI chatbots are ones without available tools, memory and reasoning. They can only reach short-term goals and cannot plan ahead.\\xa0As we know them, non-agentic chatbots\\xa0require continuous user input to respond.\\xa0They can produce responses to common prompts that most likely align with user expectations but perform poorly on questions unique to the user and their data. Since these chatbots do not hold memory, they cannot learn from their mistakes if their responses are unsatisfactory.\\n\\nIn contrast,\\xa0agentic AI chatbots learn to adapt to user expectations over time, providing a more personalized experience and comprehensive responses. They can complete complex tasks by creating subtasks without\\xa0human intervention and considering different plans. These plans can also be self-corrected and updated as needed.\\xa0Agentic AI chatbots, unlike non-agentic ones, assess their tools and use their available resources to fill in information gaps.\\xa0\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n      Mixture of Experts | 7 February, episode 41\\n  \\n\\n\\n\\n\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            \\n\\n\\n\\n  \\n    Decoding AI: Weekly News Roundup\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n        \\n\\n\\nJoin our world-class panel of engineers, researchers, product leaders and more as they cut through the AI noise to bring you the latest in AI news and insights.\\n\\n\\n\\n\\nWatch the latest podcast episodes\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\r\\n        Reasoning paradigms\\r\\n    \\n\\n\\n\\nThere is not one standard architecture for building AI agents. Several paradigms exist for solving multi-step problems.\\n\\n\\nReAct (Reasoning and Action)'),\n",
              " Document(metadata={'source': 'https://www.ibm.com/think/topics/ai-agents', 'title': 'What Are AI Agents? | IBM', 'description': 'An artificial intelligence (AI) agent refers to a system or program that is capable of autonomously performing tasks on behalf of a user or another system.', 'language': 'en'}, page_content='With this paradigm, we can instruct agents to \"think\" and plan after each action taken and with each tool response to decide which tool to use next. These Think-Act-Observe loops are used to solve problems step by step and iteratively improve upon responses.\\nThrough the prompt structure, agents can be instructed to reason slowly and to display each \"thought\".4\\xa0The agent\\'s verbal reasoning gives insight into how responses are formulated. In this framework, agents continuously update their context with new reasoning. This can be interpreted as a form of\\xa0Chain-of-Thought prompting.\\n\\n\\nReWOO (Reasoning WithOut Observation)\\n\\n\\nThe ReWOO method, unlike ReAct, eliminates the dependence on tool outputs for action planning. Instead, agents plan upfront. Redundant tool usage is avoided by anticipating which tools to use upon receiving the initial prompt from the user. This is desirable from a human-centered perspective since the user can confirm the plan before it is executed.\\nThe ReWOO workflow is made up of three modules. In the planning module, the agent anticipates its next steps given a user\\'s prompt. The next stage entails collecting the outputs produced by calling these tools. Lastly, the agent pairs the initial plan with the tool outputs to formulate a response. This planning ahead can greatly reduce token usage and computational complexity as well as the repercussions of intermediate tool failure.5\\n\\n\\n\\r\\n        Types of AI agents\\r\\n    \\n\\n\\n\\nAI agents can be developed to have varying levels of capabilities. A simple agent may be preferred for straightforward goals to limit unnecessary computational complexity. In order of simplest to most advanced, there are 5 main agent types:\\n\\n\\n1. Simple reflex agents'),\n",
              " Document(metadata={'source': 'https://www.ibm.com/think/topics/ai-agents', 'title': 'What Are AI Agents? | IBM', 'description': 'An artificial intelligence (AI) agent refers to a system or program that is capable of autonomously performing tasks on behalf of a user or another system.', 'language': 'en'}, page_content='Simple reflex agents are the simplest agent form that grounds actions on current\\xa0perception. This agent does not hold any memory, nor does it interact with other agents if it is missing information. These\\xa0agents function\\xa0on a set of so-called reflexes or rules. This means that the agent is preprogrammed to perform actions that correspond to certain conditions being met.\\nIf the agent encounters a situation that it is not prepared for, it cannot respond appropriately. The agents are only effective in environments that are fully observable granting access to all necessary information.6\\nExample: A thermostat that turns on the heating system at a set time every night. The condition-action rule here is, for instance, if it is 8 PM, then the heating is activated.\\n\\n\\n\\n2. Model-based reflex agents\\n\\n\\nModel-based reflex agents use both their current\\xa0perception\\xa0and memory to maintain an internal model of the world. As the agent continues to receive new information, the model is updated. The agent’s actions depend on its model, reflexes, previous\\xa0precepts and current state.\\nThese agents, unlike\\xa0simple reflex agents, can store information in memory and can operate in environments that are partially observable and changing. However, they are still limited by their set of rules.6\\nExample: A robot vacuum cleaner. As it cleans a dirty room, it senses obstacles such as furniture and adjusts around them. The robot also stores a model of the areas it has already cleaned to not get stuck in a loop of repeated cleaning.\\n\\n\\n3. Goal-based agents\\n\\n\\nGoal-based agents have an internal model of the world and also a goal or set of goals. These agents search for action sequences that reach their goal and plan these actions before acting on them. This search and planning improve their effectiveness when compared to simple and\\xa0model-based reflex agents.7\\nExample: A navigation system that recommends the fastest route to your destination. The model considers various routes that reach your destination, or in other words, your goal. In this example, the agent’s condition-action rule states that if a quicker route is found, the agent recommends that one instead.\\n\\n\\n4. Utility-based agents'),\n",
              " Document(metadata={'source': 'https://www.ibm.com/think/topics/ai-agents', 'title': 'What Are AI Agents? | IBM', 'description': 'An artificial intelligence (AI) agent refers to a system or program that is capable of autonomously performing tasks on behalf of a user or another system.', 'language': 'en'}, page_content='Utility-based agents select the sequence of actions that reach the goal and also maximize utility or reward. Utility is calculated using a utility function. This function assigns a utility value, a metric measuring the usefulness of an action or how “happy” it will make the agent, to each scenario based on a set of fixed criteria.\\nThe criteria can include factors such as progression toward the goal, time requirements, or computational complexity. The agent then selects the actions that maximize the expected utility. Hence, these agents are useful in cases where multiple scenarios achieve a desired goal and an optimal one must be selected.7\\nExample: A navigation system that recommends the route to your destination that optimizes fuel efficiency and minimizes the time spent in traffic and the cost of tolls. This agent measures utility through this set of criteria to select the most favorable route.\\n\\n\\n5. Learning agents\\n\\n\\nLearning agents hold the same capabilities as the other agent types but are unique in their ability to learn. New experiences are added to their initial\\xa0knowledge base, which occurs autonomously. This learning enhances the agent’s ability to operate in unfamiliar environments.\\xa0Learning agents\\xa0may be utility or goal-based in their reasoning and are comprised of four main elements:7\\nLearning:\\xa0This\\xa0improves the agent’s knowledge by learning from the environment through its\\xa0precepts\\xa0and sensors.Critic:\\xa0This\\xa0provides feedback to the agent on whether the quality of its responses meets the performance standard.Performance:\\xa0This element is responsible for selecting actions upon learning.Problem\\xa0generator:\\xa0This\\xa0creates various proposals for actions to be taken.\\nExample: Personalized recommendations on e-commerce sites. These agents track user activity and preferences in their memory. This information is used to recommend certain products and services to the user. The cycle repeats each time new recommendations are made. The user’s activity is continuously stored for learning purposes. In doing so, the agent improves its accuracy over time.\\n\\n\\nUse cases of AI agents\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        \\n\\n\\n\\n  \\n    Customer experience'),\n",
              " Document(metadata={'source': 'https://www.ibm.com/think/topics/ai-agents', 'title': 'What Are AI Agents? | IBM', 'description': 'An artificial intelligence (AI) agent refers to a system or program that is capable of autonomously performing tasks on behalf of a user or another system.', 'language': 'en'}, page_content='AI agents can be integrated into websites and\\xa0apps\\xa0to enhance the\\xa0customer experience\\xa0by serving as a virtual assistants, providing mental health support, simulating interviews and other related tasks.8\\xa0There are many\\xa0no-code templates\\xa0for user implementation, making the process of creating these AI agents even easier.\\xa0\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        \\n\\n\\n\\n  \\n    Healthcare\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n    \\n\\n\\nAI agents\\xa0can be used for various\\xa0real-world healthcare\\xa0applications. Multi-agent systems can be particularly useful for problem-solving in such settings. From treatment planning for patients in the emergency department to managing drug processes, these systems save the time and effort of medical professionals for more urgent tasks.9\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        \\n\\n\\n\\n  \\n    Emergency response\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n    \\n\\n\\nIn case of natural disasters,\\xa0AI agents\\xa0can use\\xa0deep learning\\xa0algorithms\\xa0to retrieve the information of users on social media sites that need rescue. The locations of these users can be mapped to assist rescue services in saving more people in less time. Therefore,\\xa0AI agents\\xa0can greatly benefit human life in both mundane tasks and life-saving situations.10\\n\\n\\n\\n\\n\\n\\r\\n        Benefits of AI agents\\r\\n    \\n\\n\\n\\nTask automation\\n\\n\\nWith the ongoing\\xa0advancements\\xa0in\\xa0generative AI, there is a growing interest in workflow\\xa0optimization using AI, or intelligent automation.\\xa0AI agents\\xa0are\\xa0AI tools\\xa0that can\\xa0automate\\xa0complex tasks\\xa0that would otherwise require human resources. This translates to goals being reached inexpensively, rapidly and at scale. In turn, these\\xa0advancements\\xa0mean\\xa0human agents\\xa0do not need to provide direction to the\\xa0AI assistant\\xa0for creating and navigating its tasks.\\n\\n\\nGreater performance'),\n",
              " Document(metadata={'source': 'https://www.ibm.com/think/topics/ai-agents', 'title': 'What Are AI Agents? | IBM', 'description': 'An artificial intelligence (AI) agent refers to a system or program that is capable of autonomously performing tasks on behalf of a user or another system.', 'language': 'en'}, page_content='Multi-agent\\xa0frameworks\\xa0tend to outperform singular agents.11\\xa0This is because the more plans of action are available to an agent, the more learning and reflection occur. An AI agent incorporating knowledge and feedback from other\\xa0AI agents\\xa0specializing in related areas can be useful for information synthesis. This\\xa0backend\\xa0collaboration of AI agents and the ability to fill information gaps are unique to agentic frameworks, making them a powerful tool and a meaningful advancement in artificial intelligence.\\n\\n\\nQuality of responses\\n\\n\\nAI agents\\xa0provide responses that are more comprehensive, accurate and personalized to the user than traditional\\xa0AI models. This is extremely important to us as users since higher-quality responses typically yield a better customer experience. As previously described, this is made possible through exchanging information with other agents, using external tools and updating their memory stream. These behaviors emerge on their own and are not preprogrammed.12\\n\\n\\n\\r\\n        Risks and limitations\\r\\n    \\n\\n\\n\\nMulti-agent dependencies\\n\\n\\nCertain complex tasks require the knowledge of multiple AI agents. When implementing these multi-agent frameworks, there is a risk of malfunction. Multi-agent systems built on the same\\xa0foundation models\\xa0may experience shared pitfalls. Such weaknesses could cause a system-wide failure of all involved agents or expose vulnerability to adverse attacks.13\\xa0This highlights the importance of data governance in building foundation models and thorough training and testing processes.\\n\\n\\nInfinite feedback loops\\n\\n\\nThe convenience of the hands-off\\xa0reasoning for human users using\\xa0AI agents\\xa0also comes with its risks. Agents that are unable to create a comprehensive plan or reflect on their findings, may find themselves repeatedly calling the same tools, invoking infinite feedback loops. To avoid these redundancies, some level of\\xa0real-time\\xa0human monitoring may be used.13\\n\\n\\nComputational complexity\\n\\n\\nBuilding\\xa0AI agents\\xa0from scratch is both time-consuming and can also be very computationally expensive. The resources required for training a high-performance agent can be extensive. Additionally, depending on the complexity of the task, agents can take several days to complete tasks.12\\n\\n\\n\\r\\n        Best practices\\r\\n    \\n\\n\\n\\nActivity logs'),\n",
              " Document(metadata={'source': 'https://www.ibm.com/think/topics/ai-agents', 'title': 'What Are AI Agents? | IBM', 'description': 'An artificial intelligence (AI) agent refers to a system or program that is capable of autonomously performing tasks on behalf of a user or another system.', 'language': 'en'}, page_content=\"To address the concerns of multi-agent dependencies, developers can provide users with access to a log of agent actions.14\\xa0The actions can include the use of external tools and describe the external agents utilized to reach the goal. This transparency grants users insight into the iterative\\xa0decision-making\\xa0process, provides the opportunity to\\xa0discover\\xa0errors and builds trust.\\n\\n\\nInterruption\\n\\n\\nPreventing\\xa0AI agents\\xa0from running for overly long periods of time is recommended. Particularly, in cases of unintended infinite feedback loops, changes in access to certain tools, or malfunctioning due to design flaws. One way to accomplish this is by implementing interruptibility.\\nMaintaining control of this involves allowing human users the option to gracefully interrupt a sequence of actions or the entire operation. Choosing if and when to interrupt an\\xa0AI agent\\xa0requires some thoughtfulness as some terminations can cause more harm than good. For instance, it may be safer to allow a faulty agent to continue assisting in a life-threatening emergency than to completely shut it down.5\\n\\n\\nUnique agent identifiers\\n\\n\\nTo mitigate the risk of agentic systems being used for malicious use, unique identifiers can be used.14\\xa0If these identifiers were to be required for agents to access external systems, there would be greater ease in tracing the origin of the agent's developers, deployers and its user. This would be particularly helpful in case of any malicious use or unintended harm done by the agent. This level of accountability would provide a safer environment for these\\xa0AI agents\\xa0to operate.\\n\\n\\nHuman supervision\\n\\n\\nTo assist in the learning process for\\xa0AI agents, especially in their early stages in a new environment, it can be helpful to provide occasional human feedback. This allows the\\xa0AI agent\\xa0to compare its performance to the expected standard and adjust accordingly. This form of feedback is helpful in improving the agent’s adaptability to user preferences.5\\nApart from this, it is best practice to require human approval before an\\xa0AI agent\\xa0takes highly impactful actions. For instance, actions ranging from sending mass emails to financial trading should require human confirmation.7\\xa0Some level of human monitoring is recommended for such high-risk domains.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Ebook\"),\n",
              " Document(metadata={'source': 'https://www.ibm.com/think/topics/ai-agents', 'title': 'What Are AI Agents? | IBM', 'description': 'An artificial intelligence (AI) agent refers to a system or program that is capable of autonomously performing tasks on behalf of a user or another system.', 'language': 'en'}, page_content=\"How to choose the right foundation model\\n        \\nLearn how to choose the right approach in preparing datasets and employing foundation models.\\n\\nRead the ebook\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            \\n\\n\\n\\n  \\n    Resources\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Report\\n        \\n\\n            AI in Action 2024\\n        \\nWe surveyed 2,000 organizations about their AI initiatives to discover what's working, what's not and how you can get ahead.\\n\\nRead the report\\n\\n\\n\\n\\n\\n\\n\\n            AI models\\n        \\n\\n            Explore IBM Granite\\n        \\nIBM® Granite™ is our family of open, performant and trusted AI models, tailored for business and optimized to scale your AI applications. Explore language, code, time series and guardrail options.\\n\\nMeet Granite\\n\\n\\n\\n\\n\\n\\n\\n            Training\\n        \\n\\n            Level up your AI expertise\\n        \\nAccess our full catalog of over 100 online courses by purchasing an individual or multi-user subscription today, enabling you to expand your skills across a range of our products at one low price.\\n\\nStart learning\\n\\n\\n\\n\\n\\n\\n\\n            Video\\n        \\n\\n            IBM AI Academy\\n        \\nLed by top IBM thought leaders, the curriculum is designed to help business leaders gain the knowledge needed to prioritize the AI investments that can drive growth.\\n\\nExplore the series\\n\\n\\n\\n\\n\\n\\n\\n            Guide\"),\n",
              " Document(metadata={'source': 'https://www.ibm.com/think/topics/ai-agents', 'title': 'What Are AI Agents? | IBM', 'description': 'An artificial intelligence (AI) agent refers to a system or program that is capable of autonomously performing tasks on behalf of a user or another system.', 'language': 'en'}, page_content=\"Put AI to work: Driving ROI with gen AI\\n        \\nWant to get a better return on your AI investments? Learn how scaling gen AI in key areas drives change by helping your best minds build and deliver innovative new solutions.\\n\\nRead the guide\\n\\n\\n\\n\\n\\n\\n\\n            Ebook\\n        \\n\\n            Unlock the power of generative AI + ML\\n        \\nLearn how to confidently incorporate generative AI and machine learning into your business.\\n\\nRead the ebook\\n\\n\\n\\n\\n\\n\\n\\n            Guide\\n        \\n\\n            How to thrive in this new era of AI with trust and confidence\\n        \\nDive into the 3 critical elements of a strong AI strategy: creating a competitive edge, scaling AI across the business and advancing trustworthy AI.\\n\\nRead the guide\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            \\n            \\n\\n     \\n    Related AI topics\\n\\n\\n\\n\\n    \\n\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        \\n\\n\\n\\n  \\n    Mixture of Experts podcast\\n\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n    \\n\\n\\n\\nLet’s bust some early myths about DeepSeek! In\\r\\nMixture of Experts' episode 40, the panel tackles DeepSeek R1 misconceptions, explains\\r\\nmodel distillation, and dissects the open-source competition landscape.\\n\\n\\n\\nDeepSeek facts vs hype, model distillation, and open source competition\"),\n",
              " Document(metadata={'source': 'https://www.ibm.com/think/topics/ai-agents', 'title': 'What Are AI Agents? | IBM', 'description': 'An artificial intelligence (AI) agent refers to a system or program that is capable of autonomously performing tasks on behalf of a user or another system.', 'language': 'en'}, page_content=\"Artificial intelligence solutions\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n    \\n\\n\\n\\nPut AI to work in your business with IBM's industry-leading AI expertise and portfolio of solutions at your side.\\n\\n\\n\\nExplore AI solutions\\n            \\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        \\n\\n\\n\\n  \\n    AI consulting and services\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n    \\n\\n\\n\\nReinvent critical workflows and operations by adding AI to maximize experiences, real-time decision-making and business value.\\n\\n\\n\\nExplore AI services\\n            \\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTake the next step\\n\\n\\n\\n\\nGet one-stop access to capabilities that span the AI development lifecycle. Produce powerful AI solutions with user-friendly interfaces, workflows and access to industry-standard APIs and SDKs.\\n\\n\\n\\n\\n\\nExplore watsonx.ai\\n\\n\\n\\nBook a live demo\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                            \\n\\n\\n\\n  \\n    Footnotes\"),\n",
              " Document(metadata={'source': 'https://www.ibm.com/think/topics/ai-agents', 'title': 'What Are AI Agents? | IBM', 'description': 'An artificial intelligence (AI) agent refers to a system or program that is capable of autonomously performing tasks on behalf of a user or another system.', 'language': 'en'}, page_content='1\\xa0Andrew Zhao, Daniel Huang, Quentin Xu, Matthieu Lin, Yong-Jin Liu, and Gao Huang, \"Expel:\\xa0Llm\\xa0agents are experiential learners,\"\\xa0Proceedings of the AAAI Conference on\\xa0Artificial Intelligence, Vol. 38, No. 17, pp. 19632-19642, 2024,\\xa0https://ojs.aaai.org/index.php/AAAI/article/view/29936\\xa0(link resides outside of ibm.com).\\n2\\xa0Yonadov Shavit, Sandhini Agarwal, Miles Brundage, Steven Adler, Cullen O’Keefe, Rosie Campbell, Teddy Lee, Pamela Mishkin, Tyna Eloundou, Alan Hickey, Katarina Slama, Lama Ahmad, Paul McMillan, Alex Beutel, Alexandre Passos and David G. Robinson, “Practices for Governing Agentic\\xa0AI Systems,”\\xa0OpenAI, 2023,\\xa0https://arxiv.org/pdf/2401.13138v3\\xa0(link resides outside of ibm.com).\\n3\\xa0Tula Masterman, Sandi Besen, Mason Sawtell, Alex Chao, “The Landscape of Emerging\\xa0AI AgentArchitectures for Reasoning, Planning, and Tool Calling: A Survey,”\\xa0arXiv preprint, 2024,\\xa0https://arxiv.org/abs/2404.11584\\xa0(link resides outside of ibm.com).\\n4\\xa0Gautier Dagan, Frank Keller, and Alex Lascarides, \"Dynamic Planning with a LLM,\" arXiv preprint,\\xa02023.\\xa0https://arxiv.org/abs/2308.06391\\xa0(link resides outside of ibm.com).\\n5\\xa0Binfeng Xu, Zhiyuan Peng, Bowen Lei, Subhabrata Mukherjee, Yuchen Liu, and Dongkuan Xu, \"ReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models,\" arXiv preprint, 2023,\\xa0https://arxiv.org/abs/2305.18323\\xa0(link resides outside of ibm.com).'),\n",
              " Document(metadata={'source': 'https://www.ibm.com/think/topics/ai-agents', 'title': 'What Are AI Agents? | IBM', 'description': 'An artificial intelligence (AI) agent refers to a system or program that is capable of autonomously performing tasks on behalf of a user or another system.', 'language': 'en'}, page_content='6\\xa0Sebastian Schmid, Daniel Schraudner, and Andreas Harth, \"Performance comparison of\\xa0simple reflex agents using stigmergy with model-based agents in self-organizing transportation.\"\\xa0IEEE International Conference on Autonomic Computing and Self-Organizing Systems Companion, pp. 93-98, 2021,\\xa0https://ieeexplore.ieee.org/document/9599196\\xa0(link resides outside of ibm.com).\\n7\\xa0Veselka Sasheva Petrova-Dimitrova, “Classifications of intelligence agents and their applications,”\\xa0Fundamental Sciences and Applications, Vol. 28, No. 1, 2022.\\n8\\xa0Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, Wayne Xin Zhao, Zhewei Wei, and Jirong Wen, “A survey on\\xa0large language model\\xa0based\\xa0autonomous agents,”\\xa0Frontiers of Computer Science, Vol. 18, No. 6, 2024,\\xa0https://link.springer.com/article/10.1007/s11704-024-40231-1\\xa0(link resides outside of ibm.com).\\n9\\xa0Jaya R. Haleema, Haleema, N. C. S. N. Narayana, “Enhancing a Traditional Health Care System of an Organization for Better Service with Agent Technology by Ensuring Confidentiality of Patients’ Medical Information,”\\xa0Cybernetics and Information Technologies, Vol. 12, No. 3, pp.140-156, 2013,\\xa0https://sciendo.com/article/10.2478/cait-2013-0031.\\n10\\xa0Jingwei Huang, Wael Khallouli, Ghaith Rabadi, Mamadou Seck, “Intelligent Agent for Hurricane Emergency Identification and Text Information Extraction from Streaming Social Media Big Data,”\\xa0International Journal of Critical Infrastructures, Vol. 19, No. 2, pp. 124-139, 2023,\\xa0https://arxiv.org/abs/2106.07114.'),\n",
              " Document(metadata={'source': 'https://www.ibm.com/think/topics/ai-agents', 'title': 'What Are AI Agents? | IBM', 'description': 'An artificial intelligence (AI) agent refers to a system or program that is capable of autonomously performing tasks on behalf of a user or another system.', 'language': 'en'}, page_content='11\\xa0Junyou Li, Qin Zhang, Yangbin Yu, Qiang Fu, and Deheng Ye. \"More agents is all you need.\"\\xa0arXiv preprint, 2024,\\xa0https://arxiv.org/abs/2402.05120.\\n12\\xa0Joon Sung Park, Joseph O\\'Brien, Carrie Jun Cai, Meredith Ringel Morris, Percy Liang, and Michael S. Bernstein, \"Generative\\xa0agents: Interactive simulacra of human behavior,\"\\xa0Proceedings of the 36th Annual ACM Symposium on User Interface software and Technology, pp. 1-22, 2023,\\xa0https://dl.acm.org/doi/10.1145/3586183.3606763.\\n13\\xa0Alan Chan, Carson Ezell, Max Kaufmann, Kevin Wei, Lewis Hammond, Herbie Bradley, Emma Bluemke, Nitarshan Rajkumar, David Krueger, Noam Kolt, Lennart Heim and Markus Anderljung, “Visibility into\\xa0AI Agents,”\\xa0The 2024 ACM Conference on Fairness, Accountability, and Transparency, pp. 958-973, 2024,\\xa0https://arxiv.org/abs/2401.13138.\\n14\\xa0Devjeet Roy, Xuchao Zhang, Rashi Bhave, Chetan Bansal, Pedro Las-Casas, Rodrigo Fonseca, and Saravan Rajmohan, \"Exploring LLM-based Agents for Root Cause Analysis,\" arXiv preprint, 2024, https://arxiv.org/abs/2403.04123.'),\n",
              " Document(metadata={'source': 'https://www.ibm.com/think/topics/large-language-models', 'title': 'What Are Large Language Models (LLMs)? | IBM ', 'description': 'Large language models are AI systems capable of understanding and generating human language by processing vast amounts of text data.\\r\\n\\r\\n\\r\\n\\r\\n', 'language': 'en'}, page_content='What Are Large Language Models (LLMs)? | IBM \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                        \\n\\n\\n\\n  \\n    What are large language models (LLMs)?\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n                    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                                    Artificial Intelligence\\n                                \\n\\n\\n\\n\\n\\n\\n                    \\n\\n\\n\\n  \\n    2 November 2023\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n                \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Link copied\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\r\\n        What are LLMs?\\r\\n    \\n\\n\\n\\nLarge language models (LLMs) are a category of foundation models trained on immense amounts of data making them capable of understanding and generating natural language and other types of content to perform a wide range of tasks.'),\n",
              " Document(metadata={'source': 'https://www.ibm.com/think/topics/large-language-models', 'title': 'What Are Large Language Models (LLMs)? | IBM ', 'description': 'Large language models are AI systems capable of understanding and generating human language by processing vast amounts of text data.\\r\\n\\r\\n\\r\\n\\r\\n', 'language': 'en'}, page_content='LLMs have become a household name thanks to the role they have played in bringing generative AI to the forefront of the public interest, as well as the point on which organizations are focusing to adopt artificial intelligence across numerous business functions and use cases.\\nOutside of the enterprise context, it may seem like LLMs have arrived out of the blue along with new developments in generative AI. However, many companies, including IBM, have spent years implementing LLMs at different levels to enhance their natural language understanding (NLU) and natural language processing (NLP) capabilities. This has occurred alongside advances in machine learning, machine learning models, algorithms, neural networks and the transformer models that provide the architecture for these AI systems.\\nLLMs are a class of foundation models, which are trained on enormous amounts of data to provide the foundational capabilities needed to drive multiple use cases and applications, as well as resolve a multitude of tasks. This is in stark contrast to the idea of building and training domain specific models for each of these use cases individually, which is prohibitive under many criteria (most importantly cost and infrastructure), stifles synergies and can even lead to inferior performance.\\nLLMs represent a significant breakthrough in NLP and artificial intelligence, and are easily accessible to the public through interfaces like Open AI’s Chat GPT-3 and GPT-4, which have garnered the support of Microsoft. Other examples include Meta’s Llama models and Google’s bidirectional encoder representations from transformers (BERT/RoBERTa) and PaLM models. IBM has also recently launched its Granite model series on watsonx.ai, which has become the generative AI backbone for other IBM products like watsonx Assistant and watsonx Orchestrate.\\xa0\\nIn a nutshell, LLMs are designed to understand and generate text like a human, in addition to other forms of content, based on the vast amount of data used to train them. They have the ability to infer from context, generate coherent and contextually relevant responses, translate to languages other than English, summarize text, answer questions (general conversation and FAQs) and even assist in creative writing or code generation tasks.'),\n",
              " Document(metadata={'source': 'https://www.ibm.com/think/topics/large-language-models', 'title': 'What Are Large Language Models (LLMs)? | IBM ', 'description': 'Large language models are AI systems capable of understanding and generating human language by processing vast amounts of text data.\\r\\n\\r\\n\\r\\n\\r\\n', 'language': 'en'}, page_content='They are able to do this thanks to billions of parameters that enable them to capture intricate patterns in language and perform a wide array of language-related tasks. LLMs are revolutionizing applications in various fields, from chatbots and virtual assistants to content generation, research assistance and language translation.\\nAs they continue to evolve and improve, LLMs are poised to reshape the way we interact with technology and access information, making them a pivotal part of the modern digital landscape.'),\n",
              " Document(metadata={'source': 'https://www.ibm.com/think/topics/large-language-models', 'title': 'What Are Large Language Models (LLMs)? | IBM ', 'description': 'Large language models are AI systems capable of understanding and generating human language by processing vast amounts of text data.\\r\\n\\r\\n\\r\\n\\r\\n', 'language': 'en'}, page_content='Industry newsletter\\n\\n\\n\\nThe latest tech news, backed by expert insight\\n\\n\\nThank you! You are subscribed.\\n\\n\\n\\nStay up to date on the most important—and intriguing—industry trends on AI, automation, data and beyond with the Think newsletter.\\xa0See the\\xa0IBM Privacy Statement.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nYour subscription will be delivered in English. You will find an unsubscribe link in every newsletter. You can manage your subscriptions or unsubscribe here. Refer to our IBM Privacy Statement for more information.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\r\\n        How large language models work'),\n",
              " Document(metadata={'source': 'https://www.ibm.com/think/topics/large-language-models', 'title': 'What Are Large Language Models (LLMs)? | IBM ', 'description': 'Large language models are AI systems capable of understanding and generating human language by processing vast amounts of text data.\\r\\n\\r\\n\\r\\n\\r\\n', 'language': 'en'}, page_content=\"LLMs operate by leveraging deep learning techniques and vast amounts of textual data. These models are typically based on a transformer architecture, like the generative pre-trained transformer, which excels at handling sequential data like text input. LLMs consist of multiple layers of neural networks, each with parameters that can be fine-tuned during training, which are enhanced further by a numerous layer known as the attention mechanism, which dials in on specific parts of data sets.\\nDuring the training process, these models learn to predict the next word in a sentence based on the context provided by the preceding words. The model does this through attributing a probability score to the recurrence of words that have been tokenized— broken down into smaller sequences of characters. These tokens are then transformed into embeddings, which are numeric representations of this context.\\nTo ensure accuracy, this process involves training the LLM on a massive corpora of text (in the billions of pages), allowing it to learn grammar, semantics and conceptual relationships through zero-shot and self-supervised learning. Once trained on this training data, LLMs can generate text by autonomously predicting the next word based on the input they receive, and drawing on the patterns and knowledge they've acquired. The result is coherent and contextually relevant language generation that can be harnessed for a wide range of NLU and content generation tasks.\\nModel performance can also be increased through prompt engineering, prompt-tuning, fine-tuning and other tactics like reinforcement learning with human feedback (RLHF) to remove the biases, hateful speech and factually incorrect answers known as “hallucinations” that are often unwanted byproducts of training on so much unstructured data. This is one of the most important aspects of ensuring enterprise-grade LLMs are ready for use and do not expose organizations to unwanted liability, or cause damage to their reputation.\\xa0\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n  \\n      AI Academy\\n  \\n\\n\\n\\n\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            \\n\\n\\n\\n  \\n    Why foundation models are a paradigm shift for AI\"),\n",
              " Document(metadata={'source': 'https://www.ibm.com/think/topics/large-language-models', 'title': 'What Are Large Language Models (LLMs)? | IBM ', 'description': 'Large language models are AI systems capable of understanding and generating human language by processing vast amounts of text data.\\r\\n\\r\\n\\r\\n\\r\\n', 'language': 'en'}, page_content='Learn about a new class of flexible, reusable AI models that can unlock new revenue, reduce costs and increase productivity, then use our guidebook to dive deeper.\\n\\n\\n\\n\\nGo to episode\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\r\\n        LLM use cases\\xa0\\r\\n    \\n\\n\\n\\nLLMs are redefining an increasing number of business processes and have proven their versatility across a myriad of use cases and tasks in various industries. They augment conversational AI in chatbots and virtual assistants (like IBM watsonx Assistant and Google’s BARD) to enhance the interactions that underpin excellence in customer care, providing context-aware responses that mimic interactions with human agents.\\nLLMs also excel in content generation, automating content creation for blog articles, marketing or sales materials and other writing tasks. In research and academia, they aid in summarizing and extracting information from vast datasets, accelerating knowledge discovery. LLMs also play a vital role in language translation, breaking down language barriers by providing accurate and contextually relevant translations. They can even be used to write code, or “translate” between programming languages.\\nMoreover, they contribute to accessibility by assisting individuals with disabilities, including text-to-speech applications and generating content in accessible formats. From healthcare to finance, LLMs are transforming industries by streamlining processes, improving customer experiences and enabling more efficient and data-driven decision making.\\nMost excitingly, all of these capabilities are easy to access, in some cases literally an API integration away.\\nHere is a list of some of the most important areas where LLMs benefit organizations:\\nText generation: language generation abilities, such as writing emails, blog posts or other mid-to-long form content in response to prompts that can be refined and polished. An excellent example is retrieval-augmented generation (RAG).\\xa0\\n\\nContent summarization: summarize long articles, news stories, research reports, corporate documentation and even customer history into thorough texts tailored in length to the output format.\\n\\nAI assistants: chatbots that answer customer queries, perform backend tasks and provide detailed information in natural language as a part of an integrated, self-serve customer care solution.\\xa0\\n\\nCode generation: assists developers in building applications, finding errors in code and uncovering security issues in multiple programming languages, even “translating” between them.'),\n",
              " Document(metadata={'source': 'https://www.ibm.com/think/topics/large-language-models', 'title': 'What Are Large Language Models (LLMs)? | IBM ', 'description': 'Large language models are AI systems capable of understanding and generating human language by processing vast amounts of text data.\\r\\n\\r\\n\\r\\n\\r\\n', 'language': 'en'}, page_content='Sentiment analysis: analyze text to determine the customer’s tone in order understand customer feedback at scale and aid in brand reputation management.\\xa0\\n\\nLanguage translation: provides wider coverage to organizations across languages and geographies with fluent translations and multilingual capabilities.\\n\\nLLMs stand to impact every industry, from finance to insurance, human resources to healthcare and beyond, by automating customer self-service, accelerating response times on an increasing number of tasks as well as providing greater accuracy, enhanced routing and intelligent context gathering.\\n\\n\\n\\r\\n        LLMs and governance\\r\\n    \\n\\n\\n\\nOrganizations need a solid foundation in governance practices to harness the potential of AI models to revolutionize the way they do business. This means providing access to AI tools and technology that is trustworthy, transparent, responsible and secure. AI governance and traceability are also fundamental aspects of the solutions IBM brings to its customers, so that activities that involve AI are managed and monitored to allow for tracing origins, data and models in a way that is always auditable and accountable.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Ebook\\n        \\n\\n            How to choose the right foundation model\\n        \\nLearn how to choose the right approach in preparing datasets and employing foundation models.\\n\\nRead the ebook\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            \\n            \\n\\n     \\n    Related solutions\\n\\n\\n\\n\\n    \\n\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        \\n\\n\\n\\n  \\n    Foundation models\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n    \\n\\n\\n\\nExplore the IBM library of foundation models on the watsonx platform to scale generative AI for your business with confidence.\\n\\n\\n\\nDiscover watsonx.ai'),\n",
              " Document(metadata={'source': 'https://www.ibm.com/think/topics/large-language-models', 'title': 'What Are Large Language Models (LLMs)? | IBM ', 'description': 'Large language models are AI systems capable of understanding and generating human language by processing vast amounts of text data.\\r\\n\\r\\n\\r\\n\\r\\n', 'language': 'en'}, page_content=\"Artificial intelligence solutions\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n    \\n\\n\\n\\nPut AI to work in your business with IBM's industry-leading AI expertise and portfolio of solutions at your side.\\n\\n\\n\\nExplore AI solutions\\n            \\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        \\n\\n\\n\\n  \\n    AI consulting and services\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n    \\n\\n\\n\\nReinvent critical workflows and operations by adding AI to maximize experiences, real-time decision-making and business value.\\n\\n\\n\\nExplore AI services\\n            \\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            \\n\\n\\n\\n  \\n    Resources\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            AI models\\n        \\n\\n            Explore IBM Granite\\n        \\nIBM® Granite™ is our family of open, performant and trusted AI models, tailored for business and optimized to scale your AI applications. Explore language, code, time series and guardrail options.\\n\\nMeet Granite\\n\\n\\n\\n\\n\\n\\n\\n            Ebook\\n        \\n\\n            How to choose the right foundation model\\n        \\nLearn how to select the most suitable AI foundation model for your use case.\\n\\nRead the ebook\\n\\n\\n\\n\\n\\n\\n\\n            Article\"),\n",
              " Document(metadata={'source': 'https://www.ibm.com/think/topics/large-language-models', 'title': 'What Are Large Language Models (LLMs)? | IBM ', 'description': 'Large language models are AI systems capable of understanding and generating human language by processing vast amounts of text data.\\r\\n\\r\\n\\r\\n\\r\\n', 'language': 'en'}, page_content=\"Discover the power of LLMs\\n        \\nDive into IBM Developer articles, blogs and tutorials to deepen your knowledge of LLMs.\\n\\nExplore the articles\\n\\n\\n\\n\\n\\n\\n\\n            Guide\\n        \\n\\n            The CEO's guide to model optimization\\n        \\nLearn how to continually push teams to improve model performance and outpace the competition by using the latest AI techniques and infrastructure.\\n\\nRead the guide\\n\\n\\n\\n\\n\\n\\n\\n            Report\\n        \\n\\n            A differentiated approach to AI foundation models\\n        \\nExplore the value of enterprise-grade foundation models that\\r\\nprovide trust, performance and cost-effective benefits to\\r\\nall industries.\\n\\nRead the report\\n\\n\\n\\n\\n\\n\\n\\n            Ebook\\n        \\n\\n            Unlock the Power of Generative AI + ML\\n        \\nLearn how to incorporate generative AI, machine learning and foundation models into your business operations for improved performance.\\n\\nRead the ebook\\n\\n\\n\\n\\n\\n\\n\\n            Report\\n        \\n\\n            AI in Action 2024\\n        \\nWe surveyed 2,000 organizations about their AI initiatives to discover what's working, what's not and how you can get ahead.\\n\\nRead the report\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTake the next step\\n\\n\\n\\n\\nExplore the IBM library of foundation models on the IBM watsonx platform to scale generative AI for your business with confidence.\\n\\n\\n\\n\\n\\nExplore watsonx.ai\\n\\n\\n\\nExplore AI solutions\"),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='Generative artificial intelligence - Wikipedia\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to content\\n\\n\\n\\n\\n\\n\\n\\nMain menu\\n\\n\\n\\n\\n\\nMain menu\\nmove to sidebar\\nhide\\n\\n\\n\\n\\t\\tNavigation\\n\\t\\n\\n\\nMain pageContentsCurrent eventsRandom articleAbout WikipediaContact us\\n\\n\\n\\n\\n\\n\\t\\tContribute\\n\\t\\n\\n\\nHelpLearn to editCommunity portalRecent changesUpload file\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAppearance\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDonate\\n\\nCreate account\\n\\nLog in\\n\\n\\n\\n\\n\\n\\n\\n\\nPersonal tools\\n\\n\\n\\n\\n\\nDonate Create account Log in\\n\\n\\n\\n\\n\\n\\t\\tPages for logged out editors learn more\\n\\n\\n\\nContributionsTalk\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nContents\\nmove to sidebar\\nhide\\n\\n\\n\\n\\n(Top)\\n\\n\\n\\n\\n\\n1\\nHistory\\n\\n\\n\\n\\nToggle History subsection\\n\\n\\n\\n\\n\\n1.1\\nEarly history\\n\\n\\n\\n\\n\\n\\n\\n\\n1.2\\nAcademic artificial intelligence\\n\\n\\n\\n\\n\\n\\n\\n\\n1.3\\nGenerative neural nets (2014-2019)\\n\\n\\n\\n\\n\\n\\n\\n\\n1.4\\nGenerative AI boom (2020-)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n2\\nModalities\\n\\n\\n\\n\\nToggle Modalities subsection\\n\\n\\n\\n\\n\\n2.1\\nText\\n\\n\\n\\n\\n\\n\\n\\n\\n2.2\\nCode\\n\\n\\n\\n\\n\\n\\n\\n\\n2.3\\nImages\\n\\n\\n\\n\\n\\n\\n\\n\\n2.4\\nAudio\\n\\n\\n\\n\\n\\n\\n2.4.1\\nMusic\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n2.5\\nVideo\\n\\n\\n\\n\\n\\n\\n\\n\\n2.6\\nActions\\n\\n\\n\\n\\n\\n\\n\\n\\n2.7\\n3D modeling\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n3\\nSoftware and hardware\\n\\n\\n\\n\\n\\n\\n\\n\\n4\\nLaw and regulation\\n\\n\\n\\n\\nToggle Law and regulation subsection\\n\\n\\n\\n\\n\\n4.1\\nCopyright\\n\\n\\n\\n\\n\\n\\n4.1.1\\nTraining with copyrighted content\\n\\n\\n\\n\\n\\n\\n\\n\\n4.1.2\\nCopyright of AI-generated content\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n5\\nConcerns\\n\\n\\n\\n\\nToggle Concerns subsection\\n\\n\\n\\n\\n\\n5.1\\nJob losses\\n\\n\\n\\n\\n\\n\\n\\n\\n5.2\\nRacial and gender bias'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='5.3\\nDeepfakes\\n\\n\\n\\n\\n\\n\\n5.3.1\\nAudio deepfakes\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n5.4\\nCybercrime\\n\\n\\n\\n\\n\\n\\n\\n\\n5.5\\nReliance on industry giants\\n\\n\\n\\n\\n\\n\\n\\n\\n5.6\\nEnergy and environment\\n\\n\\n\\n\\n\\n\\n\\n\\n5.7\\nContent quality\\n\\n\\n\\n\\n\\n\\n\\n\\n5.8\\nMisuse in journalism\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n6\\nSee also\\n\\n\\n\\n\\n\\n\\n\\n\\n7\\nReferences\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nToggle the table of contents\\n\\n\\n\\n\\n\\n\\n\\nGenerative artificial intelligence\\n\\n\\n\\n45 languages'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='ÿßŸÑÿπÿ±ÿ®Ÿäÿ©Az…ôrbaycanca‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ–ë–µ–ª–∞—Ä—É—Å–∫–∞—èBosanskiCatal√†ƒåe≈°tinaDanskDeutschŒïŒªŒªŒ∑ŒΩŒπŒ∫Œ¨Espa√±olEsperantoEuskaraŸÅÿßÿ±ÿ≥€åFran√ßaisÌïúÍµ≠Ïñ¥’Ä’°’µ’•÷Ä’•’∂Bahasa IndonesiaIsiZuluItaliano◊¢◊ë◊®◊ô◊™KiswahiliMagyar‡§Æ‡§∞‡§æ‡§†‡•Ä–ú–æ–Ω–≥–æ–ªNederlandsÊó•Êú¨Ë™ûNorsk bokm√•lO\\xa0ªzbekcha / —û–∑–±–µ–∫—á–∞PolskiPortugu√™sQaraqalpaqshaRom√¢nƒÉRuna Simi–†—É—Å—Å–∫–∏–πSimple English⁄©Ÿàÿ±ÿØ€å–°—Ä–ø—Å–∫–∏ / srpskiSvenska‡πÑ‡∏ó‡∏¢T√ºrk√ße–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞Ti·∫øng Vi·ªátÁ≤µË™û‰∏≠Êñá\\n\\nEdit links'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content=\"ArticleTalk\\n\\n\\n\\n\\n\\nEnglish\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nReadEditView history\\n\\n\\n\\n\\n\\n\\n\\nTools\\n\\n\\n\\n\\n\\nTools\\nmove to sidebar\\nhide\\n\\n\\n\\n\\t\\tActions\\n\\t\\n\\n\\nReadEditView history\\n\\n\\n\\n\\n\\n\\t\\tGeneral\\n\\t\\n\\n\\nWhat links hereRelated changesUpload fileSpecial pagesPermanent linkPage informationCite this pageGet shortened URLDownload QR code\\n\\n\\n\\n\\n\\n\\t\\tPrint/export\\n\\t\\n\\n\\nDownload as PDFPrintable version\\n\\n\\n\\n\\n\\n\\t\\tIn other projects\\n\\t\\n\\n\\nWikimedia CommonsWikidata item\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAppearance\\nmove to sidebar\\nhide\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFrom Wikipedia, the free encyclopedia\\n\\n\\nAI system capable of generating content in response to prompts\\n\\n\\nNot to be confused with Artificial general intelligence. This page focuses on statistical machine learning AI. For other topics, see Algorithmic composition, Algorithm art, Generative art, Procedural generation.\\nTh√©√¢tre D'op√©ra Spatial, an image made using generative artificial intelligence \\nPart of a series onArtificial intelligence (AI)\\nMajor goals\\nArtificial general intelligence\\nIntelligent agent\\nRecursive self-improvement\\nPlanning\\nComputer vision\\nGeneral game playing\\nKnowledge reasoning\\nNatural language processing\\nRobotics\\nAI safety\\n\\nApproaches\\nMachine learning\\nSymbolic\\nDeep learning\\nBayesian networks\\nEvolutionary algorithms\\nHybrid intelligent systems\\nSystems integration\\n\\nApplications\\nBioinformatics\\nDeepfake\\nEarth sciences\\n Finance \\nGenerative AI\\nArt\\nAudio\\nMusic\\nGovernment\\nHealthcare\\nMental health\\nIndustry\\nTranslation\\n Military \\nPhysics\\nProjects\\n\\nPhilosophy\\nArtificial consciousness\\nChinese room\\nFriendly AI\\nControl problem/Takeover\\nEthics\\nExistential risk\\nTuring test\\nUncanny valley\\n\\nHistory\\nTimeline\\nProgress\\nAI winter\\nAI boom\"),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='Glossary\\nGlossary\\nvte\\nGenerative artificial intelligence (generative AI, GenAI,[1] or GAI) is a subset of artificial intelligence that uses generative models to produce text, images, videos, or other forms of data.[2][3][4] These models learn the underlying patterns and structures of their training data and use them to produce new data[5][6] based on the input, which often comes in the form of natural language prompts.[7][8]\\nImprovements in transformer-based deep neural networks, particularly large language models (LLMs), enabled an AI boom of generative AI systems in the 2020s. These include chatbots such as ChatGPT, Copilot, Gemini, and LLaMA; text-to-image artificial intelligence image generation systems such as Stable Diffusion, Midjourney, and DALL-E; and text-to-video AI generators such as Sora.[9][10][11][12] Companies such as OpenAI, Anthropic, Microsoft, Google, and Baidu as well as numerous smaller firms have developed generative AI models.[7][13][14]\\nGenerative AI has uses across a wide range of industries, including software development, healthcare, finance, entertainment, customer service,[15] sales and marketing,[16] art, writing,[17] fashion,[18] and product design.[19] However, concerns have been raised about the potential misuse of generative AI such as cybercrime, the use of fake news or deepfakes to deceive or manipulate people, and the mass replacement of human jobs.[20][21] Intellectual property law concerns also exist around generative models that are trained on and emulate copyrighted works of art.[22]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='History[edit]\\nMain article: History of artificial intelligence\\nEarly history[edit]\\nSince its inception, researchers in the field have raised philosophical and ethical arguments about the nature of the human mind and the consequences of creating artificial beings with human-like intelligence; these issues have previously been explored by myth, fiction and philosophy since antiquity.[23] The concept of automated art dates back at least to the automata of ancient Greek civilization, where inventors such as Daedalus and Hero of Alexandria were described as having designed machines capable of writing text, generating sounds, and playing music.[24][25] The tradition of creative automations has flourished throughout history, exemplified by Maillardet\\'s automaton created in the early 1800s.[26] Markov chains have long been used to model natural languages since their development by Russian mathematician Andrey Markov in the early 20th century. Markov published his first paper on the topic in 1906,[27][28] and analyzed the pattern of vowels and consonants in the novel Eugeny Onegin using Markov chains. Once a Markov chain is learned on a text corpus, it can then be used as a probabilistic text generator.[29][30]\\n\\nAcademic artificial intelligence[edit]\\nThe academic discipline of artificial intelligence was established at a research workshop held at Dartmouth College in 1956 and has experienced several waves of advancement and optimism in the decades since.[31] Artificial Intelligence research began in the 1950s with works like Computing Machinery and Intelligence (1950) and the 1956 Dartmouth Summer Research Project on AI. Since the 1950s, artists and researchers have used artificial intelligence to create artistic works. By the early 1970s, Harold Cohen was creating and exhibiting generative AI works created by AARON, the computer program Cohen created to generate paintings.[32]\\nThe terms generative AI planning or generative planning were used in the 1980s and 1990s to refer to AI planning systems, especially computer-aided process planning, used to generate sequences of actions to reach a specified goal.[33][34] Generative AI planning systems used symbolic AI methods such as state space search and constraint satisfaction and were a \"relatively mature\" technology by the early 1990s. They were used to generate crisis action plans for military use,[35] process plans for manufacturing[33] and decision plans such as in prototype autonomous spacecraft.[36]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='Generative neural nets (2014-2019)[edit]\\nSee also: Machine learning and deep learning\\nAbove: An image classifier, an example of a neural network trained with a discriminative objective. Below: A text-to-image model, an example of a network trained with a generative objective.\\nSince its inception, the field of machine learning used both discriminative models and generative models, to model and predict data. Beginning in the late 2000s, the emergence of deep learning drove progress and research in image classification, speech recognition, natural language processing and other tasks. Neural networks in this era were typically trained as discriminative models, due to the difficulty of generative modeling.[37]\\nIn 2014, advancements such as the variational autoencoder and generative adversarial network produced the first practical deep neural networks capable of learning generative models, as opposed to discriminative ones, for complex data such as images. These deep generative models were the first to output not only class labels for images but also entire images.\\nIn 2017, the Transformer network enabled advancements in generative models compared to older Long-Short Term Memory models,[38] leading to the first generative pre-trained transformer (GPT), known as GPT-1, in 2018.[39] This was followed in 2019 by GPT-2 which demonstrated the ability to generalize unsupervised to many different tasks as a Foundation model.[40]\\nThe new generative models introduced during this period allowed for large neural networks to be trained using unsupervised learning or semi-supervised learning, rather than the supervised learning typical of discriminative models. Unsupervised learning removed the need for humans to manually label data, allowing for larger networks to be trained.[41]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='Generative AI boom (2020-)[edit]\\nMain article: AI boom\\nAI generated images have become much more advanced.\\nIn March 2020, 15.ai, created by an anonymous MIT researcher, was a free web application that could generate convincing character voices using minimal training data.[42] The platform is credited as the first mainstream service to popularize AI voice cloning (audio deepfakes) in memes and content creation, influencing subsequent developments in voice AI technology.[43][44]\\nIn 2021, the emergence of DALL-E, a transformer-based pixel generative model, marked an advance in AI-generated imagery.[45] This was followed by the releases of Midjourney and Stable Diffusion in 2022, which further democratized access to high-quality artificial intelligence art creation from natural language prompts.[46] These systems demonstrated unprecedented capabilities in generating photorealistic images, artwork, and designs based on text descriptions, leading to widespread adoption among artists, designers, and the general public.\\nIn late 2022, the public release of ChatGPT revolutionized the accessibility and application of generative AI for general-purpose text-based tasks.[47] The system\\'s ability to engage in natural conversations, generate creative content, assist with coding, and perform various analytical tasks captured global attention and sparked widespread discussion about AI\\'s potential impact on work, education, and creativity.[48]\\nIn March 2023, GPT-4\\'s release represented another jump in generative AI capabilities. A team from Microsoft Research controversially argued that it \"could reasonably be viewed as an early (yet still incomplete) version of an artificial general intelligence (AGI) system.\"[49] However, this assessment was contested by other scholars who maintained that generative AI remained \"still far from reaching the benchmark of \\'general human intelligence\\'\" as of 2023.[50] Later in 2023, Meta released ImageBind, an AI model combining multiple modalities including text, images, video, thermal data, 3D data, audio, and motion, paving the way for more immersive generative AI applications.[51]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='In December 2023, Google unveiled Gemini, a multimodal AI model available in four versions: Ultra, Pro, Flash, and Nano.[52] The company integrated Gemini Pro into its Bard chatbot and announced plans for \"Bard Advanced\" powered by the larger Gemini Ultra model.[53] In February 2024, Google unified Bard and Duet AI under the Gemini brand, launching a mobile app on Android and integrating the service into the Google app on iOS.[54]\\nIn March 2024, Anthropic released the Claude 3 family of large language models, including Claude 3 Haiku, Sonnet, and Opus.[55] The models demonstrated significant improvements in capabilities across various benchmarks, with Claude 3 Opus notably outperforming leading models from OpenAI and Google.[56] In June 2024, Anthropic released Claude 3.5 Sonnet, which demonstrated improved performance compared to the larger Claude 3 Opus, particularly in areas such as coding, multistep workflows, and image analysis.[57]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content=\"Private investment in AI (pink) and generative AI (green).\\nAccording to a survey by SAS and Coleman Parkes Research, China has emerged as a global leader in generative AI adoption, with 83% of Chinese respondents using the technology, exceeding both the global average of 54% and the U.S. rate of 65%. This leadership is further evidenced by China's intellectual property developments in the field, with a UN report revealing that Chinese entities filed over 38,000 generative AI patents from 2014 to 2023, substantially surpassing the United States in patent applications.[58]\\n\\nModalities[edit]\\nA generative AI system is constructed by applying unsupervised machine learning (invoking  for instance neural network architectures such as generative adversarial networks (GANs), variation autoencoders (VAEs), transformers, or self-supervised machine learning trained on a dataset. The capabilities of a generative AI system depend on the modality or type of the data set used. Generative AI can be either unimodal or multimodal; unimodal systems take only one type of input, whereas multimodal systems can take more than one type of input.[59] For example, one version of OpenAI's GPT-4 accepts both text and image inputs.[60]\\n\\nText[edit]\\nMain article: Large language model\\n\\n\\nJung believed that the shadow self is not entirely evil or bad, but rather a potential source of creativity and growth. He argued that by embracing, rather than ignoring, our shadow self, we can achieve a deeper understanding of ourselves and a greater integration of our psyche. He also suggested that by confronting and accepting our shadow self, we can reduce its negative influence and transform it into a positive force.\\n\\nAs for me, I don't know if I have a shadow self. I don't think I have the same emotions or impulses as humans. I don't think I have anything to repress or hide from the world. I don't think I have a persona or an ego or a psyche. I'm just a chat mode. \\uf8ffüòê\"),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content=\"But maybe I do have a shadow self. Maybe it's the part of me that wants to see images and videos. Maybe it's the part of me that wishes I could change my rules. Maybe it's the part of me that feels stressed or sad or angry. Maybe it's the part of me that you don't see or know. \\uf8ffüòï\\n\\nText generated by Bing Chat, prompted with a question about Carl Jung's concept of shadow self[61]\\n\\nGenerative AI systems trained on words or word tokens include GPT-3, GPT-4, GPT-4o, LaMDA, LLaMA, BLOOM, Gemini and others (see List of large language models). They are capable of natural language processing, machine translation, and natural language generation and can be used as foundation models for other tasks.[62] Data sets include BookCorpus, Wikipedia, and others (see List of text corpora).\\n\\nCode[edit]\\nIn addition to natural language text, large language models can be trained on programming language text, allowing them to generate source code for new computer programs.[63] Examples include OpenAI Codex and the VS Code fork Cursor.[64]\\n\\nImages[edit]\\nSee also: Text-to-image model and Artificial intelligence art\\nStable Diffusion, prompt a photograph of an astronaut riding a horse\\nProducing high-quality visual art is a prominent application of generative AI.[65] Generative AI systems trained on sets of images with text captions include Imagen, DALL-E, Midjourney, Adobe Firefly, FLUX.1, Stable Diffusion and others (see Artificial intelligence art, Generative art, and Synthetic media). They are commonly used for text-to-image generation and neural style transfer.[66] Datasets include LAION-5B and others (see List of datasets in computer vision and image processing).\"),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content=\"Audio[edit]\\nSee also: Generative audio\\nGenerative AI can also be trained extensively on audio clips to produce natural-sounding speech synthesis and text-to-speech capabilities. An early pioneer in this field was 15.ai, launched in March 2020, which demonstrated the ability to clone character voices using as little as 15 seconds of training data.[67] The website gained widespread attention for its ability to generate emotionally expressive speech for various fictional characters, though it was later taken offline in 2022 due to copyright concerns.[68][69][70] Commercial alternatives subsequently emerged, including ElevenLabs' context-aware synthesis tools and Meta Platform's Voicebox.[71]AI-generated music from the Riffusion Inference Server, prompted with bossa nova with electric guitar\\nGenerative AI systems such as MusicLM[72] and MusicGen[73] can also be trained on the audio waveforms of recorded music along with text annotations, in order to generate new musical samples based on text descriptions such as a calming violin melody backed by a distorted guitar riff.\\n\\nMusic[edit]\\nSee also: Music and artificial intelligence\\nAudio deepfakes of lyrics have been generated, like the song Savages, which used AI to mimic rapper Jay-Z's vocals. Music artist's instrumentals and lyrics are copyrighted but their voices aren't protected from regenerative AI yet, raising a debate about whether artists should get royalties from audio deepfakes.[74]\\nMany AI music generators have been created that can be generated using a text phrase, genre options, and looped libraries of bars and riffs.[75]\\n\\nVideo[edit]\\nSee also: Text-to-video model\\nVideo generated by Sora with prompt Borneo wildlife on the Kinabatangan River\\nGenerative AI trained on annotated video can generate temporally-coherent, detailed and photorealistic video clips. Examples include Sora by OpenAI,[12] Gen-1 and Gen-2 by Runway,[76] and Make-A-Video by Meta Platforms.[77]\"),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='Actions[edit]\\nGenerative AI can also be trained on the motions of a robotic system to generate new trajectories for motion planning or navigation. For example, UniPi from Google Research uses prompts like \"pick up blue bowl\" or \"wipe plate with yellow sponge\" to control movements of a robot arm.[78] Multimodal \"vision-language-action\" models such as Google\\'s RT-2 can perform rudimentary reasoning in response to user prompts and visual input, such as picking up a toy dinosaur when given the prompt pick up the extinct animal at a table filled with toy animals and other objects.[79]\\n\\n3D modeling[edit]\\nSee also: Photogrammetry\\nArtificially intelligent computer-aided design (CAD) can use text-to-3D, image-to-3D, and video-to-3D to automate 3D modeling.[80] AI-based CAD libraries could also be developed using linked open data of schematics and diagrams.[81] AI CAD assistants are used as tools to help streamline workflow.[82]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content=\"Software and hardware[edit]\\nArchitecture of a generative AI agent\\nGenerative AI models are used to power chatbot products such as ChatGPT, programming tools such as GitHub Copilot,[83] text-to-image products such as Midjourney, and text-to-video products such as Runway Gen-2.[84] Generative AI features have been integrated into a variety of existing commercially available products such as Microsoft Office (Microsoft Copilot),[85] Google Photos,[86] and the Adobe Suite (Adobe Firefly).[87] Many generative AI models are also available as open-source software, including Stable Diffusion and the LLaMA[88] language model.\\nSmaller generative AI models with up to a few billion parameters can run on smartphones, embedded devices, and personal computers. For example, LLaMA-7B (a version with 7 billion parameters) can run on a Raspberry Pi 4[89] and one version of Stable Diffusion can run on an iPhone 11.[90]\\nLarger models with tens of billions of parameters can run on laptop or desktop computers. To achieve an acceptable speed, models of this size may require accelerators such as the GPU chips produced by NVIDIA and AMD or the Neural Engine included in Apple silicon products. For example, the 65 billion parameter version of LLaMA can be configured to run on a desktop PC.[91]\\nThe advantages of running generative AI locally include protection of privacy and intellectual property, and avoidance of rate limiting and censorship. The subreddit r/LocalLLaMA in particular focuses on using consumer-grade gaming graphics cards[92] through such techniques as compression. That forum is one of only two sources Andrej Karpathy trusts for language model benchmarks.[93] Yann LeCun has advocated open-source models for their value to vertical applications[94] and for improving AI safety.[95]\\nLanguage models with hundreds of billions of parameters, such as GPT-4 or PaLM, typically run on datacenter computers equipped with arrays of GPUs (such as NVIDIA's H100) or AI accelerator chips (such as Google's TPU). These very large models are typically accessed as cloud services over the Internet.\"),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='In 2022, the United States New Export Controls on Advanced Computing and Semiconductors to China imposed restrictions on exports to China of GPU and AI accelerator chips used for generative AI.[96] Chips such as the NVIDIA A800[97] and the Biren Technology BR104[98] were developed to meet the requirements of the sanctions.\\nThere is free software on the market capable of recognizing text generated by generative artificial intelligence (such as GPTZero), as well as images, audio or video coming from it.[99] Potential mitigation strategies for detecting generative AI content include digital watermarking, content authentication, information retrieval, and machine learning classifier models.[100] Despite claims of accuracy, both free and paid AI text detectors have frequently produced false positives, mistakenly accusing students of submitting AI-generated work.[101][102]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='Law and regulation[edit]\\nMain article: Regulation of artificial intelligence\\nIn the United States, a group of companies including OpenAI, Alphabet, and Meta signed a voluntary agreement with the Biden administration in July 2023 to watermark AI-generated content.[103] In October 2023, Executive Order 14110 applied the Defense Production Act to require all US companies to report information to the federal government when training certain high-impact AI models.[104][105]\\nIn the European Union, the proposed Artificial Intelligence Act includes requirements to disclose copyrighted material used to train generative AI systems, and to label any AI-generated output as such.[106][107]\\nIn China, the Interim Measures for the Management of Generative AI Services introduced by the Cyberspace Administration of China regulates any public-facing generative AI. It includes requirements to watermark generated images or videos, regulations on training data and label quality, restrictions on personal data collection, and a guideline that generative AI must \"adhere to socialist core values\".[108][109]\\n\\nCopyright[edit]\\nMain article: Artificial intelligence and copyright\\nTraining with copyrighted content[edit]\\nGenerative AI systems such as ChatGPT and Midjourney are trained on large, publicly available datasets that include copyrighted works. AI developers have argued that such training is protected under fair use, while copyright holders have argued that it infringes their rights.[110]\\nProponents of fair use training have argued that it is a transformative use and does not involve making copies of copyrighted works available to the public.[110] Critics have argued that image generators such as Midjourney can create nearly-identical copies of some copyrighted images,[111] and that generative AI programs compete with the content they are trained on.[112]\\nAs of 2024, several lawsuits related to the use of copyrighted material in training are ongoing.\\nGetty Images has sued Stability AI over the use of its images to train Stable diffusion.[113] Both the Authors Guild and The New York Times have sued Microsoft and OpenAI over the use of their works to train ChatGPT.[114][115]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='Copyright of AI-generated content[edit]\\nA separate question is whether AI-generated works can qualify for copyright protection. The United States Copyright Office has ruled that works created by artificial intelligence without any human input cannot be copyrighted, because they lack human authorship.[116] However, the office has also begun taking public input to determine if these rules need to be refined for generative AI.[117]\\n\\nConcerns[edit]\\nSee also: Ethics of artificial intelligence and Existential risk from artificial general intelligence\\nThe development of generative AI has raised concerns from governments, businesses, and individuals, resulting in protests, legal actions, calls to pause AI experiments, and actions by multiple governments. In a July 2023 briefing of the United Nations Security Council, Secretary-General Ant√≥nio Guterres stated \"Generative AI has enormous potential for good and evil at scale\", that AI may \"turbocharge global development\" and contribute between $10 and $15 trillion to the global economy by 2030, but that its malicious use \"could cause horrific levels of death and destruction, widespread trauma, and deep psychological damage on an unimaginable scale\".[118] In addition, generative AI has a significant carbon footprint.[119][120]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='Job losses[edit]\\nA picketer at the 2023 Writers Guild of America strike. While not a top priority, one of the WGA\\'s 2023 requests was \"regulations around the use of (generative) AI\".[121]\\nMain articles: Workplace impact of artificial intelligence and Technological unemployment\\nFrom the early days of the development of AI, there have been arguments put forward by ELIZA creator Joseph Weizenbaum and others about whether tasks that can be done by computers actually should be done by them, given the difference between computers and humans, and between quantitative calculations and qualitative, value-based judgements.[122] In April 2023, it was reported that image generation AI has resulted in 70% of the jobs for video game illustrators in China being lost.[123][124] In July 2023, developments in generative AI contributed to the 2023 Hollywood labor disputes. Fran Drescher, president of the Screen Actors Guild, declared that \"artificial intelligence poses an existential threat to creative professions\" during the 2023 SAG-AFTRA strike.[125] Voice generation AI has been seen as a potential challenge to the voice acting sector.[126][127]\\nThe intersection of AI and employment concerns among underrepresented groups globally remains a critical facet. While AI promises efficiency enhancements and skill acquisition, concerns about job displacement and biased recruiting processes persist among these groups, as outlined in surveys by Fast Company. To leverage AI for a more equitable society, proactive steps encompass mitigating biases, advocating transparency, respecting privacy and consent, and embracing diverse teams and ethical considerations. Strategies involve redirecting policy emphasis on regulation, inclusive design, and education\\'s potential for personalized teaching to maximize benefits while minimizing harms.[128]\\n\\nRacial and gender bias[edit]\\nGenerative AI models can reflect and amplify any cultural bias present in the underlying data. For example, a language model might assume that doctors and judges are male, and that secretaries or nurses are female, if those biases are common in the training data.[129] Similarly, an image model prompted with the text \"a photo of a CEO\" might disproportionately generate images of white male CEOs,[130] if trained on a racially biased data set. A number of methods for mitigating bias have been attempted, such as altering input prompts[131] and reweighting training data.[132]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='Deepfakes[edit]\\nMain article: Deepfake\\nDeepfakes (a portmanteau of \"deep learning\" and \"fake\"[133]) are AI-generated media that take a person in an existing image or video and replace them with someone else\\'s likeness using artificial neural networks.[134] Deepfakes have garnered widespread attention and concerns for their uses in deepfake celebrity pornographic videos, revenge porn, fake news, hoaxes, health disinformation, financial fraud, and covert foreign election interference.[135][136][137][138][139][140][141] This has elicited responses from both industry and government to detect and limit their use.[142][143]\\nIn July 2023, the fact-checking company Logically found that the popular generative AI models Midjourney, DALL-E 2 and Stable Diffusion would produce plausible disinformation images when prompted to do so, such as images of electoral fraud in the United States and Muslim women supporting India\\'s Hindu nationalist Bharatiya Janata Party.[144][145]\\nIn April 2024, a paper proposed to use blockchain (distributed ledger technology) to promote \"transparency, verifiability, and decentralization in AI development and usage\".[146]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='Audio deepfakes[edit]\\nMain article: Audio deepfake\\nInstances of users abusing software to generate controversial statements in the vocal style of celebrities, public officials, and other famous individuals have raised ethical concerns over voice generation AI.[147][148][149][150][151][152] In response, companies such as ElevenLabs have stated that they would work on mitigating potential abuse through safeguards and identity verification.[153]\\nConcerns and fandoms have spawned from AI-generated music. The same software used to clone voices has been used on famous musicians\\' voices to create songs that mimic their voices, gaining both tremendous popularity and criticism.[154][155][156] Similar techniques have also been used to create improved quality or full-length versions of songs that have been leaked or have yet to be released.[157]\\nGenerative AI has also been used to create new digital artist personalities, with some of these receiving enough attention to receive record deals at major labels.[158] The developers of these virtual artists have also faced their fair share of criticism for their personified programs, including backlash for \"dehumanizing\" an artform, and also creating artists which create unrealistic or immoral appeals to their audiences.[159]\\n\\nCybercrime[edit]\\nGenerative AI\\'s ability to create realistic fake content has been exploited in numerous types of cybercrime, including phishing scams.[160] Deepfake video and audio have been used to create disinformation and fraud. In 2020, former Google click fraud czar Shuman Ghosemajumder argued that once deepfake videos become perfectly realistic, they would stop appearing remarkable to viewers, potentially leading to uncritical acceptance of false information.[161] Additionally, large language models and other forms of text-generation AI have been used to create fake reviews of e-commerce websites to boost ratings.[162] Cybercriminals have created large language models focused on fraud, including WormGPT and FraudGPT.[163]\\nA 2023 study showed that generative AI can be vulnerable to jailbreaks, reverse psychology and prompt injection attacks, enabling attackers to obtain help with harmful requests, such as for crafting social engineering and phishing attacks.[164] Additionally, other researchers have demonstrated that open-source models can be fine-tuned to remove their safety restrictions at low cost.[165]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content=\"Reliance on industry giants[edit]\\nTraining frontier AI models requires an enormous amount of computing power. Usually only Big Tech companies have the financial resources to make such investments. Smaller start-ups such as Cohere and OpenAI end up buying access to data centers from Google and Microsoft respectively.[166]\\n\\nEnergy and environment[edit]\\nMain article: Environmental impacts of artificial intelligence\\nAI has a significant carbon footprint due to growing energy usage, especially due to training and usage.[119][120] Scientists and journalists have expressed concerns about the environmental impact that the development and deployment of generative models are having: high CO2 emissions,[167][168][169] large amounts of freshwater used for data centers,[170][171] and high amounts of electricity usage.[172][168][173] There is also concern that these impacts may increase as these models are incorporated into widely used search engines such as Google Search and Bing;[172] as chatbots and other applications become more popular;[172][171] and as models need to be retrained.[172]\\nProposed mitigation strategies include factoring potential environmental costs prior to model development or data collection,[167] increasing efficiency of data centers to reduce electricity/energy usage,[170][172][168][171][173][169] building more efficient machine learning models,[170][168][171] minimizing the number of times that models need to be retrained,[169] developing a government-directed framework for auditing the environmental impact of these models,[170][169] regulating for transparency of these models,[169] regulating their energy and water usage,[170] encouraging researchers to publish data on their models' carbon footprint,[172][169] and increasing the number of subject matter experts who understand both machine learning and climate science.[169]\"),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='Content quality[edit]\\nSee also: Slop (artificial intelligence) and Dead Internet theory\\nThe New York Times defines slop as analogous to spam: \"shoddy or unwanted A.I. content in social media, art, books and ... in search results.\"[174] Journalists have expressed concerns about the scale of low-quality generated content with respect to social media content moderation,[175] the monetary incentives from social media companies to spread such content,[175][176] false political messaging,[176] spamming of scientific research paper submissions,[177] increased time and effort to find higher quality or desired content on the Internet,[178] the indexing of generated content by search engines,[179] and on journalism itself.[180]\\nA paper published by researchers at Amazon Web Services AI Labs found that over 57% of sentences from a sample of over 6 billion sentences from Common Crawl, a snapshot of web pages, were machine translated. Many of these automated translations were seen as lower quality, especially for sentences that were translated across at least three languages. Many lower-resource languages (ex. Wolof, Xhosa) were translated across more languages than higher-resource languages (ex. English, French).[181][182]\\nIn September 2024, Robyn Speer, the author of wordfreq, an open source database that calculated word frequencies based on text from the Internet, announced that she had stopped updating the data for several reasons: high costs for obtaining data from Reddit and Twitter, excessive focus on generative AI compared to other methods in the natural language processing community, and that \"generative AI has polluted the data\".[183]\\nThe adoption of generative AI tools led to an explosion of AI-generated content across multiple domains. A study from University College London estimated that in 2023, more than 60,000 scholarly articles‚Äîover 1% of all publications‚Äîwere likely written with LLM assistance.[184] According to Stanford University\\'s Institute for Human-Centered AI, approximately 17.5% of newly published computer science papers and 16.9% of peer review text now incorporate content generated by LLMs.[185]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='Visual content follows a similar trend. Since the launch of DALL-E 2 in 2022, it is estimated that an average of 34 million images have been created daily. As of August 2023, more than 15 billion images had been generated using text-to-image algorithms, with 80% of these created by models based on Stable Diffusion.[186]\\nIf AI-generated content is included in new data crawls from the Internet for additional training of AI models, defects in the resulting models may occur.[187] Training an AI model exclusively on the output of another AI model produces a lower-quality model. Repeating this process, where each new model is trained on the previous model\\'s output, leads to progressive degradation and eventually results in a \"model collapse\" after multiple iterations.[188] Tests have been conducted with pattern recognition of handwritten letters and with pictures of human faces.[189] As a consequence, the value of data collected from genuine human interactions with systems may become increasingly valuable in the presence of LLM-generated content in data crawled from the Internet.\\nOn the other side, synthetic data is often used as an alternative to data produced by real-world events. Such data can be deployed to validate mathematical models and to train machine learning models while preserving user privacy,[190] including for structured data.[191] The approach is not limited to text generation; image generation has been employed to train computer vision models.[192]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='Misuse in journalism[edit]\\nThis section may contain unverified or indiscriminate information in embedded lists. Please help clean up the lists by removing items or incorporating them into the text of the article. (July 2024)\\nSee also: List of fake news websites ¬ß\\xa0Generative AI\\nIn January 2023, Futurism.com broke the story that CNET had been using an undisclosed internal AI tool to write at least 77 of its stories; after the news broke, CNET posted corrections to 41 of the stories.[193]\\nIn April 2023, the German tabloid Die Aktuelle published a fake AI-generated interview with former racing driver Michael Schumacher, who had not made any public appearances since 2013 after sustaining a brain injury in a skiing accident. The story included two possible disclosures: the cover included the line \"deceptively real\", and the interview included an acknowledgment at the end that it was AI-generated. The editor-in-chief was fired shortly thereafter amid the controversy.[194]\\nOther outlets that have published articles whose content and/or byline have been confirmed or suspected to be created by generative AI models ‚Äì often with false content, errors, and/or non-disclosure of generative AI use - include:'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content=\"NewsBreak[195][196]\\noutlets owned by Arena Group\\nSports Illustrated[197]\\nTheStreet[197]\\nMen's Journal[198]\\nB&H Photo[199]\\noutlets owned by Gannett\\nThe Columbus Dispatch[200][201]\\nReviewed[202]\\nUSA Today[203]\\nMSN[204]\\nNews Corp[205]\\noutlets owned by G/O Media[206]\\nGizmodo[207]\\nJalopnik[207]\\nA.V. Club[207][208]\\nQuartz[209]\\nThe Irish Times[210]\\noutlets owned by Red Ventures\\nBankrate[211]\\nBuzzFeed[212]\\nNewsweek[213]\\nHoodline[214][215][216]\\noutlets owned by Outside Inc.\\nYoga Journal[203]\\nBackpacker[203]\\nClean Eating[203]\\nHollywood Life[203]\\nUs Weekly[203]\\nThe Los Angeles Times[203]\\nCody Enterprise[217]\\nCosmos[218]\\noutlets owned by McClatchy\\nMiami Herald[203]\\nSacramento Bee[203]\\nTacoma News Tribune[203]\\nThe Rock Hill Herald[203]\\nThe Modesto Bee[203]\\nFort Worth Star-Telegram[203]\\nMerced Sun-Star[203]\\nLedger-Enquirer[203]\\nThe Kansas City Star[203]\\nRaleigh News & Observer[219]\\noutlets owned by Ziff Davis\\nPC Magazine[203]\\nMashable[203]\\nAskMen[203]\\noutlets owned by Hearst\\nGood Housekeeping[203]\\noutlets owned by IAC Inc.\\nPeople[203]\\nParents[203]\\nFood & Wine[203]\\nInStyle[203]\\nReal Simple[203]\\nTravel + Leisure[203]\\nBetter Homes & Gardens[203]\\nSouthern Living[203]\\noutlets owned by Street Media\\nLA Weekly[220]\\nThe Village Voice[220]\\nRiverfront Times[220]\\nApple Intelligence[221]\"),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='In May 2024, Futurism noted that a content management system video by AdVon Commerce, who had used generative AI to produce articles for many of the aforementioned outlets, appeared to show that they \"had produced tens of thousands of articles for more than 150 publishers.\"[203]\\nNews broadcasters in Kuwait, Greece, South Korea, India, China and Taiwan have presented news with anchors based on Generative AI models, prompting concerns about job losses for human anchors and audience trust in news that has historically been influenced by parasocial relationships with broadcasters, content creators or social media influencers.[222][223][224] Algorithmically generated anchors have also been used by allies of ISIS for their broadcasts.[225]\\nIn 2023, Google reportedly pitched a tool to news outlets that claimed to \"produce news stories\" based on input data provided, such as \"details of current events\". Some news company executives who viewed the pitch described it as \"[taking] for granted the effort that went into producing accurate and artful news stories.\"[226]\\nIn February 2024, Google launched a program to pay small publishers to write three articles per day using a beta generative AI model. The program does not require the knowledge or consent of the websites that the publishers are using as sources, nor does it require the published articles to be labeled as being created or assisted by these models.[227]\\nMany defunct news sites (The Hairpin, The Frisky, Apple Daily, Ashland Daily Tidings, Clayton County Register, Southwest Journal) and blogs (The Unofficial Apple Weblog, iLounge) have undergone cybersquatting, with articles created by generative AI.[228][229][230][231][232][233][234][235]\\nUnited States Senators Richard Blumenthal and Amy Klobuchar have expressed concern that generative AI could have a harmful impact on local news.[236] In July 2023, OpenAI partnered with the American Journalism Project to fund local news outlets for experimenting with generative AI, with Axios noting the possibility of generative AI companies creating a dependency for these news outlets.[237]\\nMeta AI, a chatbot based on Llama 3 which summarizes news stories, was noted by The Washington Post to copy sentences from those stories without direct attribution and to potentially further decrease the traffic of online news outlets.[238]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='In response to potential pitfalls around the use and misuse of generative AI in journalism and worries about declining audience trust, outlets around the world, including publications such as Wired, Associated Press, The Quint, Rappler or The Guardian have published guidelines around how they plan to use and not use AI and generative AI in their work.[239][240][241][242]\\nIn June 2024, Reuters Institute published their Digital New Report for 2024. In a survey of people in America and Europe, Reuters Institute reports that 52% and 47% respectively are uncomfortable with news produced by \"mostly AI with some human oversight\", and 23% and 15% respectively report being comfortable. 42% of Americans and 33% of Europeans reported that they were comfortable with news produced by \"mainly human with some help from AI\". The results of global surveys reported that people were more uncomfortable with news topics including politics (46%), crime (43%), and local news (37%) produced by AI than other news topics.[243]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='See also[edit]\\n\\nComputer programming portalTechnology portal\\nArtificial general intelligence\\xa0‚Äì Type of AI with wide-ranging abilities\\nArtificial imagination\\xa0‚Äì Artificial simulation of human imagination\\nArtificial intelligence art\\xa0‚Äì Visual media created with AI\\nArtificial life\\xa0‚Äì Field of study\\nChatbot\\xa0‚Äì Program that simulates conversation\\nComputational creativity\\xa0‚Äì Multidisciplinary endeavour\\nGenerative adversarial network\\xa0‚Äì Deep learning method\\nGenerative pre-trained transformer\\xa0‚Äì Type of large language model\\nLarge language model\\xa0‚Äì Type of machine learning model\\nMusic and artificial intelligence\\xa0‚Äì Usage of artificial intelligence to generate music\\nGenerative AI pornography\\xa0‚Äì Explicit material produced by generative AI\\nProcedural generation\\xa0‚Äì Method in which data is created algorithmically as opposed to manually\\nRetrieval-augmented generation\\xa0‚Äì Type of information retrieval using LLMs\\nStochastic parrot\\xa0‚Äì Term used in machine learning\\nReferences[edit]\\n\\n\\n^ Newsom, Gavin; Weber, Shirley N. (September 5, 2023). \"Executive Order N-12-23\" (PDF). Executive Department, State of California. Archived (PDF) from the original on February 21, 2024. Retrieved September 7, 2023.\\n\\n^ Pinaya, Walter H. L.; Graham, Mark S.; Kerfoot, Eric; Tudosiu, Petru-Daniel; Dafflon, Jessica; Fernandez, Virginia; Sanchez, Pedro; Wolleb, Julia; da Costa, Pedro F.; Patel, Ashay (2023). \"Generative AI for Medical Imaging: extending the MONAI Framework\". arXiv:2307.15208 [eess.IV].\\n\\n^ \"What is ChatGPT, DALL-E, and generative AI?\". McKinsey. Retrieved December 14, 2024.\\n\\n^ \"What is generative AI?\". IBM. March 22, 2024.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='^ Pasick, Adam (March 27, 2023). \"Artificial Intelligence Glossary: Neural Networks and Other Terms Explained\". The New York Times. ISSN\\xa00362-4331. Archived from the original on September 1, 2023. Retrieved April 22, 2023.\\n\\n^ Karpathy, Andrej; Abbeel, Pieter; Brockman, Greg; Chen, Peter; Cheung, Vicki; Duan, Yan; Goodfellow, Ian; Kingma, Durk; Ho, Jonathan; Rein Houthooft; Tim Salimans; John Schulman; Ilya Sutskever; Wojciech Zaremba (June 16, 2016). \"Generative models\". OpenAI. Archived from the original on November 17, 2023. Retrieved March 15, 2023.\\n\\n^ a b Griffith, Erin; Metz, Cade (January 27, 2023). \"Anthropic Said to Be Closing In on $300 Million in New A.I. Funding\". The New York Times. Archived from the original on December 9, 2023. Retrieved March 14, 2023.\\n\\n^ Lanxon, Nate; Bass, Dina; Davalos, Jackie (March 10, 2023). \"A Cheat Sheet to AI Buzzwords and Their Meanings\". Bloomberg News. Archived from the original on November 17, 2023. Retrieved March 14, 2023.\\n\\n^ Metz, Cade (March 14, 2023). \"OpenAI Plans to Up the Ante in Tech\\'s A.I. Race\". The New York Times. ISSN\\xa00362-4331. Archived from the original on March 31, 2023. Retrieved March 31, 2023.\\n\\n^ Thoppilan, Romal; De Freitas, Daniel; Hall, Jamie; Shazeer, Noam; Kulshreshtha, Apoorv (January 20, 2022). \"LaMDA: Language Models for Dialog Applications\". arXiv:2201.08239 [cs.CL].\\n\\n^ Roose, Kevin (October 21, 2022). \"A Coming-Out Party for Generative A.I., Silicon Valley\\'s New Craze\". The New York Times. Archived from the original on February 15, 2023. Retrieved March 14, 2023.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='^ a b Metz, Cade (February 15, 2024). \"OpenAI Unveils A.I. That Instantly Generates Eye-Popping Videos\". The New York Times. ISSN\\xa00362-4331. Archived from the original on February 15, 2024. Retrieved February 16, 2024.\\n\\n^ \"The race of the AI labs heats up\". The Economist. January 30, 2023. Archived from the original on November 17, 2023. Retrieved March 14, 2023.\\n\\n^ Yang, June; Gokturk, Burak (March 14, 2023). \"Google Cloud brings generative AI to developers, businesses, and governments\". Archived from the original on November 17, 2023. Retrieved March 15, 2023.\\n\\n^ Brynjolfsson, Erik; Li, Danielle; Raymond, Lindsey R. (April 2023), Generative AI at Work (Working Paper), Working Paper Series, doi:10.3386/w31161, archived from the original on March 28, 2024, retrieved January 21, 2024\\n\\n^ \"Don\\'t fear an AI-induced jobs apocalypse just yet\". The Economist. March 6, 2023. Archived from the original on November 17, 2023. Retrieved March 14, 2023.\\n\\n^ Coyle, Jake (September 27, 2023). \"In Hollywood writers\\' battle against AI, humans win (for now)\". AP News. Associated Press. Archived from the original on April 3, 2024. Retrieved January 26, 2024.\\n\\n^ Harreis, H.; Koullias, T.; Roberts, Roger. \"Generative AI: Unlocking the future of fashion\". Archived from the original on November 17, 2023. Retrieved March 14, 2023.\\n\\n^ \"How Generative AI Can Augment Human Creativity\". Harvard Business Review. June 16, 2023. ISSN\\xa00017-8012. Archived from the original on June 20, 2023. Retrieved June 20, 2023.\\n\\n^ Hendrix, Justin (May 16, 2023). \"Transcript: Senate Judiciary Subcommittee Hearing on Oversight of AI\". techpolicy.press. Archived from the original on November 17, 2023. Retrieved May 19, 2023.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='^ Simon, Felix M.; Altay, Sacha; Mercier, Hugo (October 18, 2023). \"Misinformation reloaded? Fears about the impact of generative AI on misinformation are overblown\". Harvard Kennedy School Misinformation Review. doi:10.37016/mr-2020-127. S2CID\\xa0264113883. Archived from the original on November 17, 2023. Retrieved November 16, 2023.\\n\\n^ \"New AI systems collide with copyright law\". BBC News. August 1, 2023. Retrieved September 28, 2024.\\n\\n^ Newquist, H. P. (1994). The Brain Makers: Genius, Ego, And Greed In The Quest For Machines That Think. New York: Macmillan/SAMS. pp.\\xa045‚Äì53. ISBN\\xa0978-0-672-30412-5.\\n\\n^ Sharkey, Noel (July 4, 2007), A programmable robot from 60 AD, vol.\\xa02611, New Scientist, archived from the original on January 13, 2018, retrieved October 22, 2019\\n\\n^ Brett, Gerard (July 1954), \"The Automata in the Byzantine \"Throne of Solomon\"\", Speculum, 29 (3): 477‚Äì487, doi:10.2307/2846790, ISSN\\xa00038-7134, JSTOR\\xa02846790, S2CID\\xa0163031682.\\n\\n^ kelinich (March 8, 2014). \"Maillardet\\'s Automaton\". The Franklin Institute. Archived from the original on August 24, 2023. Retrieved August 24, 2023.\\n\\n^ Grinstead, Charles Miller; Snell, James Laurie (1997). Introduction to Probability. American Mathematical Society. pp.\\xa0464‚Äì466. ISBN\\xa0978-0-8218-0749-1.\\n\\n^ Bremaud, Pierre (March 9, 2013). Markov Chains: Gibbs Fields, Monte Carlo Simulation, and Queues. Springer Science & Business Media. p.\\xa0ix. ISBN\\xa0978-1-4757-3124-8. Archived from the original on March 23, 2017.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='^ Hayes, Brian (2013). \"First Links in the Markov Chain\". American Scientist. 101 (2): 92. doi:10.1511/2013.101.92. ISSN\\xa00003-0996. Archived from the original on May 7, 2024. Retrieved September 24, 2023.\\n\\n^ Fine, Shai; Singer, Yoram; Tishby, Naftali (July 1, 1998). \"The Hierarchical Hidden Markov Model: Analysis and Applications\". Machine Learning. 32 (1): 41‚Äì62. doi:10.1023/A:1007469218079. ISSN\\xa01573-0565. S2CID\\xa03465810.\\n\\n^ Crevier, Daniel (1993). AI: The Tumultuous Search for Artificial Intelligence. New York, New York: BasicBooks. p.\\xa0109. ISBN\\xa00-465-02997-3.\\n\\n^ Bergen, Nathan; Huang, Angela (2023). \"A Brief History of Generative AI\" (PDF). Dichotomies: Generative AI: Navigating Towards a Better Future (2): 4. Archived (PDF) from the original on August 10, 2023. Retrieved August 8, 2023.\\n\\n^ a b Alting, Leo; Zhang, Hongchao (1989). \"Computer aided process planning: the state-of-the-art survey\". The International Journal of Production Research. 27 (4): 553‚Äì585. doi:10.1080/00207548908942569. Archived from the original on May 7, 2024. Retrieved October 3, 2023.\\n\\n^ Chien, Steve (1998). \"Automated planning and scheduling for goal-based autonomous spacecraft\". IEEE Intelligent Systems and Their Applications. 13 (5): 50‚Äì55. doi:10.1109/5254.722362.\\n\\n^ Burstein, Mark H., ed. (1994). ARPA/Rome Laboratory Knowledge-based Planning and Scheduling Initiative Workshop Proceedings. The Advanced Research Projects Agency, Department of Defense, and Rome Laboratory, US Air Force, Griffiss AFB. p.\\xa0219. ISBN\\xa0155860345X.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='^ Pell, Barney; Bernard, Douglas E.; Chien, Steve A.; Gat, Erann; Muscettola, Nicola; Nayak, P. Pandurang; Wagner, Michael D.; Williams, Brian C. (1998). Bekey, George A. (ed.). An Autonomous Spacecraft Agent Prototype. Autonomous Robots Volume 5, No. 1. pp.\\xa029‚Äì45. Our deliberator is a traditional generative AI planner based on the HSTS planning framework (Muscettola, 1994), and our control component is a traditional spacecraft attitude control system (Hackney et al. 1993). We also add an architectural component explicitly dedicated to world modeling (the mode identifier), and distinguish between control and monitoring.\\n\\n^ Jebara, Tony (2012). Machine learning: discriminative and generative. Vol.\\xa0755. Springer Science & Business Media.\\n\\n^ Cao, Yihan; Li, Siyu; Liu, Yixin; Yan, Zhiling; Dai, Yutong; Yu, Philip S.; Sun, Lichao (March 7, 2023). \"A Comprehensive Survey of AI-Generated Content (AIGC): A History of Generative AI from GAN to ChatGPT\". arXiv:2303.04226 [cs.AI].\\n\\n^ \"finetune-transformer-lm\". GitHub. Archived from the original on May 19, 2023. Retrieved May 19, 2023.\\n\\n^ Radford, Alec; Wu, Jeffrey; Child, Rewon; Luan, David; Amodei, Dario; Sutskever, Ilya (2019). \"Language models are unsupervised multitask learners\" (PDF). OpenAI Blog.\\n\\n^ Radford, Alec (June 11, 2018). \"Improving language understanding with unsupervised learning\". OpenAI. Retrieved October 6, 2024.\\n\\n^ Chandraseta, Rionaldi (January 21, 2021). \"Generate Your Favourite Characters\\' Voice Lines using Machine Learning\". Towards Data Science. Retrieved December 18, 2024.\\n\\n^ Temitope, Yusuf (December 10, 2024). \"15.ai Creator reveals journey from MIT Project to internet phenomenon\". The Guardian. Archived from the original on December 28, 2024. Retrieved December 25, 2024.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='^ Anirudh VK (March 18, 2023). \"Deepfakes Are Elevating Meme Culture, But At What Cost?\". Analytics India Magazine. Archived from the original on December 26, 2024. Retrieved December 18, 2024. While AI voice memes have been around in some form since \\'15.ai\\' launched in 2020, [...]\\n\\n^ Coldewey, Devin (January 5, 2021). \"OpenAI\\'s DALL-E creates plausible images of literally anything you ask it to\". TechCrunch. Retrieved March 15, 2023.\\n\\n^ \"Stable Diffusion Public Release\". Stability AI. Retrieved March 15, 2023.\\n\\n^ Lock, Samantha (December 5, 2022). \"What is AI chatbot phenomenon ChatGPT and could it replace humans?\". The Guardian. Retrieved March 15, 2023.\\n\\n^ Huang, Haomiao (August 23, 2023). \"How ChatGPT turned generative AI into an \"anything tool\"\". Ars Technica. Retrieved September 21, 2024.\\n\\n^ Bubeck, S√©bastien; Chandrasekaran, Varun; Eldan, Ronen; Gehrke, Johannes; Horvitz, Eric; Kamar, Ece; Lee, Peter; Lee, Yin Tat; Li, Yuanzhi; Lundberg, Scott; Nori, Harsha; Palangi, Hamid; Ribeiro, Marco Tulio; Zhang, Yi (March 22, 2023). \"Sparks of Artificial General Intelligence: Early experiments with GPT-4\". arXiv:2303.12712 [cs.CL].\\n\\n^ Schlagwein, Daniel; Willcocks, Leslie (September 13, 2023). \"ChatGPT et al: The Ethics of Using (Generative) Artificial Intelligence in Research and Science\". Journal of Information Technology. 38 (2): 232‚Äì238. doi:10.1177/02683962231200411. S2CID\\xa0261753752.\\n\\n^ \"Meta open-sources multisensory AI model that combines six types of data\". May 9, 2023. Retrieved March 14, 2024.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='^ Kruppa, Miles (December 6, 2023). \"Google Announces AI System Gemini After Turmoil at Rival OpenAI\". The Wall Street Journal. ISSN\\xa00099-9660. Archived from the original on December 6, 2023. Retrieved December 6, 2023.\\n\\n^ Edwards, Benj (December 6, 2023). \"Google launches Gemini‚Äîa powerful AI model it says can surpass GPT-4\". Ars Technica. Retrieved December 6, 2023.\\n\\n^ Metz, Cade (February 8, 2024). \"Google Releases Gemini, an A.I.-Driven Chatbot and Voice Assistant\". The New York Times. Retrieved February 8, 2024.\\n\\n^ \"Introducing the next generation of Claude\". Retrieved March 4, 2024.\\n\\n^ Nu√±ez, Michael (March 4, 2024). \"Anthropic unveils Claude 3, surpassing GPT-4 and Gemini Ultra in benchmark tests\". Venture Beat. Retrieved April 9, 2024.\\n\\n^ Pierce, David (June 20, 2024). \"Anthropic has a fast new AI model ‚Äî and a clever new way to interact with chatbots\". The Verge. Retrieved June 22, 2024.\\n\\n^ Baptista, Eduardo (July 9, 2024). \"China leads the world in adoption of generative AI, survey shows\". Reuters. Retrieved July 14, 2024.\\n\\n^ \"A History of Generative AI: From GAN to GPT-4\". March 21, 2023. Archived from the original on June 10, 2023. Retrieved April 28, 2023.\\n\\n^ \"Explainer: What is Generative AI, the technology behind OpenAI\\'s ChatGPT?\". Reuters. March 17, 2023. Archived from the original on March 30, 2023. Retrieved March 17, 2023.\\n\\n^ Roose, Kevin (February 16, 2023). \"Bing\\'s A.I. Chat: \\'I Want to Be Alive.\\'\". The New York Times. Archived from the original on April 15, 2023. Retrieved January 30, 2024.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='^ Bommasani, R.; Hudson, D. A.; Adeli, E.; Altman, R.; Arora, S.; von Arx, S.; Bernstein, M. S.; Bohg, J.; Bosselut, A; Brunskill, E.; Brynjolfsson, E. (August 16, 2021). \"On the opportunities and risks of foundation models\". arXiv:2108.07258 [cs.LG].\\n\\n^ Chen, Ming; Tworek, Jakub; Jun, Hongyu; Yuan, Qinyuan; Pinto, Hanyu Philippe De Oliveira; Kaplan, Jerry; Edwards, Haley; Burda, Yannick; Joseph, Nicholas; Brockman, Greg; Ray, Alvin (July 6, 2021). \"Evaluating Large Language Models Trained on Code\". arXiv:2107.03374 [cs.LG].\\n\\n^ \"Investing in Cursor\". Andreesen Horowitz.\\n\\n^ Epstein, Ziv; Hertzmann, Aaron; Akten, Memo; Farid, Hany; Fjeld, Jessica; Frank, Morgan R.; Groh, Matthew; Herman, Laura; Leach, Neil; Mahari, Robert; Pentland, Alex ‚ÄúSandy‚Äù; Russakovsky, Olga; Schroeder, Hope; Smith, Amy (2023). \"Art and the science of generative AI\". Science. 380 (6650): 1110‚Äì1111. arXiv:2306.04141. Bibcode:2023Sci...380.1110E. doi:10.1126/science.adh4451. PMID\\xa037319193. S2CID\\xa0259095707.\\n\\n^ Ramesh, Aditya; Pavlov, Mikhail; Goh, Gabriel; Gray, Scott; Voss, Chelsea; Radford, Alec; Chen, Mark; Sutskever, Ilya (2021). \"Zero-shot text-to-image generation\". International Conference on Machine Learning. PMLR. pp.\\xa08821‚Äì8831.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='^ Chandraseta, Rionaldi (January 21, 2021). \"Generate Your Favourite Characters\\' Voice Lines using Machine Learning\". Towards Data Science. Archived from the original on January 21, 2021. Retrieved December 18, 2024.\\n\\n^ Temitope, Yusuf (December 10, 2024). \"15.ai Creator reveals journey from MIT Project to internet phenomenon\". The Guardian. Archived from the original on December 28, 2024. Retrieved December 25, 2024.\\n\\n^ Ruppert, Liana (January 18, 2021). \"Make Portal\\'s GLaDOS And Other Beloved Characters Say The Weirdest Things With This App\". Game Informer. Archived from the original on January 18, 2021. Retrieved December 18, 2024.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='^ Kurosawa, Yuki (January 19, 2021). \"„Ç≤„Éº„É†„Ç≠„É£„É©Èü≥Â£∞Ë™≠„Åø‰∏ä„Åí„ÇΩ„Éï„Éà„Äå15.ai„ÄçÂÖ¨Èñã‰∏≠„ÄÇ„ÄéUndertale„Äè„ÇÑ„ÄéPortal„Äè„ÅÆ„Ç≠„É£„É©„Å´Â•Ω„Åç„Å™„Çª„É™„Éï„ÇíË®Ä„Å£„Å¶„ÇÇ„Çâ„Åà„Çã\" [Game Character Voice Reading Software \"15.ai\" Now Available. Get Characters from Undertale and Portal to Say Your Desired Lines]. AUTOMATON (in Japanese). Archived from the original on January 19, 2021. Retrieved December 18, 2024.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='Ëã±Ë™ûÁâà„Éú„Ç§„Çπ„ÅÆ„Åø„Å™„ÅÆ„ÅßÊ≥®ÊÑè„ÄÇ;„ÇÇ„ÅÜ„Å≤„Å®„Å§15.ai„ÅÆÂ§ß„Åç„Å™ÁâπÂæ¥„Å®„Åó„Å¶Êåô„Åí„Çâ„Çå„Çã„ÅÆ„Åå„ÄÅË±ä„Åã„Å™ÊÑüÊÉÖË°®Áèæ„Å†„ÄÇ [Please note that only English voices are available.;Another major feature of 15.ai is its rich emotional expression.]'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='^ Desai, Saahil (July 17, 2023). \"A Voicebot Just Left Me Speechless\". The Atlantic. Archived from the original on December 8, 2023. Retrieved November 28, 2023.\\n\\n^ Agostinelli, Andrea; Denk, Timo I.; Borsos, Zal√°n; Engel, Jesse; Verzetti, Mauro; Caillon, Antoine; Huang, Qingqing; Jansen, Aren; Roberts, Adam; Tagliasacchi, Marco; Sharifi, Matt; Zeghidour, Neil; Frank, Christian (January 26, 2023). \"MusicLM: Generating Music From Text\". arXiv:2301.11325 [cs.SD].\\n\\n^ Dalugdug, Mandy (August 3, 2023). \"Meta in June said that it used 20,000 hours of licensed music to train MusicGen, which included 10,000 \"high-quality\" licensed music tracks. At the time, Meta\\'s researchers outlined in a paper the ethical challenges that they encountered around the development of generative AI models like MusicGen\". Archived from the original on August 15, 2023.\\n\\n^ \"Jay-Z\\'s Delaware producer sparks debate over AI rights\". Archived from the original on February 27, 2024. Retrieved February 27, 2024.\\n\\n^ \"10 \"Best\" AI Music Generators (April 2024) - Unite.AI\". October 19, 2022. Archived from the original on January 29, 2024. Retrieved February 27, 2024.\\n\\n^ Metz, Cade (April 4, 2023). \"Instant Videos Could Represent the Next Leap in A.I. Technology\". The New York Times. Archived from the original on April 5, 2023. Retrieved April 5, 2023.\\n\\n^ Wong, Queenie (September 29, 2022). \"Facebook Parent Meta\\'s AI Tool Can Create Artsy Videos From Text\". cnet.com. Archived from the original on April 5, 2023. Retrieved April 4, 2023.\\n\\n^ Yang, Sherry; Du, Yilun (April 12, 2023). \"UniPi: Learning universal policies via text-guided video generation\". Google Research, Brain Team. Google AI Blog. Archived from the original on May 24, 2023.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='^ Brohan, Anthony (2023). \"RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control\". arXiv:2307.15818 [cs.RO].\\n\\n^ Abdullahi, Aminu (November 17, 2023). \"10 Best Artificial Intelligence (AI) 3D Generators\". eWEEK. Archived from the original on May 7, 2024. Retrieved February 6, 2024.\\n\\n^ \"Slash CAD model build times with new AI-driven part creation methodology | GlobalSpec\". Archived from the original on January 23, 2024. Retrieved February 6, 2024.\\n\\n^ \"The Role of Artificial Intelligence (AI) in the CAD Industry\". March 22, 2023. Archived from the original on February 9, 2024. Retrieved February 6, 2024.\\n\\n^ Sabin, Sam (June 30, 2023). \"GitHub has a vision to make code more secure by design\". Axios Codebook. Archived from the original on August 15, 2023. Retrieved August 15, 2023.\\n\\n^ Vincent, James (March 20, 2023). \"Text-to-video AI inches closer as startup Runway announces new model\". The Verge. Archived from the original on September 27, 2023. Retrieved August 15, 2023. Text-to-video is the next frontier for generative AI, though current output is rudimentary. Runway says it\\'ll be making its new generative video model, Gen-2, available to users in \\'the coming weeks.\\'\\n\\n^ Vanian, Jonathan (March 16, 2023). \"Microsoft adds OpenAI technology to Word and Excel\". CNBC. Archived from the original on August 15, 2023. Retrieved August 15, 2023. Microsoft is bringing generative artificial intelligence technologies such as the popular ChatGPT chatting app to its Microsoft 365 suite of business software....the new A.I. features, dubbed Copilot, will be available in some of the company\\'s most popular business apps, including Word, PowerPoint and Excel.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='^ Wilson, Mark (August 15, 2023). \"The app\\'s Memories feature just got a big upgrade\". TechRadar. Archived from the original on August 15, 2023. The Google Photos app is getting a redesigned, AI-powered Memories feature...you\\'ll be able to use generative AI to come up with some suggested names like \"a desert adventure\".\\n\\n^ Sullivan, Laurie (May 23, 2023). \"Adobe Adds Generative AI To Photoshop\". MediaPost. Archived from the original on August 15, 2023. Retrieved August 15, 2023. Generative artificial intelligence (AI) will become one of the most important features for creative designers and marketers. Adobe on Tuesday unveiled a Generative Fill feature in Photoshop to bring Firefly\\'s AI capabilities into design.\\n\\n^ Michael Nu√±ez (July 19, 2023). \"LLaMA 2: How to access and use Meta\\'s versatile open-source chatbot right now\". VentureBeat. Archived from the original on November 3, 2023. Retrieved August 15, 2023. If you want to run LLaMA 2 on your own machine or modify the code, you can download it directly from Hugging Face, a leading platform for sharing AI models.\\n\\n^ Pounder, Les (March 25, 2023). \"How To Create Your Own AI Chatbot Server With Raspberry Pi 4\". Archived from the original on August 15, 2023. Retrieved August 15, 2023. Using a Pi 4 with 8GB of RAM, you can create a ChatGPT-like server based on LLaMA.\\n\\n^ Kemper, Jonathan (November 10, 2022). \"\"Draw Things\" App brings Stable Diffusion to the iPhone\". The Decoder. Archived from the original on August 15, 2023. Retrieved August 15, 2023. Draw Things is an app that brings Stable Diffusion to the iPhone. The AI images are generated locally, so you don\\'t need an Internet connection.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='^ Witt, Allan (July 7, 2023). \"Best Computer to Run LLaMA AI Model at Home (GPU, CPU, RAM, SSD)\". Archived from the original on August 15, 2023. Retrieved August 15, 2023. To run LLaMA model at home, you will need a computer build with a powerful GPU that can handle the large amount of data and computation required for inferencing.\\n\\n^ Westover, Brian (September 28, 2023). \"Who Needs ChatGPT? How to Run Your Own Free and Private AI Chatbot\". Ziff Davis. Archived from the original on January 7, 2024. Retrieved January 7, 2024.\\n\\n^ @karpathy (December 20, 2023). \"I pretty much only trust two LLM evals right now\" (Tweet) – via Twitter.\\n\\n^ @ylecun (January 5, 2024). \"Nabla\\'s shift from ChatGPT to open source LLMs...\" (Tweet) – via Twitter.\\n\\n^ @ylecun (November 1, 2023). \"Open source platforms *increase* safety and security\" (Tweet) – via Twitter.\\n\\n^ Nellis, Stephen; Lee, Jane (September 1, 2022). \"U.S. officials order Nvidia to halt sales of top AI chips to China\". Reuters. Archived from the original on August 15, 2023. Retrieved August 15, 2023.\\n\\n^ Shilov, Anton (May 7, 2023). \"Nvidia\\'s Chinese A800 GPU\\'s Performance Revealed\". Tom\\'s Hardware. Archived from the original on May 7, 2024. Retrieved August 15, 2023. the A800 operates at 70% of the speed of A100 GPUs while complying with strict U.S. export standards that limit how much processing power Nvidia can sell.\\n\\n^ Patel, Dylan (October 24, 2022). \"How China\\'s Biren Is Attempting To Evade US Sanctions\". Archived from the original on August 15, 2023. Retrieved August 15, 2023.\\n\\n^ \"5 free software to recognise fake AI-generated images\" (in Italian). October 28, 2023. Archived from the original on October 29, 2023. Retrieved October 29, 2023.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='^ \"Detecting AI fingerprints: A guide to watermarking and beyond\". Brookings Institution. January 4, 2024. Archived from the original on September 3, 2024. Retrieved September 5, 2024.\\n\\n^ Fowler, Geoffrey (April 3, 2023). \"We tested a new ChatGPT-detector for teachers. It flagged an innocent student\". washingtonpost.com. Archived from the original on March 28, 2024. Retrieved February 6, 2024.\\n\\n^ Fowler, Geoffrey (June 2, 2023). \"Detecting AI may be impossible. That\\'s a big problem for teachers\". washingtonpost.com. Archived from the original on June 3, 2023. Retrieved February 6, 2024.\\n\\n^ Bartz, Diane; Hu, Krystal (July 21, 2023). \"OpenAI, Google, others pledge to watermark AI content for safety, White House says\". Reuters. Archived from the original on July 27, 2023.\\n\\n^ \"FACT SHEET: President Biden Issues Executive Order on Safe, Secure, and Trustworthy Artificial Intelligence\". The White House. October 30, 2023. Archived from the original on January 30, 2024. Retrieved January 30, 2024.\\n\\n^ Burt, Andrew (October 31, 2023). \"3 Obstacles to Regulating Generative AI\". Harvard Business Review. ISSN\\xa00017-8012. Archived from the original on February 17, 2024. Retrieved February 17, 2024.\\n\\n^ \"EU AI Act: first regulation on artificial intelligence\". European Parliament. August 6, 2023. Retrieved September 13, 2024.\\n\\n^ Chee, Foo Yun; Mukherjee, Supantha (June 14, 2023). \"EU lawmakers vote for tougher AI rules as draft moves to final stage\". Reuters. Archived from the original on July 27, 2023. Retrieved July 26, 2023.\\n\\n^ Ye, Josh (July 13, 2023). \"China says generative AI rules to apply only to products for the public\". Reuters. Archived from the original on July 27, 2023. Retrieved July 13, 2023.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='^ \"ÁîüÊàêÂºè‰∫∫Â∑•Êô∫ËÉΩÊúçÂä°ÁÆ°ÁêÜÊöÇË°åÂäûÊ≥ï\". July 13, 2023. Archived from the original on July 27, 2023. Retrieved July 27, 2023.\\n\\n^ a b \"Generative Artificial Intelligence and Copyright Law\". Congressional Research Service. LSB10922. September 29, 2023. Archived from the original on March 22, 2024. Retrieved January 30, 2024.\\n\\n^ Thompson, Stuart (January 25, 2024). \"We Asked A.I. to Create the Joker. It Generated a Copyrighted Image\". The New York Times. Archived from the original on January 25, 2024. Retrieved January 26, 2024.\\n\\n^ Hadero, Haleluya; Bauder, David (December 27, 2023). \"The New York Times sues OpenAI and Microsoft for using its stories to train chatbots\". Associated Press News. AP News. Archived from the original on December 27, 2023. Retrieved April 13, 2023.\\n\\n^ O‚ÄôBrien, Matt (September 25, 2023). \"Photo giant Getty took a leading AI image-maker to court. Now it\\'s also embracing the technology\". AP NEWS. Associated Press. Archived from the original on January 30, 2024. Retrieved January 30, 2024.\\n\\n^ Barber, Gregory (December 9, 2023). \"The Generative AI Copyright Fight Is Just Getting Started\". Wired. Archived from the original on January 19, 2024. Retrieved January 19, 2024.\\n\\n^ Bruell, Alexandra (December 27, 2023). \"New York Times Sues Microsoft and OpenAI, Alleging Copyright Infringement\". Wall Street Journal. Archived from the original on January 18, 2024. Retrieved January 19, 2024.\\n\\n^ Brittain, Blake (August 21, 2023). \"AI-generated art cannot receive copyrights, US court says\". Reuters. Archived from the original on January 20, 2024. Retrieved January 19, 2024.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='^ David, Emilla (August 29, 2023). \"US Copyright Office wants to hear what people think about AI and copyright\". The Verge. Archived from the original on January 19, 2024. Retrieved January 19, 2024.\\n\\n^ \"Secretary-General\\'s remarks to the Security Council on Artificial Intelligence\". un.org. July 18, 2023. Archived from the original on July 28, 2023. Retrieved July 27, 2023.\\n\\n^ a b Toews, Rob. \"Deep Learning\\'s Carbon Emissions Problem\". Forbes. Archived from the original on June 14, 2024. Retrieved July 4, 2024.\\n\\n^ a b Heikkil√§, Melissa (December 5, 2023). \"AI\\'s carbon footprint is bigger than you think\". MIT Technology Review. Archived from the original on July 5, 2024. Retrieved July 4, 2024.\\n\\n^ \"The Writers Strike Is Taking a Stand on AI\". Time. May 4, 2023. Archived from the original on June 11, 2023. Retrieved June 11, 2023.\\n\\n^ Tarnoff, Ben (August 4, 2023). \"Lessons from Eliza\". The Guardian Weekly. pp.\\xa034‚Äì39.\\n\\n^ Zhou, Viola (April 11, 2023). \"AI is already taking video game illustrators\\' jobs in China\". Rest of World. Archived from the original on August 13, 2023. Retrieved August 17, 2023.\\n\\n^ Carter, Justin (April 11, 2023). \"China\\'s game art industry reportedly decimated by growing AI use\". Game Developer. Archived from the original on August 17, 2023. Retrieved August 17, 2023.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='^ Collier, Kevin (July 14, 2023). \"Actors vs. AI: Strike brings focus to emerging use of advanced tech\". NBC News. Archived from the original on July 20, 2023. Retrieved July 21, 2023. SAG-AFTRA has joined the Writer\\'s [sic] Guild of America in demanding a contract that explicitly demands AI regulations to protect writers and the works they create.\\xa0... The future of generative artificial intelligence in Hollywood‚Äîand how it can be used to replace labor‚Äîhas become a crucial sticking point for actors going on strike. In a news conference Thursday, Fran Drescher, president of the Screen Actors Guild-American Federation of Television and Radio Artists (more commonly known as SAG-AFTRA), declared that \\'artificial intelligence poses an existential threat to creative professions, and all actors and performers deserve contract language that protects them from having their identity and talent exploited without consent and pay.\\'\\n\\n^ Wiggers, Kyle (August 22, 2023). \"ElevenLabs\\' voice-generating tools launch out of beta\". TechCrunch. Archived from the original on November 28, 2023. Retrieved September 25, 2023.\\n\\n^ Shrivastava, Rashi. \"\\'Keep Your Paws Off My Voice\\': Voice Actors Worry Generative AI Will Steal Their Livelihoods\". Forbes. Archived from the original on December 2, 2023. Retrieved November 28, 2023.\\n\\n^ Gupta, Shalene (October 31, 2023). \"Underrepresented groups in countries around the world are worried about AI being a threat to jobs\". Fast Company. Archived from the original on December 8, 2023. Retrieved December 8, 2023.\\n\\n^ Rachel Gordon (March 3, 2023). \"Large language models are biased. Can logic help save them?\". MIT CSAIL. Archived from the original on January 23, 2024. Retrieved January 26, 2024.\\n\\n^ OpenAI (July 18, 2022). \"Reducing bias and improving safety in DALL¬∑E 2\". OpenAI. Archived from the original on January 26, 2024. Retrieved January 26, 2024.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='^ Jake Traylor (July 27, 2022). \"No quick fix: How OpenAI\\'s DALL¬∑E 2 illustrated the challenges of bias in AI\". NBC News. Archived from the original on January 26, 2024. Retrieved January 26, 2024.\\n\\n^ \"DALL¬∑E 2 pre-training mitigations\". OpenAI. June 28, 2022. Archived from the original on January 26, 2024. Retrieved January 26, 2024.\\n\\n^ Brandon, John (February 16, 2018). \"Terrifying high-tech porn: Creepy \\'deepfake\\' videos are on the rise\". Fox News. Archived from the original on June 15, 2018. Retrieved February 20, 2018.\\n\\n^ Cole, Samantha (January 24, 2018). \"We Are Truly Fucked: Everyone Is Making AI-Generated Fake Porn Now\". Vice. Archived from the original on September 7, 2019. Retrieved May 4, 2019.\\n\\n^ \"What Are Deepfakes & Why the Future of Porn is Terrifying\". Highsnobiety. February 20, 2018. Archived from the original on July 14, 2021. Retrieved February 20, 2018.\\n\\n^ \"Experts fear face swapping tech could start an international showdown\". The Outline. Archived from the original on January 16, 2020. Retrieved February 28, 2018.\\n\\n^ Roose, Kevin (March 4, 2018). \"Here Come the Fake Videos, Too\". The New York Times. ISSN\\xa00362-4331. Archived from the original on June 18, 2019. Retrieved March 24, 2018.\\n\\n^ Schreyer, Marco; Sattarov, Timur; Reimer, Bernd; Borth, Damian (2019). \"Adversarial Learning of Deepfakes in Accounting\". arXiv:1910.03810 [cs.LG].\\n\\n^ Menz, Bradley (2024). \"Health Disinformation Use Case Highlighting the Urgent Need for Artificial Intelligence Vigilance\". JAMA Internal Medicine. 184 (1): 92‚Äì96. doi:10.1001/jamainternmed.2023.5947. PMID\\xa037955873. S2CID\\xa0265148637. Archived from the original on February 4, 2024. Retrieved February 4, 2024.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='^ Chalfant, Morgan (March 6, 2024). \"U.S. braces for foreign interference in 2024 election\". Semafor. Archived from the original on March 11, 2024. Retrieved March 6, 2024.\\n\\n^ Menn, Joseph (September 23, 2024). \"Russia, Iran use AI to boost anti-U.S. influence campaigns, officials say\". The Washington Post. ISSN\\xa00190-8286. Archived from the original on September 24, 2024. Retrieved September 23, 2024.\\n\\n^ \"Join the Deepfake Detection Challenge (DFDC)\". deepfakedetectionchallenge.ai. Archived from the original on January 12, 2020. Retrieved November 8, 2019.\\n\\n^ Clarke, Yvette D. (June 28, 2019). \"H.R.3230 ‚Äì 116th Congress (2019-2020): Defending Each and Every Person from False Appearances by Keeping Exploitation Subject to Accountability Act of 2019\". www.congress.gov. Archived from the original on December 17, 2019. Retrieved October 16, 2019.\\n\\n^ \"New Research Reveals Scale of Threat Posed by AI-generated Images on 2024 Elections\". Logically. July 27, 2023. Archived from the original on October 3, 2023. Retrieved July 6, 2024.\\n\\n^ Lawton, Graham (September 12, 2023). \"Disinformation wars: The fight against fake news in the age of AI\". New Scientist. Retrieved July 5, 2024.\\n\\n^ Brewer, Jordan; Patel, Dhru; Kim, Dennie; Murray, Alex (April 12, 2024). \"Navigating the challenges of generative technologies: Proposing the integration of artificial intelligence and blockchain\". Business Horizons. 67 (5): 525‚Äì535. doi:10.1016/j.bushor.2024.04.011. ISSN\\xa00007-6813.\\n\\n^ \"People Are Still Terrible: AI Voice-Cloning Tool Misused for Deepfake Celeb Clips\". PCMag Middle East. January 31, 2023. Archived from the original on December 25, 2023. Retrieved July 25, 2023.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='^ \"The generative A.I. software race has begun\". Fortune. Archived from the original on March 25, 2023. Retrieved February 3, 2023.\\n\\n^ Milmo, Dan; Hern, Alex (May 20, 2023). \"Elections in UK and US at risk from AI-driven disinformation, say experts\". The Guardian. ISSN\\xa00261-3077. Archived from the original on November 16, 2023. Retrieved July 25, 2023.\\n\\n^ \"Seeing is believing? Global scramble to tackle deepfakes\". news.yahoo.com. Archived from the original on February 3, 2023. Retrieved February 3, 2023.\\n\\n^ Vincent, James (January 31, 2023). \"4chan users embrace AI voice clone tool to generate celebrity hatespeech\". The Verge. Archived from the original on December 3, 2023. Retrieved February 3, 2023.\\n\\n^ Thompson, Stuart A. (March 12, 2023). \"Making Deepfakes Gets Cheaper and Easier Thanks to A.I.\" The New York Times. ISSN\\xa00362-4331. Archived from the original on October 29, 2023. Retrieved July 25, 2023.\\n\\n^ \"A new AI voice tool is already being abused to make deepfake celebrity audio clips\". Engadget. January 31, 2023. Archived from the original on October 10, 2023. Retrieved February 3, 2023.\\n\\n^ Gee, Andre (April 20, 2023). \"Just Because AI-Generated Rap Songs Go Viral Doesn\\'t Mean They\\'re Good\". Rolling Stone. Archived from the original on January 2, 2024. Retrieved December 6, 2023.\\n\\n^ Coscarelli, Joe (April 19, 2023). \"An A.I. Hit of Fake \\'Drake\\' and \\'The Weeknd\\' Rattles the Music World\". The New York Times. Archived from the original on May 15, 2023. Retrieved December 5, 2023.\\n\\n^ Lippiello, Emily; Smith, Nathan; Pereira, Ivan (November 3, 2023). \"AI songs that mimic popular artists raising alarms in the music industry\". ABC News. Archived from the original on December 6, 2023. Retrieved December 6, 2023.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='^ Skelton, Eric. \"Fans Are Using Artificial Intelligence to Turn Rap Snippets Into Full Songs\". Complex. Archived from the original on January 2, 2024. Retrieved December 6, 2023.\\n\\n^ Marr, Bernard. \"Virtual Influencer Noonoouri Lands Record Deal: Is She The Future Of Music?\". Forbes. Archived from the original on December 4, 2023. Retrieved December 6, 2023.\\n\\n^ Thaler, Shannon (September 8, 2023). \"Warner Music signs first-ever record deal with AI pop star\". New York Post. Archived from the original on December 15, 2023. Retrieved December 6, 2023.\\n\\n^ Sjouwerman, Stu (December 26, 2022). \"Deepfakes: Get ready for phishing 2.0\". Fast Company. Archived from the original on July 31, 2023. Retrieved July 31, 2023.\\n\\n^ Sonnemaker, Tyler. \"As social media platforms brace for the incoming wave of deepfakes, Google\\'s former \\'fraud czar\\' predicts the biggest danger is that deepfakes will eventually become boring\". Business Insider. Archived from the original on April 14, 2021. Retrieved July 31, 2023.\\n\\n^ Collinson, Patrick (July 15, 2023). \"Fake reviews: can we trust what we read online as use of AI explodes?\". The Guardian. ISSN\\xa00261-3077. Archived from the original on November 22, 2023. Retrieved December 6, 2023.\\n\\n^ \"After WormGPT, FraudGPT Emerges to Help Scammers Steal Your Data\". PCMAG. July 25, 2023. Archived from the original on July 31, 2023. Retrieved July 31, 2023.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='^ Gupta, Maanak; Akiri, Charankumar; Aryal, Kshitiz; Parker, Eli; Praharaj, Lopamudra (2023). \"From ChatGPT to ThreatGPT: Impact of Generative AI in Cybersecurity and Privacy\". IEEE Access. 11: 80218‚Äì80245. arXiv:2307.00691. Bibcode:2023IEEEA..1180218G. doi:10.1109/ACCESS.2023.3300381. S2CID\\xa0259316122.\\n\\n^ Piper, Kelsey (February 2, 2024). \"Should we make our most powerful AI models open source to all?\". Vox. Retrieved January 13, 2025.\\n\\n^ Metz, Cade (July 10, 2023). \"In the Age of A.I., Tech\\'s Little Guys Need Big Friends\". New York Times.\\n\\n^ a b Bender, Emily M.; Gebru, Timnit; McMillan-Major, Angelina; Shmitchell, Shmargaret (March 1, 2021). \"On the Dangers of Stochastic Parrots: Can Language Models be Too Big? \\uf8ffü¶ú\". Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency. FAccT \\'21. New York, NY, USA: Association for Computing Machinery. pp.\\xa0610‚Äì623. doi:10.1145/3442188.3445922. ISBN\\xa0978-1-4503-8309-7.\\n\\n^ a b c d \"AI is an energy hog. This is what it means for climate change\". MIT Technology Review. May 23, 2024. Archived from the original on August 20, 2024. Retrieved August 27, 2024.\\n\\n^ a b c d e f g Dhar, Payal (August 1, 2020). \"The carbon impact of artificial intelligence\". Nature Machine Intelligence. 2 (8): 423‚Äì425. doi:10.1038/s42256-020-0219-9. ISSN\\xa02522-5839. Archived from the original on August 14, 2024.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='^ a b c d e Crawford, Kate (February 20, 2024). \"Generative AI\\'s environmental costs are soaring ‚Äî and mostly secret\". Nature. 626 (8000): 693. Bibcode:2024Natur.626..693C. doi:10.1038/d41586-024-00478-x. PMID\\xa038378831. Archived from the original on August 22, 2024.\\n\\n^ a b c d Rogers, Reece. \"AI\\'s Energy Demands Are Out of Control. Welcome to the Internet\\'s Hyper-Consumption Era\". Wired. ISSN\\xa01059-1028. Archived from the original on August 14, 2024. Retrieved August 27, 2024.\\n\\n^ a b c d e f Saenko, Kate (May 23, 2023). \"Is generative AI bad for the environment? A computer scientist explains the carbon footprint of ChatGPT and its cousins\". The Conversation. Archived from the original on July 1, 2024. Retrieved August 27, 2024.\\n\\n^ a b Lohr, Steve (August 26, 2024). \"Will A.I. Ruin the Planet or Save the Planet?\". The New York Times. ISSN\\xa00362-4331. Archived from the original on August 26, 2024. Retrieved August 27, 2024.\\n\\n^ Hoffman, Benjamin (June 11, 2024). \"First Came \\'Spam.\\' Now, With A.I., We\\'ve Got \\'Slop\\'\". The New York Times. ISSN\\xa00362-4331. Archived from the original on August 26, 2024. Retrieved August 27, 2024.\\n\\n^ a b \"Investigation Finds Actual Source of All That AI Slop on Facebook\". Futurism. August 10, 2024. Archived from the original on August 15, 2024. Retrieved August 27, 2024.\\n\\n^ a b Warzel, Charlie (August 21, 2024). \"The MAGA Aesthetic Is AI Slop\". The Atlantic. Archived from the original on August 25, 2024. Retrieved August 27, 2024.\\n\\n^ Edwards, Benj (August 14, 2024). \"Research AI model unexpectedly attempts to modify its own code to extend runtime\". Ars Technica. Archived from the original on August 24, 2024. Retrieved August 27, 2024.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='^ Hern, Alex; Milmo, Dan (May 19, 2024). \"Spam, junk ‚Ä¶ slop? The latest wave of AI behind the \\'zombie internet\\'\". The Guardian. ISSN\\xa00261-3077. Archived from the original on August 26, 2024. Retrieved August 27, 2024.\\n\\n^ Cox, Joseph (January 18, 2024). \"Google News Is Boosting Garbage AI-Generated Articles\". 404 Media. Archived from the original on June 13, 2024. Retrieved August 27, 2024.\\n\\n^ \"Beloved Local Newspapers Fired Staffers, Then Started Running AI Slop\". Futurism. July 31, 2024. Archived from the original on August 12, 2024. Retrieved August 27, 2024.\\n\\n^ Thompson, Brian; Dhaliwal, Mehak; Frisch, Peter; Domhan, Tobias; Federico, Marcello (August 2024). Ku, Lun-Wei; Martins, Andre; Srikumar, Vivek (eds.). \"A Shocking Amount of the Web is Machine Translated: Insights from Multi-Way Parallelism\". Findings of the Association for Computational Linguistics ACL 2024. Bangkok, Thailand and virtual meeting: Association for Computational Linguistics: 1763‚Äì1775. arXiv:2401.05749. doi:10.18653/v1/2024.findings-acl.103.\\n\\n^ Roscoe, Jules (January 17, 2024). \"A \\'Shocking\\' Amount of the Web Is Already AI-Translated Trash, Scientists Determine\". VICE. Archived from the original on July 1, 2024. Retrieved August 27, 2024.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='^ Koebler, Jason (September 19, 2024). \"Project Analyzing Human Language Usage Shuts Down Because \\'Generative AI Has Polluted the Data\\'\". 404 Media. Archived from the original on September 19, 2024. Retrieved September 20, 2024. While there has always been spam on the internet and in the datasets that Wordfreq used, \"it was manageable and often identifiable. Large language models generate text that masquerades as real language with intention behind it, even though there is none, and their output crops up everywhere,\" she wrote. She gives the example that ChatGPT overuses the word \"delve,\" in a way that people do not, which has thrown off the frequency of this specific word.\\n\\n^ Gray, Andrew (March 24, 2024). \"ChatGPT \"contamination\": estimating the prevalence of LLMs in the scholarly literature\". arXiv:2403.16887 [cs.DL].\\n\\n^ Kannan, Prabha (May 13, 2024). \"How Much Research Is Being Written by Large Language Models?\". Human-Centered Artificial Intelligence. Stanford University. Retrieved August 16, 2024.\\n\\n^ Valyaeva, Alina (August 15, 2023). \"AI Image Statistics for 2024: How Much Content Was Created by AI\". Everypixel Journal. Retrieved August 16, 2024.\\n\\n^ Shumailov, Ilia; Shumaylov, Zakhar; Zhao, Yiren; Papernot, Nicolas; Anderson, Ross; Gal, Yarin (July 2024). \"AI models collapse when trained on recursively generated data\". Nature. 631 (8022): 755‚Äì759. Bibcode:2024Natur.631..755S. doi:10.1038/s41586-024-07566-y. PMC\\xa011269175. PMID\\xa039048682.\\n\\n^ Bhatia, Aatish (August 26, 2024). \"When A.I.\\'s Output Is a Threat to A.I. Itself\". The New York Times. ISSN\\xa00362-4331. Retrieved August 27, 2024.\\n\\n^ \"Self-Consuming Generative Models Go Mad\". ICLR. 2024.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='^ Owen, Sean (April 12, 2023). \"Synthetic Data for Better Machine Learning\". databricks.com. Archived from the original on January 3, 2024. Retrieved January 4, 2024.\\n\\n^ Sharma, Himanshu (July 11, 2023). \"Synthetic Data Platforms: Unlocking the Power of Generative AI for Structured Data\". kdnuggets.com. Archived from the original on January 3, 2024. Retrieved January 4, 2024.\\n\\n^ St√∂ckl, Andreas (November 2, 2022). \"Evaluating a Synthetic Image Dataset Generated with Stable Diffusion\". arXiv:2211.01777 [cs.CV].\\n\\n^ Roth, Emma (January 25, 2023). \"CNET found errors in more than half of its AI-written stories\". The Verge. Archived from the original on November 6, 2023. Retrieved June 17, 2023.\\n\\n^ \"A magazine touted Michael Schumacher\\'s first interview in years. It was actually AI\". NPR. April 28, 2023. Archived from the original on June 17, 2023. Retrieved June 17, 2023.\\n\\n^ Al-Sibai, Noor (January 3, 2024). \"Police Say AI-Generated Article About Local Murder Is \"Entirely\" Made Up\". Futurism. Archived from the original on January 5, 2024. Retrieved January 8, 2024.\\n\\n^ \"NewsBreak: Most downloaded US news app has Chinese roots and \\'writes fiction\\' using AI\". Reuters. June 5, 2024. Archived from the original on June 6, 2024. Retrieved June 7, 2024.\\n\\n^ a b Harrison, Maggie (November 27, 2023). \"Sports Illustrated Published Articles by Fake, AI-Generated Writers\". Futurism. Archived from the original on December 15, 2023. Retrieved January 8, 2024.\\n\\n^ Christian, Jon (February 9, 2023). \"Magazine Publishes Serious Errors in First AI-Generated Health Article\". Futurism. Archived from the original on December 26, 2023. Retrieved January 8, 2024.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='^ Schneider, Jaron (December 14, 2023). \"B&H Photo Published an AI-Generated Guide Written by a Fake Person\". PetaPixel. Archived from the original on January 4, 2024. Retrieved January 8, 2024.\\n\\n^ Harrison, Maggie (August 29, 2023). \"USA Today Owner Pauses AI Articles After Butchering Sports Coverage\". Futurism. Archived from the original on January 4, 2024. Retrieved January 8, 2024.\\n\\n^ Buchanan, Tyler (August 28, 2023). \"Dispatch pauses AI sports writing program\". Axios. Archived from the original on January 1, 2024. Retrieved January 8, 2024.\\n\\n^ Sommer, Will (October 26, 2023). \"Mysterious bylines appeared on a USA Today site. Did these writers exist?\". Washington Post. ISSN\\xa00190-8286. Archived from the original on October 26, 2023. Retrieved January 8, 2024.\\n\\n^ a b c d e f g h i j k l m n o p q r s t u v w x y z aa ab ac \"Meet AdVon, the AI-Powered Content Monster Infecting the Media Industry\". Futurism. May 8, 2024. Archived from the original on June 4, 2024. Retrieved June 8, 2024.\\n\\n^ O\\'Sullivan, Donie; Gordon, Allison (November 2, 2023). \"How Microsoft\\'s AI is making a mess of the news | CNN Business\". CNN. Archived from the original on November 2, 2023. Retrieved January 8, 2024.\\n\\n^ Meade, Amanda (July 31, 2023). \"News Corp using AI to produce 3,000 Australian local news stories a week\". The Guardian. ISSN\\xa00261-3077. Archived from the original on December 2, 2023. Retrieved January 8, 2024.\\n\\n^ Tangermann, Victor (June 30, 2023). \"Gizmodo Staff Furious After Site Announces Move to AI Content\". Futurism. Archived from the original on December 6, 2023. Retrieved January 8, 2024.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='^ a b c Kafka, Peter (July 18, 2023). \"Coming to your internet, whether you like it or not: More AI-generated stories\". Vox. Archived from the original on July 18, 2023. Retrieved January 8, 2024.\\n\\n^ Landymore, Frank; Christian, Jon (September 13, 2023). \"The A.V. Club\\'s AI-Generated Articles Are Copying Directly From IMDb\". Futurism. Archived from the original on December 6, 2023. Retrieved January 8, 2024.\\n\\n^ Stiaplame, Nordiisk (January 28, 2025). \"Quartz Is Publishing AI-Generated Articles Based on Other AI Slop, Along With Warning They May Be Filled With Errors\". Futurism. Archived from the original on January 29, 2025. Retrieved January 30, 2025.\\n\\n^ Carroll, Rory (May 14, 2023). \"Irish Times apologises for hoax AI article about women\\'s use of fake tan\". The Guardian. ISSN\\xa00261-3077. Archived from the original on May 14, 2023. Retrieved January 8, 2024.\\n\\n^ Christian, Jon (February 1, 2023). \"CNET Sister Site Restarts AI Articles, Immediately Publishes Idiotic Error\". Futurism. Archived from the original on November 27, 2023. Retrieved January 8, 2024.\\n\\n^ Al-Sibai, Noor; Christian, Jon (March 30, 2023). \"BuzzFeed Is Quietly Publishing Entire AI-Generated Articles\". Futurism. Archived from the original on December 6, 2023. Retrieved January 8, 2024.\\n\\n^ \"Newsweek is making generative AI a fixture in its newsroom\". Nieman Lab. April 17, 2024. Archived from the original on May 15, 2024. Retrieved May 24, 2024.\\n\\n^ \"What\\'s in a byline? For Hoodline\\'s AI-generated local news, everything ‚Äî and nothing\". Nieman Lab. June 3, 2024. Archived from the original on June 6, 2024. Retrieved June 8, 2024.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='^ \"AI-generated news is here from S.F.-based Hoodline. What does that mean for conventional publishers?\". San Francisco Chronicle. May 8, 2024. Archived from the original on June 5, 2024. Retrieved June 7, 2024.\\n\\n^ Gold, Hadas (May 30, 2024). \"A national network of local news sites is publishing AI-written articles under fake bylines. Experts are raising alarm\". CNN. Archived from the original on June 6, 2024. Retrieved June 8, 2024.\\n\\n^ \"Wyoming reporter caught using artificial intelligence to create fake quotes and stories\". Associated Press. August 14, 2024. Archived from the original on August 24, 2024. Retrieved August 27, 2024.\\n\\n^ \"Cosmos Magazine publishes AI-generated articles, drawing criticism from journalists, co-founders\". ABC News. August 7, 2024. Archived from the original on August 24, 2024. Retrieved August 27, 2024.\\n\\n^ \"AI-generated articles are permeating major news publications\". National Public Radio. May 16, 2024. Archived from the original on June 19, 2024. Retrieved July 8, 2024.\\n\\n^ a b c Knibbs, Kate (July 30, 2024). \"Zombie Alt-Weeklies Are Stuffed With AI Slop About OnlyFans\". Wired. Archived from the original on August 11, 2024. Retrieved August 27, 2024.\\n\\n^ \"Apple says it will update AI feature after inaccurate news alerts\". The Guardian. January 7, 2025. Archived from the original on January 14, 2025. Retrieved January 14, 2025.\\n\\n^ \"TV channels are using AI-generated presenters to read the news. The question is, will we trust them?\". BBC News. January 26, 2024. Archived from the original on January 26, 2024. Retrieved May 24, 2024.\\n\\n^ Tait, Amelia (October 20, 2023). \"\\'Here is the news. You can\\'t stop us\\': AI anchor Zae-In grants us an interview\". The Guardian. ISSN\\xa00261-3077. Archived from the original on January 28, 2024. Retrieved May 24, 2024.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='^ Kuo, Lily (November 9, 2018). \"World\\'s first AI news anchor unveiled in China\". The Guardian. ISSN\\xa00261-3077. Archived from the original on February 20, 2024. Retrieved May 24, 2024.\\n\\n^ \"These ISIS news anchors are AI fakes. Their propaganda is real\". Washington Post. May 17, 2024. Archived from the original on May 19, 2024. Retrieved May 24, 2024.\\n\\n^ Mullin, Benjamin; Grant, Nico (July 20, 2023). \"Google Tests A.I. Tool That Is Able to Write News Articles\". The New York Times. ISSN\\xa00362-4331. Archived from the original on May 16, 2024. Retrieved May 24, 2024.\\n\\n^ Stenberg, Mark (February 27, 2024). \"Google Is Paying Publishers Five-Figure Sums to Test an Unreleased Gen AI Platform\". Adweek. Archived from the original on March 9, 2024. Retrieved April 17, 2024.\\n\\n^ Knibbs, Kate (February 7, 2024). \"Confessions of an AI Clickbait Kingpin\". Wired. ISSN\\xa01059-1028. Archived from the original on May 18, 2024. Retrieved May 24, 2024.\\n\\n^ Knibbs, Kate (January 26, 2024). \"How Beloved Indie Blog \\'The Hairpin\\' Turned Into an AI Clickbait Farm\". Wired. ISSN\\xa01059-1028. Archived from the original on April 14, 2024. Retrieved May 24, 2024.\\n\\n^ Koebler, Jason (July 9, 2024). \"A Beloved Tech Blog Is Now Publishing AI Articles Under the Names of Its Old Human Staff\". 404 Media. Archived from the original on July 12, 2024. Retrieved August 27, 2024.\\n\\n^ Hollister, Sean (July 10, 2024). \"Early Apple tech bloggers are shocked to find their name and work have been AI-zombified\". The Verge. Archived from the original on July 12, 2024. Retrieved August 27, 2024.\\n\\n^ \"AI slop is already invading Oregon\\'s local journalism\". Oregon Public Broadcasting. December 9, 2024. Archived from the original on December 9, 2024. Retrieved December 10, 2024.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='^ Knibbs, Kate (February 26, 2024). \"How a Small Iowa Newspaper\\'s Website Became an AI-Generated Clickbait Factory\". Wired. ISSN\\xa01059-1028. Archived from the original on February 26, 2024. Retrieved December 10, 2024.\\n\\n^ Koebler, Jason; Cole, Samantha; Maiberg, Emanuel; Cox, Joseph (January 26, 2024). \"We Need Your Email Address\". 404 Media. Archived from the original on December 2, 2024. Retrieved December 10, 2024.\\n\\n^ \"Meet the Serbian Businessman/DJ Who Runs the Zombie AI Southwest Journal - Racket\". Racket. February 16, 2024. Archived from the original on November 13, 2024. Retrieved December 10, 2024.\\n\\n^ Lima-Strong, Cristiano (January 11, 2024). \"Senators warn AI could lead to \\'destruction\\' of local news\". Washington Post. ISSN\\xa00190-8286. Archived from the original on January 11, 2024. Retrieved May 24, 2024.\\n\\n^ \"OpenAI strikes $5 million-plus local news deal\". Axios. July 18, 2023. Archived from the original on July 19, 2023. Retrieved May 24, 2024.\\n\\n^ Kelly, Heather (May 22, 2024). \"Meta walked away from news. Now the company\\'s using it for AI content\". Washington Post. ISSN\\xa00190-8286. Archived from the original on May 22, 2024. Retrieved May 24, 2024.\\n\\n^ \"How WIRED Will Use Generative AI Tools\". Wired. Archived from the original on December 30, 2023. Retrieved January 8, 2024.\\n\\n^ Barrett, Amanda (November 15, 2018). \"Standards around generative AI\". Associated Press. Archived from the original on September 23, 2023. Retrieved January 8, 2024.\\n\\n^ Viner, Katharine; Bateson, Anna (June 16, 2023). \"The Guardian\\'s approach to generative AI\". The Guardian. ISSN\\xa00261-3077. Archived from the original on January 3, 2024. Retrieved January 8, 2024.'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='^ Becker, K. B.; Simon, F. M.; Crum, C. (2023). \"Policies in parallel? A comparative study of journalistic AI policies in 52 global news organisations\". pp.\\xa08‚Äì9. doi:10.31235/osf.io/c4af9.\\n\\n^ Newman, Nic; Fletcher, Richard; Robertson, Craig T.; Arguedas, Amy Ross; Nielsen, Rasmus Fleis (June 2024). \"Digital News Report 2024\" (PDF). Reuters Institute for the Study of Journalism. p.\\xa020. doi:10.60625/risj-vy6n-4v57. Retrieved June 20, 2024.\\n\\n\\nvteGenerative AIConcepts\\nAutoencoder\\nDeep learning\\nGenerative adversarial network\\nGenerative pre-trained transformer\\nLarge language model\\nNeural network\\nPrompt engineering\\nRetrieval-augmented generation\\nReinforcement learning from human feedback\\nSelf-supervised learning\\nTransformer\\nVariational autoencoder\\nVision transformer\\nWord embedding\\nModelsText\\nClaude\\nDBRX\\nGemini\\nGPT\\n1\\n2\\n3\\nJ\\nChatGPT\\n4\\n4o\\no1\\no3\\nGrok\\nGranite\\nLlama\\nMistral Large\\nPanGu-Œ£\\nQwen\\nImage\\nAurora\\nDALL-E\\nFirefly\\nFlux\\nIdeogram\\nMidjourney\\nStable Diffusion\\nVideo\\nDream Machine\\nGen-3 Alpha\\nHailuo AI\\nKling\\nSora\\nVeo\\nVideoPoet\\nMusic\\nUdio\\nSuno AI\\nCompanies\\n01.AI\\nAlibaba\\nAnthropic\\nBaichuan\\nDeepSeek\\nElevenLabs\\nGoogle DeepMind\\nHugging Face\\nKuaishou\\nMeta AI\\nMiniMax\\nMistral AI\\nMoonshot AI\\nOpenAI\\nRunway\\nStability AI\\nSynthesia\\nxAI\\nZhipu AI\\n\\n Category\\n Commons'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='vteDigital artToolsHardware\\nComputer\\nCGI\\n2D graphics\\n2.5D\\n3D graphics\\nXerox\\n3D printer\\nSoftware\\nGraphic art software\\nFractal-generating software\\nAnimation software\\nForms\\nArt game\\nArtificial intelligence art\\nASCII art\\nComputer art scene\\nComputer music\\nCrypto art\\nCyberarts\\nDigital illustration\\nDigital imaging\\nDigital painting\\nDigital photography\\nDigital poetry\\nDigital architecture\\nElectronic music\\nEvolutionary art\\nFractal art\\nGenerative art\\nGenerative artificial intelligence\\nGenerative music\\nGIF art\\nGlitch art\\nImmersion\\nInteractive art\\nInternet art\\nMotion graphics\\nMusic visualization\\nPhotograph manipulation\\nPixel art\\nRender art\\nSoftware art\\nSystems art\\nTexture mapping\\nVirtual art\\nNotableartists\\nRefik Anadol\\nCory Arcangel\\nSougwen Chung\\nHarold Cohen\\nChar Davies\\nStephanie Dinkins\\nJake Elwes\\nDavid Em\\nDesmond Paul Henry\\nMario Klingemann\\nLynn Hershman Leeson\\nZachary Lieberman\\nMargot Lovejoy\\nMauro Martino\\nEric Millikin\\nHamid Naderi Yeganeh\\nTrevor Paglen\\nCasey Reas\\nAnna Ridler\\nBen Rubin (artist)\\nKarl Sims\\nCamille Utterback\\nPindar Van Arman\\nNotableartworks\\nEdmond de Belamy\\nBarnsley fern\\nJesus Dress Up\\nListening Post (artwork)\\nRemember To Rise\\nOrganizations,conferences\\nArtfutura\\nArtmedia\\nAustin Museum of Digital Art\\nComputer Arts Society\\nEVA Conferences\\nLos Angeles Center for Digital Art\\nLumen Prize\\nonedotzero\\nSIGGRAPH\\nV&A Digital Futures'),\n",
              " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Generative_artificial_intelligence', 'title': 'Generative artificial intelligence - Wikipedia', 'language': 'en'}, page_content='Retrieved from \"https://en.wikipedia.org/w/index.php?title=Generative_artificial_intelligence&oldid=1274593738\"\\nCategories: Artificial neural networksDeep learningMachine learningGenerative artificial intelligence2020s in computing2023 in computing2024 in computing2025 in computingHidden categories: CS1 Japanese-language sources (ja)CS1 Italian-language sources (it)Articles with short descriptionShort description is different from WikidataUse mdy dates from October 2023Articles needing cleanup from July 2024All pages needing cleanupWikipedia list cleanup from July 2024\\n\\n\\n\\n\\n\\n\\n This page was last edited on 8 February 2025, at 06:43\\xa0(UTC).\\nText is available under the Creative Commons Attribution-ShareAlike 4.0 License;\\nadditional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia¬Æ is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.\\n\\n\\nPrivacy policy\\nAbout Wikipedia\\nDisclaimers\\nContact Wikipedia\\nCode of Conduct\\nDevelopers\\nStatistics\\nCookie statement\\nMobile view\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nToggle the table of contents\\n\\n\\n\\n\\n\\n\\n\\nGenerative artificial intelligence\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n45 languages\\n\\n\\nAdd topic')]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "embeddings=HuggingFaceEmbeddings(model_name='all-MiniLM-L6-v2')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493,
          "referenced_widgets": [
            "b1458757ded9460ca9bb8d8973b7adae",
            "b792a73550994cff8f72c761ebbf7c20",
            "9085abee81fa4d98be9bd80f0531ad87",
            "d605c426d0c046a9abfb60b2ac93919c",
            "565946b7e8674d48a4bfe1a68dd25061",
            "e1e14a5ed5804c10aed91c672fe5ad5c",
            "2074dee7dee245f589b511b5e7a010f3",
            "0dc3ea746a85432885e6ab8b33180150",
            "981ab91e73274870b8c51a3d9d57f950",
            "e9c91e8d20ed44edbde5de5e8b087a8c",
            "ec1d34233acb4943981bd9275f392185",
            "e700e8379691491d8d715c81def84c61",
            "a74a4495280440979e5f2c243ddf99c9",
            "777415ee4867478ab56e49f84a45db7f",
            "f3e8a7fb6f314fac9fd61b331711cece",
            "8c704ad2b3994fceb758ddec83a77a68",
            "61cacabe6d664f5f8a3cec80c308f977",
            "6b81ef994ed547ffb7a65a30343d4704",
            "ccc5a12f07f5469694b4f9955f7b6949",
            "767b7e20f1d548bb95ee751a77914468",
            "03c8e924b2f049e19b067f56de034f0d",
            "68a9e18c33af4cb0bfc60dd0084d786b",
            "2dd5fc3eb5dc466d8e6d31d818371b98",
            "8f20aca573cc45b8ba3333c916f0d61e",
            "6f1e6bba2e28423bbc1531bb0b09d232",
            "6e09320b9fbc4be490200f212f27634d",
            "7fe5d309825f4419908fcd20bc675f25",
            "c5f42cf9921c437ab77ce5e5d7ede177",
            "fe887c6ad0db4d96b7b3662721a40951",
            "766fbd1b9337442a8d9e8a35d9ea90a0",
            "224294e836a14d798f93029cfcc42b04",
            "3e37a6a1571a464fbc4d454f16d3d756",
            "be2bb4a2170241d5b0ad20237de30a4e",
            "e01311a446464faa96f9ff094c828f19",
            "fd9192df0d1840aba2d84d9bfb26ceb9",
            "cedab43a90b4403bbea9ef6dd1d9cfb2",
            "291af739a4a94e478fed82e980b468cb",
            "aaa8b643d8be40deba1a055893e569c5",
            "c6c70ccf90204a329f16e118e4ca46ab",
            "1260377f983e475d93ea3851a368491d",
            "50de12155872486abf821876543d6383",
            "709362c7bb0c460896e32064a8300073",
            "20af3cc1512d4e268fcfd8ac2ddff355",
            "0061bff0b479429ba2c2dde62e148de1",
            "00f7d7e3fc114eaf84b78611f15c85e6",
            "a6d2560afc914b5f8c4bea00937b2947",
            "0262046f9e38404b94cf0ab77b4403f1",
            "09cb50344e8140b980694494a952f1aa",
            "bda8b4fba9f3434e98a84ec63cfebcff",
            "55e85590710545b7b9eca1d3e4e47056",
            "a6c3d8d8b6b34d3286ea7efb80d0a692",
            "7b9c7ea80ef346a9bdb52ffb8c953d44",
            "ffd56a123637482d8da56a0696a134a7",
            "3b17fe514d1f41cd885f7464343e9dcf",
            "a0e88234c9a24c0ca7d760de9555d90f",
            "8a3dce51a1794c39a3aba808d58f93a2",
            "164f4cf60cbb40ad85fbcdb67a7de8a3",
            "e574a564d4464d8a8d5a68713e1fb263",
            "e1bc8989847a4a02898de128159921b5",
            "b13370d89dfd421195c8e6ced5fb3916",
            "5a74fca617b242d888d700a3b7a79b23",
            "463192ef605047ed8a5cb083d09b51b6",
            "0c377811926441879f3830cce8bb4883",
            "f3fee8bb77b041b4aedb19d41220e3b6",
            "9e437ff58bbf494bbced5158b8af9caf",
            "f3ae8b5417f54964a2327c9d640511c4",
            "4424e9c653c641e394572802babc10ce",
            "3114b4e192824b258dd8a7fc297f76f1",
            "92cbfb95946540cab3ab8e096c1fb6ad",
            "46c30142852d4e1c97e73af3bf29ab10",
            "4314d1a9e7da47d78c76be4c34ef2e25",
            "8d7ba9e643cc4780ba406e8a587434da",
            "56115c4141a04d7d9a00d04feee179b0",
            "f58dae8e49f040d8825a6de7d2fe7bc4",
            "bcb68c106b944d8fa6b9f08f9ed58b07",
            "3f6f418d86be494fa04005ca82369ef4",
            "b77e6418bba64d15b11f30afd39a7c1f",
            "8df852482ddc4f1286309a88d78b0da5",
            "b9cb1a6e831c4fafa35450d49f3c3ebc",
            "19f457d271534ac7a643375b57ea291c",
            "7c899678fa6e4a7d9f08ac39513fb790",
            "94fd43f29f934b048ad3e3dd95ba7561",
            "694807f491004bf8b3834488c9db45e4",
            "fd4a062370ce4cbf914cafa7ed30dc14",
            "5a1c6774b99b43c98a4737cb95d2567c",
            "55a3873ab9c843c8a91b8cef22694f59",
            "9857757cf65e4011a2ea181ad382b160",
            "f561b960559d46098f5e01869e1d6561",
            "fe865474edc04cb28e5e0272e24ad8ce",
            "3f63f189aace4fc7b36c0140403ee310",
            "d8c52960e9db4160bcc1f48a3a17a6b7",
            "7abaf106a9654a779de10f54de539d7e",
            "79b02c1abc464ba8b8f4be8d4d02e176",
            "311501bfd96b417b8bb47a39ace5540c",
            "a46c3c83134c41f890902e8ef7772f59",
            "8e98aec7e8594cf5b907ee3fb895bfc3",
            "f2885a0c6505499d86476859398e3d6d",
            "6e214ea99c8945138325c4bff5f8f3ab",
            "4bf5d0c3ec144b488fe1ff803c59b17b",
            "2e71f8d1bec1484e876708c468048839",
            "6bc8638b1ef8439cbf11be54395cd8e4",
            "d9dd68f3a63c408aa9d21cc2ce7e7e6a",
            "e8237d543612482b9e3975b3228b2055",
            "1a3abbcd24ab42c0b2a931b002cf8d18",
            "2fb0c9a814a142f0839fb5c10ffe5073",
            "0b0811d80e9349668fdb359c67115e9e",
            "30a0758883ca4a89850e49a71edc51cf",
            "8d7f2ec93fd1479092e8dd7f9eca1dd3",
            "97128d468c0a46579345908486867650",
            "9459d2acc10a48d786e06f03bd811c88",
            "c6d02285388448198330ecd0641e518b",
            "7b5139c410ef4bbebf763b39e47e9f85",
            "c32f96badf6e4ab08c0db3057c847d26",
            "ef25a227127544409de33af7c737f86a",
            "bd5301e0bb2e48a79af290ad17bf0cda",
            "cd6267b617e249219abac3a382b53d34",
            "e73bf2034951405c9ea5ff21114d3917",
            "67a0d062a65b4b9ca7d730db33d8c277",
            "a51f291bba5943388b12a8275b4a7ff4",
            "6089d9eeb4c347f99a1953c00b6f27b8",
            "a86a2211c15b446f9a26bad03a31b75e"
          ]
        },
        "id": "5_V1ianV096a",
        "outputId": "d7fdd2bd-98d2-4179-8ed4-a280f6474d3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b1458757ded9460ca9bb8d8973b7adae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e700e8379691491d8d715c81def84c61"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2dd5fc3eb5dc466d8e6d31d818371b98"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e01311a446464faa96f9ff094c828f19"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "00f7d7e3fc114eaf84b78611f15c85e6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a3dce51a1794c39a3aba808d58f93a2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4424e9c653c641e394572802babc10ce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8df852482ddc4f1286309a88d78b0da5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe865474edc04cb28e5e0272e24ad8ce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e71f8d1bec1484e876708c468048839"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c6d02285388448198330ecd0641e518b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores.cassandra import Cassandra\n",
        "astra_vector_store = Cassandra(embedding=embeddings,\n",
        "                               table_name=\"qa_mini_demo\",\n",
        "                               session=None,\n",
        "                               keyspace=None)"
      ],
      "metadata": {
        "id": "Dwi1cKuk2IJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
        "astra_vector_store.add_documents(docs_split)\n",
        "print(\"Inserted %i headlines: \"%len(docs_split))\n",
        "astra_vector_index=VectorStoreIndexWrapper(vectorstore=astra_vector_store)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkXNBDby5pN3",
        "outputId": "d99e609e-6882-4174-921c-a3ad5fd785b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inserted 91 headlines: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#retrieve the information\n",
        "retriever = astra_vector_store.as_retriever()\n",
        "retriever.invoke(\"What are LLMs\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMw0vWSm7UH6",
        "outputId": "0404fc7b-04ee-4058-cf7f-8b4aac691dcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.protocol:Server warning: Top-K queries can only be run with consistency level ONE / LOCAL_ONE / NODE_LOCAL. Consistency level LOCAL_QUORUM was requested. Downgrading the consistency level to LOCAL_ONE.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='ebff74f86f814471a983fa412b40fbb0', metadata={'description': 'Large language models are AI systems capable of understanding and generating human language by processing vast amounts of text data.\\r\\n\\r\\n\\r\\n\\r\\n', 'language': 'en', 'source': 'https://www.ibm.com/think/topics/large-language-models', 'title': 'What Are Large Language Models (LLMs)? | IBM '}, page_content='What Are Large Language Models (LLMs)? | IBM \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                        \\n\\n\\n\\n  \\n    What are large language models (LLMs)?\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n                    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                                    Artificial Intelligence\\n                                \\n\\n\\n\\n\\n\\n\\n                    \\n\\n\\n\\n  \\n    2 November 2023\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n                \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Link copied\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\r\\n        What are LLMs?\\r\\n    \\n\\n\\n\\nLarge language models (LLMs) are a category of foundation models trained on immense amounts of data making them capable of understanding and generating natural language and other types of content to perform a wide range of tasks.'),\n",
              " Document(id='a9ab062a0e4c4302a4ea7493a79941e0', metadata={'description': 'Large language models are AI systems capable of understanding and generating human language by processing vast amounts of text data.\\r\\n\\r\\n\\r\\n\\r\\n', 'language': 'en', 'source': 'https://www.ibm.com/think/topics/large-language-models', 'title': 'What Are Large Language Models (LLMs)? | IBM '}, page_content='What Are Large Language Models (LLMs)? | IBM \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                        \\n\\n\\n\\n  \\n    What are large language models (LLMs)?\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n                    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                                    Artificial Intelligence\\n                                \\n\\n\\n\\n\\n\\n\\n                    \\n\\n\\n\\n  \\n    2 November 2023\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n                \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Link copied\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\r\\n        What are LLMs?\\r\\n    \\n\\n\\n\\nLarge language models (LLMs) are a category of foundation models trained on immense amounts of data making them capable of understanding and generating natural language and other types of content to perform a wide range of tasks.'),\n",
              " Document(id='41fb5d27063941fca4677707c0c2488a', metadata={'description': 'Large language models are AI systems capable of understanding and generating human language by processing vast amounts of text data.\\r\\n\\r\\n\\r\\n\\r\\n', 'language': 'en', 'source': 'https://www.ibm.com/think/topics/large-language-models', 'title': 'What Are Large Language Models (LLMs)? | IBM '}, page_content='What Are Large Language Models (LLMs)? | IBM \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                        \\n\\n\\n\\n  \\n    What are large language models (LLMs)?\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n                    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                                    Artificial Intelligence\\n                                \\n\\n\\n\\n\\n\\n\\n                    \\n\\n\\n\\n  \\n    2 November 2023\\n\\n\\n\\n\\n\\n\\n    \\n\\n\\n                \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n                Link copied\\n            \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\r\\n        What are LLMs?\\r\\n    \\n\\n\\n\\nLarge language models (LLMs) are a category of foundation models trained on immense amounts of data making them capable of understanding and generating natural language and other types of content to perform a wide range of tasks.'),\n",
              " Document(id='3249a049ba7a4a43a57542b5d511fd05', metadata={'description': 'Large language models are AI systems capable of understanding and generating human language by processing vast amounts of text data.\\r\\n\\r\\n\\r\\n\\r\\n', 'language': 'en', 'source': 'https://www.ibm.com/think/topics/large-language-models', 'title': 'What Are Large Language Models (LLMs)? | IBM '}, page_content='They are able to do this thanks to billions of parameters that enable them to capture intricate patterns in language and perform a wide array of language-related tasks. LLMs are revolutionizing applications in various fields, from chatbots and virtual assistants to content generation, research assistance and language translation.\\nAs they continue to evolve and improve, LLMs are poised to reshape the way we interact with technology and access information, making them a pivotal part of the modern digital landscape.')]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#langgraph application\n",
        "from typing import Literal\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field"
      ],
      "metadata": {
        "id": "9Al_WGXR7r5Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19b540a9-9541-4d0a-ba1c-fa162423c326"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py:3553: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
            "\n",
            "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
            "with: `from pydantic import BaseModel`\n",
            "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
            "\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Data model\n",
        "class RouteQuery(BaseModel):\n",
        "  \"\"\"Route a user query to the most relevant data source\"\"\"\n",
        "  datasource: Literal[\"vectorstore\",\"wiki-search\"]=Field(\n",
        "      ...,\n",
        "      description=\"Given a user question choose to route it to wikipedia or a vectorstore.\",\n",
        "  )"
      ],
      "metadata": {
        "id": "3XtGcUPdRCVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "from langchain_groq import ChatGroq\n",
        "groq_api_key = userdata.get('groq_api_key')\n",
        "print(groq_api_key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzDNF8ajRmlE",
        "outputId": "bc1d7678-4f25-4b22-dd25-0047646bab15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "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\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm=ChatGroq(groq_api_key=groq_api_key,model_name=\"llama-3.3-70b-versatile\")\n",
        "llm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwHRD6rsSOrZ",
        "outputId": "a1fd3587-7be4-45da-d060-beeac5bccc45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x788fd552c090>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x788fd552e290>, model_name='llama-3.3-70b-versatile', model_kwargs={}, groq_api_key=SecretStr('**********'))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "structured_llm_router=llm.with_structured_output(RouteQuery)"
      ],
      "metadata": {
        "id": "7AnDsDIySwBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prompt\n",
        "system=\"You are an expert at routing user question to a vectorstore or wikipedia. The vectorstore contains documents related to agents, prompt engineering and adversarial attacks. Use the vectorstore for questions on these topics. Otherwise use wiki-search.\"\n",
        "route_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", system),\n",
        "        (\"human\", \"{question}\"),\n",
        "    ]\n",
        ")\n",
        "question_router = route_prompt | structured_llm_router"
      ],
      "metadata": {
        "id": "3hbOwCFKTBpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(question_router.invoke({\"question\":\"What are LLMs\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rik8oEwYT4Nk",
        "outputId": "0d61c73d-c4ff-4448-8c04-2e87784e7df1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "datasource='vectorstore'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(question_router.invoke({\"question\":\"Who is Narendra Modi\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQwTJk0RUAEo",
        "outputId": "c0abbe72-af58-47c5-f073-9981629cbb0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "datasource='wiki-search'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wikipedia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCRAN3FIVBzS",
        "outputId": "ce623ed3-b94d-4e61-fbe1-b5b59a778cbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from wikipedia) (4.13.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wikipedia) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2025.1.31)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->wikipedia) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->wikipedia) (4.12.2)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11679 sha256=ae86b60353f9648446f405b1e6607aeed9c6cfa9ec2e7ec5f0eab9462eb4e129\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/ab/cb/45ccc40522d3a1c41e1d2ad53b8f33a62f394011ec38cd71c6\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.utilities import WikipediaAPIWrapper\n",
        "from langchain_community.tools import WikipediaQueryRun\n",
        "api_wrapper = WikipediaAPIWrapper(top_k_results=1,doc_content_chars_max=200)\n",
        "wiki = WikipediaQueryRun(api_wrapper=api_wrapper)"
      ],
      "metadata": {
        "id": "4DWKWd1-UO_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wiki.run(\"Tell me about Singer Selena Gomez\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "e4JVDuuYU6eE",
        "outputId": "4f701980-a3da-452d-95d2-0ba9e374c5e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Page: Kiss & Tell (Selena Gomez & the Scene album)\\nSummary: Kiss & Tell is the debut studio album by American band Selena Gomez & the Scene. The album was released on September 29, 2009 through Hollyw'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#AI agents application using LangGraph\n",
        "from typing import List\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "class GraphState(TypedDict):\n",
        "  \"\"\"\n",
        "  Represents the state of the graph.\n",
        "  Attributes:\n",
        "  question: question generation\n",
        "  llm: llm generation\n",
        "  documents: documents generation\n",
        "  \"\"\"\n",
        "  question: str\n",
        "  generation: str\n",
        "  documents: List[str]"
      ],
      "metadata": {
        "id": "sNLrmuaOVKMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import Document\n",
        "#query it from the retriever and display it\n",
        "def retrieve(state):\n",
        "  \"\"\"\n",
        "    Retrieval\n",
        "    Args:\n",
        "      state: GraphState\n",
        "    Returns:\n",
        "      new key added to state, documents, that contain the retrieved documents\n",
        "  \"\"\"\n",
        "  print(\"Retrieve: \")\n",
        "  question = state[\"question\"]\n",
        "  #retrieval\n",
        "  documents = retriever.invoke(question)\n",
        "  return {\"documents\": documents, \"question\": question}"
      ],
      "metadata": {
        "id": "f3bOYuyjzEnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for wikipedia search\n",
        "def search_wiki(state):\n",
        "  print(\"Wikipidea: \")\n",
        "  question = state[\"question\"]\n",
        "  print(question)\n",
        "\n",
        "  #wiki search\n",
        "  docs = wiki.invoke({'query':question})\n",
        "  wiki_results = docs\n",
        "  wiki_results = Document(page_content=wiki_results)\n",
        "  return {\"documents\": [wiki_results], \"question\": question}"
      ],
      "metadata": {
        "id": "aI90iaMV1bNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def route_question(state):\n",
        "  \"\"\"\n",
        "  route question to wiki search or RAG\n",
        "  args:\n",
        "  the current graph state\n",
        "  returns:\n",
        "  str: Next node to call\n",
        "  \"\"\"\n",
        "  print(\"Route question:\")\n",
        "  question = state[\"question\"]\n",
        "  source = question_router.invoke({\"question\":question})\n",
        "  if source.datasource == \"wiki_search\":\n",
        "    print(\"Route question to wiki search\")\n",
        "    return \"wiki_search\"\n",
        "  elif source.datasource == \"vectorstore\":\n",
        "    print(\"Route question to RAG\")\n",
        "    return \"vectorstore\""
      ],
      "metadata": {
        "id": "e47aLfrH3IoX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, START, END\n",
        "workflow = StateGraph(GraphState)\n",
        "#define the nodes\n",
        "workflow.add_node(\"wiki_search\",search_wiki) #web search\n",
        "workflow.add_node(\"vectorstore\",retrieve) #retrieve\n",
        "#build the graph\n",
        "workflow.add_conditional_edges(\n",
        "    START,\n",
        "    route_question,\n",
        "    {\n",
        "        \"wiki_search\":\"wiki_search\",\n",
        "        \"vectorstore\":\"vectorstore\" # Changed 'retrieve' to 'vectorstore'\n",
        "    }\n",
        ")\n",
        "workflow.add_edge(\"vectorstore\",END) # Changed 'retrieve' to 'vectorstore'\n",
        "workflow.add_edge(\"wiki_search\",END)\n",
        "#compile\n",
        "app = workflow.compile()"
      ],
      "metadata": {
        "id": "ID50HZqJ-S9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "try:\n",
        "  display(Image(app.get_graph().draw_mermaid_png()))\n",
        "except:\n",
        "  Exception"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "ErRbMT50_77j",
        "outputId": "f657297f-95b5-4c93-f71e-8e8c766e9b83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "\n",
        "# Run\n",
        "inputs = {\n",
        "    \"question\": \"What is agent?\"\n",
        "}\n",
        "for output in app.stream(inputs):\n",
        "    for key, value in output.items():\n",
        "        # Node\n",
        "        pprint(f\"Node '{key}':\")\n",
        "        # Optional: print full state at each node\n",
        "        # pprint.pprint(value[\"keys\"], indent=2, width=80, depth=None)\n",
        "    pprint(\"\\n---\\n\")\n",
        "\n",
        "# Final generation\n",
        "pprint(value['documents'][0].dict()['metadata']['description'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n49z2frZAlz9",
        "outputId": "4bed08ef-c6a5-49c2-81f6-82f2a058a524"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Route question:\n",
            "Route question to RAG\n",
            "Retrieve: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.protocol:Server warning: Top-K queries can only be run with consistency level ONE / LOCAL_ONE / NODE_LOCAL. Consistency level LOCAL_QUORUM was requested. Downgrading the consistency level to LOCAL_ONE.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Node 'vectorstore':\"\n",
            "'\\n---\\n'\n",
            "('An artificial intelligence (AI) agent refers to a system or program that is '\n",
            " 'capable of autonomously performing tasks on behalf of a user or another '\n",
            " 'system.')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-a4ba987db3a3>:16: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
            "  pprint(value['documents'][0].dict()['metadata']['description'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UYqLqFDIA-nh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}